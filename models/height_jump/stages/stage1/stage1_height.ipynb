{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames extracted for 1_user2.mp4\n",
      "Frames extracted for 1_user5.mp4\n",
      "Frames extracted for 1_user12.mp4\n",
      "Frames extracted for 1_user7.mp4\n",
      "Frames extracted for 1_user13.mp4\n",
      "Frames extracted for 0_user3.mp4\n",
      "Frames extracted for 0_user1.mp4\n",
      "Frames extracted for 0_user22.mp4\n",
      "Frames extracted for 0_user20.mp4\n",
      "Frames extracted for 0_user10.mp4\n",
      "Frames extracted for 1_user23.mp4\n",
      "Frames extracted for 1_user21.mp4\n",
      "Frames extracted for 1_user8.mp4\n",
      "Frames extracted for 1_user9.mp4\n",
      "Frames extracted for 0.5_user6.mp4\n",
      "Frame extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "video_dir = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/videos\"\n",
    "frames_dir = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/frames\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(frames_dir, exist_ok=True)\n",
    "\n",
    "def extract_frames(video_path, output_dir, interval=1):\n",
    "    \"\"\"\n",
    "    Extract frames from a video at a given interval (default: every 1 frame).\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    frame_count = 0\n",
    "    video_name = os.path.basename(video_path).rsplit('.', 1)[0]  # Get the video name without extension\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Save every 'interval' frame\n",
    "        if count % interval == 0:\n",
    "            frame_path = os.path.join(output_dir, f\"{video_name}_frame{frame_count}.jpg\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            frame_count += 1\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Process all videos\n",
    "for video_file in os.listdir(video_dir):\n",
    "    # Check if the filename ends with \".mp4\" and starts with a valid number\n",
    "    if video_file.endswith(\".mp4\"):\n",
    "        try:\n",
    "            # Split by '_' and attempt to convert the first part to float\n",
    "            prefix = video_file.split('_')[0]\n",
    "            float(prefix)  # This ensures it works for values like '0.5', '1', or '0'\n",
    "            \n",
    "            # Proceed with frame extraction\n",
    "            video_path = os.path.join(video_dir, video_file)\n",
    "            video_frames_dir = os.path.join(frames_dir, video_file.rsplit('.', 1)[0])  # Use full name\n",
    "            os.makedirs(video_frames_dir, exist_ok=True)\n",
    "            extract_frames(video_path, video_frames_dir)\n",
    "            print(f\"Frames extracted for {video_file}\")\n",
    "        except ValueError:\n",
    "            print(f\"Skipping file with invalid prefix: {video_file}\")\n",
    "\n",
    "print(\"Frame extraction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736958387.855475 4325357 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n",
      "W0000 00:00:1736958387.906867 4340948 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1736958387.931131 4340941 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints extracted for 0.5_user6\n",
      "Keypoints extracted for 0_user3\n",
      "Keypoints extracted for 0_user20\n",
      "Keypoints extracted for 1_user13\n",
      "Keypoints extracted for 1_user5\n",
      "Keypoints extracted for 1_user2\n",
      "Keypoints extracted for 1_user23\n",
      "Keypoints extracted for 0_user10\n",
      "Keypoints extracted for 1_user12\n",
      "Keypoints extracted for 0_user1\n",
      "Keypoints extracted for 1_user8\n",
      "Keypoints extracted for 1_user21\n",
      "Keypoints extracted for 1_user7\n",
      "Keypoints extracted for 0_user22\n",
      "Keypoints extracted for 1_user9\n",
      "Keypoint extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import json\n",
    "\n",
    "# Paths\n",
    "frames_dir = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/frames\"\n",
    "keypoints_dir = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/keypoints\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(keypoints_dir, exist_ok=True)\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=True, model_complexity=2, enable_segmentation=False)\n",
    "\n",
    "def extract_keypoints_from_frame(frame_path):\n",
    "    \"\"\"\n",
    "    Extract keypoints relevant to upright posture and alignment.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(frame_path)\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    result = pose.process(rgb_image)\n",
    "\n",
    "    if result.pose_landmarks:\n",
    "        # Extract relevant keypoints for upright posture analysis\n",
    "        keypoints = {\n",
    "            \"right_foot_index\": {\n",
    "                \"x\": result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX].x,\n",
    "                \"y\": result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX].y,\n",
    "                \"z\": result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_FOOT_INDEX].z,\n",
    "            },\n",
    "            \"right_heel\": {\n",
    "                \"x\": result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HEEL].x,\n",
    "                \"y\": result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HEEL].y,\n",
    "                \"z\": result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HEEL].z,\n",
    "            },\n",
    "            \"left_foot_index\": {\n",
    "                \"x\": result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_FOOT_INDEX].x,\n",
    "                \"y\": result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_FOOT_INDEX].y,\n",
    "                \"z\": result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_FOOT_INDEX].z,\n",
    "            },\n",
    "            \"left_heel\": {\n",
    "                \"x\": result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HEEL].x,\n",
    "                \"y\": result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HEEL].y,\n",
    "                \"z\": result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HEEL].z,\n",
    "            },\n",
    "            \"hip_center\": {\n",
    "                \"x\": (result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP].x +\n",
    "                      result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP].x) / 2,\n",
    "                \"y\": (result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP].y +\n",
    "                      result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP].y) / 2,\n",
    "                \"z\": (result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP].z +\n",
    "                      result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP].z) / 2,\n",
    "            },\n",
    "            \"shoulder_center\": {\n",
    "                \"x\": (result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x +\n",
    "                      result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x) / 2,\n",
    "                \"y\": (result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y +\n",
    "                      result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y) / 2,\n",
    "                \"z\": (result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].z +\n",
    "                      result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].z) / 2,\n",
    "            },\n",
    "        }\n",
    "        return keypoints\n",
    "    return None\n",
    "\n",
    "def process_frames(video_frames_dir, output_path):\n",
    "    \"\"\"\n",
    "    Process all frames for a video and save keypoints as JSON.\n",
    "    \"\"\"\n",
    "    keypoints_data = []\n",
    "    for frame_file in sorted(os.listdir(video_frames_dir)):\n",
    "        frame_path = os.path.join(video_frames_dir, frame_file)\n",
    "        keypoints = extract_keypoints_from_frame(frame_path)\n",
    "        if keypoints:\n",
    "            keypoints_data.append(keypoints)\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(keypoints_data, f, indent=4)\n",
    "\n",
    "# Process frames for each video\n",
    "for video_name in os.listdir(frames_dir):\n",
    "    video_frames_dir = os.path.join(frames_dir, video_name)\n",
    "    if os.path.isdir(video_frames_dir):\n",
    "        output_path = os.path.join(keypoints_dir, f\"{video_name}_keypoints.json\")\n",
    "        process_frames(video_frames_dir, output_path)\n",
    "        print(f\"Keypoints extracted for {video_name}\")\n",
    "\n",
    "print(\"Keypoint extraction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP features extracted for 0.5_user6\n",
      "CLIP features extracted for 0_user3\n",
      "CLIP features extracted for 0_user20\n",
      "CLIP features extracted for 1_user13\n",
      "CLIP features extracted for 1_user5\n",
      "CLIP features extracted for 1_user2\n",
      "CLIP features extracted for 1_user23\n",
      "CLIP features extracted for 0_user10\n",
      "CLIP features extracted for 1_user12\n",
      "CLIP features extracted for 0_user1\n",
      "CLIP features extracted for 1_user8\n",
      "CLIP features extracted for 1_user21\n",
      "CLIP features extracted for 1_user7\n",
      "CLIP features extracted for 0_user22\n",
      "CLIP features extracted for 1_user9\n",
      "CLIP feature extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "\n",
    "# Paths\n",
    "frames_dir = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/frames\"\n",
    "clip_features_dir = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/clip_features\"\n",
    "os.makedirs(clip_features_dir, exist_ok=True)\n",
    "\n",
    "# Load CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "def extract_clip_features(video_frames_dir, output_path, batch_size=8):\n",
    "    \"\"\"\n",
    "    Extract CLIP features for all frames in a video using batch processing.\n",
    "    \"\"\"\n",
    "    frame_features = []\n",
    "    frame_paths = sorted(os.listdir(video_frames_dir))\n",
    "    images = []\n",
    "\n",
    "    for i, frame_file in enumerate(frame_paths):\n",
    "        try:\n",
    "            frame_path = os.path.join(video_frames_dir, frame_file)\n",
    "            image = Image.open(frame_path).convert(\"RGB\")\n",
    "            images.append(image)\n",
    "\n",
    "            # Process batch\n",
    "            if len(images) == batch_size or i == len(frame_paths) - 1:\n",
    "                inputs = processor(images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "                with torch.no_grad():\n",
    "                    image_features = model.get_image_features(**inputs).cpu().numpy()\n",
    "                    frame_features.extend(image_features)\n",
    "                images = []  # Clear batch to free memory\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing frame {frame_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Save features\n",
    "    torch.save(frame_features, output_path)\n",
    "\n",
    "# Process all videos\n",
    "for video_name in os.listdir(frames_dir):\n",
    "    video_frames_dir = os.path.join(frames_dir, video_name)\n",
    "    if os.path.isdir(video_frames_dir):\n",
    "        output_path = os.path.join(clip_features_dir, f\"{video_name}_clip.pt\")\n",
    "        extract_clip_features(video_frames_dir, output_path)\n",
    "        print(f\"CLIP features extracted for {video_name}\")\n",
    "\n",
    "print(\"CLIP feature extraction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keypoint 11 at frame 1, skipping.\n",
      "Missing keypoint 11 at frame 2, skipping.\n",
      "Missing keypoint 11 at frame 3, skipping.\n",
      "Missing keypoint 11 at frame 4, skipping.\n",
      "Missing keypoint 11 at frame 5, skipping.\n",
      "Missing keypoint 11 at frame 6, skipping.\n",
      "Missing keypoint 11 at frame 7, skipping.\n",
      "Missing keypoint 11 at frame 8, skipping.\n",
      "Missing keypoint 11 at frame 9, skipping.\n",
      "Missing keypoint 11 at frame 10, skipping.\n",
      "Missing keypoint 11 at frame 11, skipping.\n",
      "Missing keypoint 11 at frame 12, skipping.\n",
      "Missing keypoint 11 at frame 13, skipping.\n",
      "Missing keypoint 11 at frame 14, skipping.\n",
      "Missing keypoint 11 at frame 15, skipping.\n",
      "Missing keypoint 11 at frame 16, skipping.\n",
      "Missing keypoint 11 at frame 17, skipping.\n",
      "Missing keypoint 11 at frame 18, skipping.\n",
      "Missing keypoint 11 at frame 19, skipping.\n",
      "Missing keypoint 11 at frame 20, skipping.\n",
      "Missing keypoint 11 at frame 21, skipping.\n",
      "Missing keypoint 11 at frame 22, skipping.\n",
      "Missing keypoint 11 at frame 23, skipping.\n",
      "Missing keypoint 11 at frame 24, skipping.\n",
      "Missing keypoint 11 at frame 25, skipping.\n",
      "Missing keypoint 11 at frame 26, skipping.\n",
      "Missing keypoint 31 at frame 1, skipping.\n",
      "Missing keypoint 31 at frame 2, skipping.\n",
      "Missing keypoint 31 at frame 3, skipping.\n",
      "Missing keypoint 31 at frame 4, skipping.\n",
      "Missing keypoint 31 at frame 5, skipping.\n",
      "Missing keypoint 31 at frame 6, skipping.\n",
      "Missing keypoint 31 at frame 7, skipping.\n",
      "Missing keypoint 31 at frame 8, skipping.\n",
      "Missing keypoint 31 at frame 9, skipping.\n",
      "Missing keypoint 31 at frame 10, skipping.\n",
      "Missing keypoint 31 at frame 11, skipping.\n",
      "Missing keypoint 31 at frame 12, skipping.\n",
      "Missing keypoint 31 at frame 13, skipping.\n",
      "Missing keypoint 31 at frame 14, skipping.\n",
      "Missing keypoint 31 at frame 15, skipping.\n",
      "Missing keypoint 31 at frame 16, skipping.\n",
      "Missing keypoint 31 at frame 17, skipping.\n",
      "Missing keypoint 31 at frame 18, skipping.\n",
      "Missing keypoint 31 at frame 19, skipping.\n",
      "Missing keypoint 31 at frame 20, skipping.\n",
      "Missing keypoint 31 at frame 21, skipping.\n",
      "Missing keypoint 31 at frame 22, skipping.\n",
      "Missing keypoint 31 at frame 23, skipping.\n",
      "Missing keypoint 31 at frame 24, skipping.\n",
      "Missing keypoint 31 at frame 25, skipping.\n",
      "Missing keypoint 31 at frame 26, skipping.\n",
      "Combined features saved for 0_user3\n",
      "Missing keypoint 11 at frame 1, skipping.\n",
      "Missing keypoint 11 at frame 2, skipping.\n",
      "Missing keypoint 11 at frame 3, skipping.\n",
      "Missing keypoint 11 at frame 4, skipping.\n",
      "Missing keypoint 31 at frame 1, skipping.\n",
      "Missing keypoint 31 at frame 2, skipping.\n",
      "Missing keypoint 31 at frame 3, skipping.\n",
      "Missing keypoint 31 at frame 4, skipping.\n",
      "Combined features saved for 1_user7\n",
      "Missing keypoint 11 at frame 1, skipping.\n",
      "Missing keypoint 11 at frame 2, skipping.\n",
      "Missing keypoint 11 at frame 3, skipping.\n",
      "Missing keypoint 11 at frame 4, skipping.\n",
      "Missing keypoint 11 at frame 5, skipping.\n",
      "Missing keypoint 11 at frame 6, skipping.\n",
      "Missing keypoint 11 at frame 7, skipping.\n",
      "Missing keypoint 11 at frame 8, skipping.\n",
      "Missing keypoint 31 at frame 1, skipping.\n",
      "Missing keypoint 31 at frame 2, skipping.\n",
      "Missing keypoint 31 at frame 3, skipping.\n",
      "Missing keypoint 31 at frame 4, skipping.\n",
      "Missing keypoint 31 at frame 5, skipping.\n",
      "Missing keypoint 31 at frame 6, skipping.\n",
      "Missing keypoint 31 at frame 7, skipping.\n",
      "Missing keypoint 31 at frame 8, skipping.\n",
      "Combined features saved for 1_user8\n",
      "Missing keypoint 11 at frame 1, skipping.\n",
      "Missing keypoint 11 at frame 2, skipping.\n",
      "Missing keypoint 11 at frame 3, skipping.\n",
      "Missing keypoint 11 at frame 4, skipping.\n",
      "Missing keypoint 11 at frame 5, skipping.\n",
      "Missing keypoint 11 at frame 6, skipping.\n",
      "Missing keypoint 11 at frame 7, skipping.\n",
      "Missing keypoint 11 at frame 8, skipping.\n",
      "Missing keypoint 11 at frame 9, skipping.\n",
      "Missing keypoint 11 at frame 10, skipping.\n",
      "Missing keypoint 11 at frame 11, skipping.\n",
      "Missing keypoint 11 at frame 12, skipping.\n",
      "Missing keypoint 11 at frame 13, skipping.\n",
      "Missing keypoint 11 at frame 14, skipping.\n",
      "Missing keypoint 11 at frame 15, skipping.\n",
      "Missing keypoint 11 at frame 16, skipping.\n",
      "Missing keypoint 11 at frame 17, skipping.\n",
      "Missing keypoint 11 at frame 18, skipping.\n",
      "Missing keypoint 11 at frame 19, skipping.\n",
      "Missing keypoint 11 at frame 20, skipping.\n",
      "Missing keypoint 11 at frame 21, skipping.\n",
      "Missing keypoint 11 at frame 22, skipping.\n",
      "Missing keypoint 11 at frame 23, skipping.\n",
      "Missing keypoint 11 at frame 24, skipping.\n",
      "Missing keypoint 11 at frame 25, skipping.\n",
      "Missing keypoint 11 at frame 26, skipping.\n",
      "Missing keypoint 11 at frame 27, skipping.\n",
      "Missing keypoint 11 at frame 28, skipping.\n",
      "Missing keypoint 11 at frame 29, skipping.\n",
      "Missing keypoint 11 at frame 30, skipping.\n",
      "Missing keypoint 11 at frame 31, skipping.\n",
      "Missing keypoint 11 at frame 32, skipping.\n",
      "Missing keypoint 11 at frame 33, skipping.\n",
      "Missing keypoint 11 at frame 34, skipping.\n",
      "Missing keypoint 11 at frame 35, skipping.\n",
      "Missing keypoint 11 at frame 36, skipping.\n",
      "Missing keypoint 11 at frame 37, skipping.\n",
      "Missing keypoint 11 at frame 38, skipping.\n",
      "Missing keypoint 11 at frame 39, skipping.\n",
      "Missing keypoint 11 at frame 40, skipping.\n",
      "Missing keypoint 11 at frame 41, skipping.\n",
      "Missing keypoint 11 at frame 42, skipping.\n",
      "Missing keypoint 11 at frame 43, skipping.\n",
      "Missing keypoint 11 at frame 44, skipping.\n",
      "Missing keypoint 11 at frame 45, skipping.\n",
      "Missing keypoint 11 at frame 46, skipping.\n",
      "Missing keypoint 11 at frame 47, skipping.\n",
      "Missing keypoint 11 at frame 48, skipping.\n",
      "Missing keypoint 11 at frame 49, skipping.\n",
      "Missing keypoint 11 at frame 50, skipping.\n",
      "Missing keypoint 11 at frame 51, skipping.\n",
      "Missing keypoint 11 at frame 52, skipping.\n",
      "Missing keypoint 11 at frame 53, skipping.\n",
      "Missing keypoint 11 at frame 54, skipping.\n",
      "Missing keypoint 11 at frame 55, skipping.\n",
      "Missing keypoint 11 at frame 56, skipping.\n",
      "Missing keypoint 11 at frame 57, skipping.\n",
      "Missing keypoint 11 at frame 58, skipping.\n",
      "Missing keypoint 11 at frame 59, skipping.\n",
      "Missing keypoint 11 at frame 60, skipping.\n",
      "Missing keypoint 11 at frame 61, skipping.\n",
      "Missing keypoint 11 at frame 62, skipping.\n",
      "Missing keypoint 11 at frame 63, skipping.\n",
      "Missing keypoint 11 at frame 64, skipping.\n",
      "Missing keypoint 11 at frame 65, skipping.\n",
      "Missing keypoint 11 at frame 66, skipping.\n",
      "Missing keypoint 11 at frame 67, skipping.\n",
      "Missing keypoint 11 at frame 68, skipping.\n",
      "Missing keypoint 11 at frame 69, skipping.\n",
      "Missing keypoint 11 at frame 70, skipping.\n",
      "Missing keypoint 11 at frame 71, skipping.\n",
      "Missing keypoint 11 at frame 72, skipping.\n",
      "Missing keypoint 11 at frame 73, skipping.\n",
      "Missing keypoint 11 at frame 74, skipping.\n",
      "Missing keypoint 11 at frame 75, skipping.\n",
      "Missing keypoint 11 at frame 76, skipping.\n",
      "Missing keypoint 11 at frame 77, skipping.\n",
      "Missing keypoint 11 at frame 78, skipping.\n",
      "Missing keypoint 11 at frame 79, skipping.\n",
      "Missing keypoint 11 at frame 80, skipping.\n",
      "Missing keypoint 11 at frame 81, skipping.\n",
      "Missing keypoint 11 at frame 82, skipping.\n",
      "Missing keypoint 11 at frame 83, skipping.\n",
      "Missing keypoint 11 at frame 84, skipping.\n",
      "Missing keypoint 11 at frame 85, skipping.\n",
      "Missing keypoint 11 at frame 86, skipping.\n",
      "Missing keypoint 11 at frame 87, skipping.\n",
      "Missing keypoint 11 at frame 88, skipping.\n",
      "Missing keypoint 11 at frame 89, skipping.\n",
      "Missing keypoint 11 at frame 90, skipping.\n",
      "Missing keypoint 11 at frame 91, skipping.\n",
      "Missing keypoint 11 at frame 92, skipping.\n",
      "Missing keypoint 11 at frame 93, skipping.\n",
      "Missing keypoint 11 at frame 94, skipping.\n",
      "Missing keypoint 11 at frame 95, skipping.\n",
      "Missing keypoint 11 at frame 96, skipping.\n",
      "Missing keypoint 11 at frame 97, skipping.\n",
      "Missing keypoint 11 at frame 98, skipping.\n",
      "Missing keypoint 11 at frame 99, skipping.\n",
      "Missing keypoint 11 at frame 100, skipping.\n",
      "Missing keypoint 11 at frame 101, skipping.\n",
      "Missing keypoint 11 at frame 102, skipping.\n",
      "Missing keypoint 11 at frame 103, skipping.\n",
      "Missing keypoint 11 at frame 104, skipping.\n",
      "Missing keypoint 11 at frame 105, skipping.\n",
      "Missing keypoint 11 at frame 106, skipping.\n",
      "Missing keypoint 11 at frame 107, skipping.\n",
      "Missing keypoint 11 at frame 108, skipping.\n",
      "Missing keypoint 11 at frame 109, skipping.\n",
      "Missing keypoint 11 at frame 110, skipping.\n",
      "Missing keypoint 11 at frame 111, skipping.\n",
      "Missing keypoint 11 at frame 112, skipping.\n",
      "Missing keypoint 11 at frame 113, skipping.\n",
      "Missing keypoint 11 at frame 114, skipping.\n",
      "Missing keypoint 11 at frame 115, skipping.\n",
      "Missing keypoint 11 at frame 116, skipping.\n",
      "Missing keypoint 11 at frame 117, skipping.\n",
      "Missing keypoint 11 at frame 118, skipping.\n",
      "Missing keypoint 11 at frame 119, skipping.\n",
      "Missing keypoint 11 at frame 120, skipping.\n",
      "Missing keypoint 11 at frame 121, skipping.\n",
      "Missing keypoint 11 at frame 122, skipping.\n",
      "Missing keypoint 11 at frame 123, skipping.\n",
      "Missing keypoint 11 at frame 124, skipping.\n",
      "Missing keypoint 11 at frame 125, skipping.\n",
      "Missing keypoint 11 at frame 126, skipping.\n",
      "Missing keypoint 11 at frame 127, skipping.\n",
      "Missing keypoint 11 at frame 128, skipping.\n",
      "Missing keypoint 11 at frame 129, skipping.\n",
      "Missing keypoint 11 at frame 130, skipping.\n",
      "Missing keypoint 11 at frame 131, skipping.\n",
      "Missing keypoint 31 at frame 1, skipping.\n",
      "Missing keypoint 31 at frame 2, skipping.\n",
      "Missing keypoint 31 at frame 3, skipping.\n",
      "Missing keypoint 31 at frame 4, skipping.\n",
      "Missing keypoint 31 at frame 5, skipping.\n",
      "Missing keypoint 31 at frame 6, skipping.\n",
      "Missing keypoint 31 at frame 7, skipping.\n",
      "Missing keypoint 31 at frame 8, skipping.\n",
      "Missing keypoint 31 at frame 9, skipping.\n",
      "Missing keypoint 31 at frame 10, skipping.\n",
      "Missing keypoint 31 at frame 11, skipping.\n",
      "Missing keypoint 31 at frame 12, skipping.\n",
      "Missing keypoint 31 at frame 13, skipping.\n",
      "Missing keypoint 31 at frame 14, skipping.\n",
      "Missing keypoint 31 at frame 15, skipping.\n",
      "Missing keypoint 31 at frame 16, skipping.\n",
      "Missing keypoint 31 at frame 17, skipping.\n",
      "Missing keypoint 31 at frame 18, skipping.\n",
      "Missing keypoint 31 at frame 19, skipping.\n",
      "Missing keypoint 31 at frame 20, skipping.\n",
      "Missing keypoint 31 at frame 21, skipping.\n",
      "Missing keypoint 31 at frame 22, skipping.\n",
      "Missing keypoint 31 at frame 23, skipping.\n",
      "Missing keypoint 31 at frame 24, skipping.\n",
      "Missing keypoint 31 at frame 25, skipping.\n",
      "Missing keypoint 31 at frame 26, skipping.\n",
      "Missing keypoint 31 at frame 27, skipping.\n",
      "Missing keypoint 31 at frame 28, skipping.\n",
      "Missing keypoint 31 at frame 29, skipping.\n",
      "Missing keypoint 31 at frame 30, skipping.\n",
      "Missing keypoint 31 at frame 31, skipping.\n",
      "Missing keypoint 31 at frame 32, skipping.\n",
      "Missing keypoint 31 at frame 33, skipping.\n",
      "Missing keypoint 31 at frame 34, skipping.\n",
      "Missing keypoint 31 at frame 35, skipping.\n",
      "Missing keypoint 31 at frame 36, skipping.\n",
      "Missing keypoint 31 at frame 37, skipping.\n",
      "Missing keypoint 31 at frame 38, skipping.\n",
      "Missing keypoint 31 at frame 39, skipping.\n",
      "Missing keypoint 31 at frame 40, skipping.\n",
      "Missing keypoint 31 at frame 41, skipping.\n",
      "Missing keypoint 31 at frame 42, skipping.\n",
      "Missing keypoint 31 at frame 43, skipping.\n",
      "Missing keypoint 31 at frame 44, skipping.\n",
      "Missing keypoint 31 at frame 45, skipping.\n",
      "Missing keypoint 31 at frame 46, skipping.\n",
      "Missing keypoint 31 at frame 47, skipping.\n",
      "Missing keypoint 31 at frame 48, skipping.\n",
      "Missing keypoint 31 at frame 49, skipping.\n",
      "Missing keypoint 31 at frame 50, skipping.\n",
      "Missing keypoint 31 at frame 51, skipping.\n",
      "Missing keypoint 31 at frame 52, skipping.\n",
      "Missing keypoint 31 at frame 53, skipping.\n",
      "Missing keypoint 31 at frame 54, skipping.\n",
      "Missing keypoint 31 at frame 55, skipping.\n",
      "Missing keypoint 31 at frame 56, skipping.\n",
      "Missing keypoint 31 at frame 57, skipping.\n",
      "Missing keypoint 31 at frame 58, skipping.\n",
      "Missing keypoint 31 at frame 59, skipping.\n",
      "Missing keypoint 31 at frame 60, skipping.\n",
      "Missing keypoint 31 at frame 61, skipping.\n",
      "Missing keypoint 31 at frame 62, skipping.\n",
      "Missing keypoint 31 at frame 63, skipping.\n",
      "Missing keypoint 31 at frame 64, skipping.\n",
      "Missing keypoint 31 at frame 65, skipping.\n",
      "Missing keypoint 31 at frame 66, skipping.\n",
      "Missing keypoint 31 at frame 67, skipping.\n",
      "Missing keypoint 31 at frame 68, skipping.\n",
      "Missing keypoint 31 at frame 69, skipping.\n",
      "Missing keypoint 31 at frame 70, skipping.\n",
      "Missing keypoint 31 at frame 71, skipping.\n",
      "Missing keypoint 31 at frame 72, skipping.\n",
      "Missing keypoint 31 at frame 73, skipping.\n",
      "Missing keypoint 31 at frame 74, skipping.\n",
      "Missing keypoint 31 at frame 75, skipping.\n",
      "Missing keypoint 31 at frame 76, skipping.\n",
      "Missing keypoint 31 at frame 77, skipping.\n",
      "Missing keypoint 31 at frame 78, skipping.\n",
      "Missing keypoint 31 at frame 79, skipping.\n",
      "Missing keypoint 31 at frame 80, skipping.\n",
      "Missing keypoint 31 at frame 81, skipping.\n",
      "Missing keypoint 31 at frame 82, skipping.\n",
      "Missing keypoint 31 at frame 83, skipping.\n",
      "Missing keypoint 31 at frame 84, skipping.\n",
      "Missing keypoint 31 at frame 85, skipping.\n",
      "Missing keypoint 31 at frame 86, skipping.\n",
      "Missing keypoint 31 at frame 87, skipping.\n",
      "Missing keypoint 31 at frame 88, skipping.\n",
      "Missing keypoint 31 at frame 89, skipping.\n",
      "Missing keypoint 31 at frame 90, skipping.\n",
      "Missing keypoint 31 at frame 91, skipping.\n",
      "Missing keypoint 31 at frame 92, skipping.\n",
      "Missing keypoint 31 at frame 93, skipping.\n",
      "Missing keypoint 31 at frame 94, skipping.\n",
      "Missing keypoint 31 at frame 95, skipping.\n",
      "Missing keypoint 31 at frame 96, skipping.\n",
      "Missing keypoint 31 at frame 97, skipping.\n",
      "Missing keypoint 31 at frame 98, skipping.\n",
      "Missing keypoint 31 at frame 99, skipping.\n",
      "Missing keypoint 31 at frame 100, skipping.\n",
      "Missing keypoint 31 at frame 101, skipping.\n",
      "Missing keypoint 31 at frame 102, skipping.\n",
      "Missing keypoint 31 at frame 103, skipping.\n",
      "Missing keypoint 31 at frame 104, skipping.\n",
      "Missing keypoint 31 at frame 105, skipping.\n",
      "Missing keypoint 31 at frame 106, skipping.\n",
      "Missing keypoint 31 at frame 107, skipping.\n",
      "Missing keypoint 31 at frame 108, skipping.\n",
      "Missing keypoint 31 at frame 109, skipping.\n",
      "Missing keypoint 31 at frame 110, skipping.\n",
      "Missing keypoint 31 at frame 111, skipping.\n",
      "Missing keypoint 31 at frame 112, skipping.\n",
      "Missing keypoint 31 at frame 113, skipping.\n",
      "Missing keypoint 31 at frame 114, skipping.\n",
      "Missing keypoint 31 at frame 115, skipping.\n",
      "Missing keypoint 31 at frame 116, skipping.\n",
      "Missing keypoint 31 at frame 117, skipping.\n",
      "Missing keypoint 31 at frame 118, skipping.\n",
      "Missing keypoint 31 at frame 119, skipping.\n",
      "Missing keypoint 31 at frame 120, skipping.\n",
      "Missing keypoint 31 at frame 121, skipping.\n",
      "Missing keypoint 31 at frame 122, skipping.\n",
      "Missing keypoint 31 at frame 123, skipping.\n",
      "Missing keypoint 31 at frame 124, skipping.\n",
      "Missing keypoint 31 at frame 125, skipping.\n",
      "Missing keypoint 31 at frame 126, skipping.\n",
      "Missing keypoint 31 at frame 127, skipping.\n",
      "Missing keypoint 31 at frame 128, skipping.\n",
      "Missing keypoint 31 at frame 129, skipping.\n",
      "Missing keypoint 31 at frame 130, skipping.\n",
      "Missing keypoint 31 at frame 131, skipping.\n",
      "Combined features saved for 1_user23\n",
      "Missing keypoint 11 at frame 1, skipping.\n",
      "Missing keypoint 11 at frame 2, skipping.\n",
      "Missing keypoint 11 at frame 3, skipping.\n",
      "Missing keypoint 11 at frame 4, skipping.\n",
      "Missing keypoint 11 at frame 5, skipping.\n",
      "Missing keypoint 11 at frame 6, skipping.\n",
      "Missing keypoint 11 at frame 7, skipping.\n",
      "Missing keypoint 11 at frame 8, skipping.\n",
      "Missing keypoint 11 at frame 9, skipping.\n",
      "Missing keypoint 11 at frame 10, skipping.\n",
      "Missing keypoint 11 at frame 11, skipping.\n",
      "Missing keypoint 11 at frame 12, skipping.\n",
      "Missing keypoint 11 at frame 13, skipping.\n",
      "Missing keypoint 11 at frame 14, skipping.\n",
      "Missing keypoint 11 at frame 15, skipping.\n",
      "Missing keypoint 31 at frame 1, skipping.\n",
      "Missing keypoint 31 at frame 2, skipping.\n",
      "Missing keypoint 31 at frame 3, skipping.\n",
      "Missing keypoint 31 at frame 4, skipping.\n",
      "Missing keypoint 31 at frame 5, skipping.\n",
      "Missing keypoint 31 at frame 6, skipping.\n",
      "Missing keypoint 31 at frame 7, skipping.\n",
      "Missing keypoint 31 at frame 8, skipping.\n",
      "Missing keypoint 31 at frame 9, skipping.\n",
      "Missing keypoint 31 at frame 10, skipping.\n",
      "Missing keypoint 31 at frame 11, skipping.\n",
      "Missing keypoint 31 at frame 12, skipping.\n",
      "Missing keypoint 31 at frame 13, skipping.\n",
      "Missing keypoint 31 at frame 14, skipping.\n",
      "Missing keypoint 31 at frame 15, skipping.\n",
      "Combined features saved for 1_user9\n",
      "Missing keypoint 11 at frame 1, skipping.\n",
      "Missing keypoint 11 at frame 2, skipping.\n",
      "Missing keypoint 11 at frame 3, skipping.\n",
      "Missing keypoint 11 at frame 4, skipping.\n",
      "Missing keypoint 11 at frame 5, skipping.\n",
      "Missing keypoint 11 at frame 6, skipping.\n",
      "Missing keypoint 11 at frame 7, skipping.\n",
      "Missing keypoint 11 at frame 8, skipping.\n",
      "Missing keypoint 11 at frame 9, skipping.\n",
      "Missing keypoint 11 at frame 10, skipping.\n",
      "Missing keypoint 11 at frame 11, skipping.\n",
      "Missing keypoint 11 at frame 12, skipping.\n",
      "Missing keypoint 11 at frame 13, skipping.\n",
      "Missing keypoint 11 at frame 14, skipping.\n",
      "Missing keypoint 11 at frame 15, skipping.\n",
      "Missing keypoint 11 at frame 16, skipping.\n",
      "Missing keypoint 11 at frame 17, skipping.\n",
      "Missing keypoint 11 at frame 18, skipping.\n",
      "Missing keypoint 11 at frame 19, skipping.\n",
      "Missing keypoint 11 at frame 20, skipping.\n",
      "Missing keypoint 11 at frame 21, skipping.\n",
      "Missing keypoint 11 at frame 22, skipping.\n",
      "Missing keypoint 11 at frame 23, skipping.\n",
      "Missing keypoint 11 at frame 24, skipping.\n",
      "Missing keypoint 11 at frame 25, skipping.\n",
      "Missing keypoint 11 at frame 26, skipping.\n",
      "Missing keypoint 11 at frame 27, skipping.\n",
      "Missing keypoint 11 at frame 28, skipping.\n",
      "Missing keypoint 11 at frame 29, skipping.\n",
      "Missing keypoint 11 at frame 30, skipping.\n",
      "Missing keypoint 11 at frame 31, skipping.\n",
      "Missing keypoint 11 at frame 32, skipping.\n",
      "Missing keypoint 11 at frame 33, skipping.\n",
      "Missing keypoint 11 at frame 34, skipping.\n",
      "Missing keypoint 11 at frame 35, skipping.\n",
      "Missing keypoint 11 at frame 36, skipping.\n",
      "Missing keypoint 11 at frame 37, skipping.\n",
      "Missing keypoint 11 at frame 38, skipping.\n",
      "Missing keypoint 11 at frame 39, skipping.\n",
      "Missing keypoint 11 at frame 40, skipping.\n",
      "Missing keypoint 11 at frame 41, skipping.\n",
      "Missing keypoint 11 at frame 42, skipping.\n",
      "Missing keypoint 11 at frame 43, skipping.\n",
      "Missing keypoint 11 at frame 44, skipping.\n",
      "Missing keypoint 11 at frame 45, skipping.\n",
      "Missing keypoint 11 at frame 46, skipping.\n",
      "Missing keypoint 11 at frame 47, skipping.\n",
      "Missing keypoint 11 at frame 48, skipping.\n",
      "Missing keypoint 11 at frame 49, skipping.\n",
      "Missing keypoint 11 at frame 50, skipping.\n",
      "Missing keypoint 11 at frame 51, skipping.\n",
      "Missing keypoint 11 at frame 52, skipping.\n",
      "Missing keypoint 11 at frame 53, skipping.\n",
      "Missing keypoint 11 at frame 54, skipping.\n",
      "Missing keypoint 11 at frame 55, skipping.\n",
      "Missing keypoint 31 at frame 1, skipping.\n",
      "Missing keypoint 31 at frame 2, skipping.\n",
      "Missing keypoint 31 at frame 3, skipping.\n",
      "Missing keypoint 31 at frame 4, skipping.\n",
      "Missing keypoint 31 at frame 5, skipping.\n",
      "Missing keypoint 31 at frame 6, skipping.\n",
      "Missing keypoint 31 at frame 7, skipping.\n",
      "Missing keypoint 31 at frame 8, skipping.\n",
      "Missing keypoint 31 at frame 9, skipping.\n",
      "Missing keypoint 31 at frame 10, skipping.\n",
      "Missing keypoint 31 at frame 11, skipping.\n",
      "Missing keypoint 31 at frame 12, skipping.\n",
      "Missing keypoint 31 at frame 13, skipping.\n",
      "Missing keypoint 31 at frame 14, skipping.\n",
      "Missing keypoint 31 at frame 15, skipping.\n",
      "Missing keypoint 31 at frame 16, skipping.\n",
      "Missing keypoint 31 at frame 17, skipping.\n",
      "Missing keypoint 31 at frame 18, skipping.\n",
      "Missing keypoint 31 at frame 19, skipping.\n",
      "Missing keypoint 31 at frame 20, skipping.\n",
      "Missing keypoint 31 at frame 21, skipping.\n",
      "Missing keypoint 31 at frame 22, skipping.\n",
      "Missing keypoint 31 at frame 23, skipping.\n",
      "Missing keypoint 31 at frame 24, skipping.\n",
      "Missing keypoint 31 at frame 25, skipping.\n",
      "Missing keypoint 31 at frame 26, skipping.\n",
      "Missing keypoint 31 at frame 27, skipping.\n",
      "Missing keypoint 31 at frame 28, skipping.\n",
      "Missing keypoint 31 at frame 29, skipping.\n",
      "Missing keypoint 31 at frame 30, skipping.\n",
      "Missing keypoint 31 at frame 31, skipping.\n",
      "Missing keypoint 31 at frame 32, skipping.\n",
      "Missing keypoint 31 at frame 33, skipping.\n",
      "Missing keypoint 31 at frame 34, skipping.\n",
      "Missing keypoint 31 at frame 35, skipping.\n",
      "Missing keypoint 31 at frame 36, skipping.\n",
      "Missing keypoint 31 at frame 37, skipping.\n",
      "Missing keypoint 31 at frame 38, skipping.\n",
      "Missing keypoint 31 at frame 39, skipping.\n",
      "Missing keypoint 31 at frame 40, skipping.\n",
      "Missing keypoint 31 at frame 41, skipping.\n",
      "Missing keypoint 31 at frame 42, skipping.\n",
      "Missing keypoint 31 at frame 43, skipping.\n",
      "Missing keypoint 31 at frame 44, skipping.\n",
      "Missing keypoint 31 at frame 45, skipping.\n",
      "Missing keypoint 31 at frame 46, skipping.\n",
      "Missing keypoint 31 at frame 47, skipping.\n",
      "Missing keypoint 31 at frame 48, skipping.\n",
      "Missing keypoint 31 at frame 49, skipping.\n",
      "Missing keypoint 31 at frame 50, skipping.\n",
      "Missing keypoint 31 at frame 51, skipping.\n",
      "Missing keypoint 31 at frame 52, skipping.\n",
      "Missing keypoint 31 at frame 53, skipping.\n",
      "Missing keypoint 31 at frame 54, skipping.\n",
      "Missing keypoint 31 at frame 55, skipping.\n",
      "Combined features saved for 0_user10\n",
      "Missing keypoint 11 at frame 1, skipping.\n",
      "Missing keypoint 11 at frame 2, skipping.\n",
      "Missing keypoint 11 at frame 3, skipping.\n",
      "Missing keypoint 11 at frame 4, skipping.\n",
      "Missing keypoint 11 at frame 5, skipping.\n",
      "Missing keypoint 11 at frame 6, skipping.\n",
      "Missing keypoint 11 at frame 7, skipping.\n",
      "Missing keypoint 11 at frame 8, skipping.\n",
      "Missing keypoint 11 at frame 9, skipping.\n",
      "Missing keypoint 11 at frame 10, skipping.\n",
      "Missing keypoint 11 at frame 11, skipping.\n",
      "Missing keypoint 11 at frame 12, skipping.\n",
      "Missing keypoint 11 at frame 13, skipping.\n",
      "Missing keypoint 11 at frame 14, skipping.\n",
      "Missing keypoint 11 at frame 15, skipping.\n",
      "Missing keypoint 11 at frame 16, skipping.\n",
      "Missing keypoint 11 at frame 17, skipping.\n",
      "Missing keypoint 11 at frame 18, skipping.\n",
      "Missing keypoint 11 at frame 19, skipping.\n",
      "Missing keypoint 11 at frame 20, skipping.\n",
      "Missing keypoint 11 at frame 21, skipping.\n",
      "Missing keypoint 11 at frame 22, skipping.\n",
      "Missing keypoint 11 at frame 23, skipping.\n",
      "Missing keypoint 11 at frame 24, skipping.\n",
      "Missing keypoint 11 at frame 25, skipping.\n",
      "Missing keypoint 11 at frame 26, skipping.\n",
      "Missing keypoint 11 at frame 27, skipping.\n",
      "Missing keypoint 11 at frame 28, skipping.\n",
      "Missing keypoint 11 at frame 29, skipping.\n",
      "Missing keypoint 11 at frame 30, skipping.\n",
      "Missing keypoint 11 at frame 31, skipping.\n",
      "Missing keypoint 11 at frame 32, skipping.\n",
      "Missing keypoint 11 at frame 33, skipping.\n",
      "Missing keypoint 11 at frame 34, skipping.\n",
      "Missing keypoint 31 at frame 1, skipping.\n",
      "Missing keypoint 31 at frame 2, skipping.\n",
      "Missing keypoint 31 at frame 3, skipping.\n",
      "Missing keypoint 31 at frame 4, skipping.\n",
      "Missing keypoint 31 at frame 5, skipping.\n",
      "Missing keypoint 31 at frame 6, skipping.\n",
      "Missing keypoint 31 at frame 7, skipping.\n",
      "Missing keypoint 31 at frame 8, skipping.\n",
      "Missing keypoint 31 at frame 9, skipping.\n",
      "Missing keypoint 31 at frame 10, skipping.\n",
      "Missing keypoint 31 at frame 11, skipping.\n",
      "Missing keypoint 31 at frame 12, skipping.\n",
      "Missing keypoint 31 at frame 13, skipping.\n",
      "Missing keypoint 31 at frame 14, skipping.\n",
      "Missing keypoint 31 at frame 15, skipping.\n",
      "Missing keypoint 31 at frame 16, skipping.\n",
      "Missing keypoint 31 at frame 17, skipping.\n",
      "Missing keypoint 31 at frame 18, skipping.\n",
      "Missing keypoint 31 at frame 19, skipping.\n",
      "Missing keypoint 31 at frame 20, skipping.\n",
      "Missing keypoint 31 at frame 21, skipping.\n",
      "Missing keypoint 31 at frame 22, skipping.\n",
      "Missing keypoint 31 at frame 23, skipping.\n",
      "Missing keypoint 31 at frame 24, skipping.\n",
      "Missing keypoint 31 at frame 25, skipping.\n",
      "Missing keypoint 31 at frame 26, skipping.\n",
      "Missing keypoint 31 at frame 27, skipping.\n",
      "Missing keypoint 31 at frame 28, skipping.\n",
      "Missing keypoint 31 at frame 29, skipping.\n",
      "Missing keypoint 31 at frame 30, skipping.\n",
      "Missing keypoint 31 at frame 31, skipping.\n",
      "Missing keypoint 31 at frame 32, skipping.\n",
      "Missing keypoint 31 at frame 33, skipping.\n",
      "Missing keypoint 31 at frame 34, skipping.\n",
      "Combined features saved for 1_user21\n",
      "Missing keypoint 11 at frame 1, skipping.\n",
      "Missing keypoint 11 at frame 2, skipping.\n",
      "Missing keypoint 11 at frame 3, skipping.\n",
      "Missing keypoint 11 at frame 4, skipping.\n",
      "Missing keypoint 11 at frame 5, skipping.\n",
      "Missing keypoint 11 at frame 6, skipping.\n",
      "Missing keypoint 11 at frame 7, skipping.\n",
      "Missing keypoint 11 at frame 8, skipping.\n",
      "Missing keypoint 11 at frame 9, skipping.\n",
      "Missing keypoint 11 at frame 10, skipping.\n",
      "Missing keypoint 11 at frame 11, skipping.\n",
      "Missing keypoint 11 at frame 12, skipping.\n",
      "Missing keypoint 11 at frame 13, skipping.\n",
      "Missing keypoint 11 at frame 14, skipping.\n",
      "Missing keypoint 11 at frame 15, skipping.\n",
      "Missing keypoint 11 at frame 16, skipping.\n",
      "Missing keypoint 11 at frame 17, skipping.\n",
      "Missing keypoint 11 at frame 18, skipping.\n",
      "Missing keypoint 11 at frame 19, skipping.\n",
      "Missing keypoint 11 at frame 20, skipping.\n",
      "Missing keypoint 11 at frame 21, skipping.\n",
      "Missing keypoint 11 at frame 22, skipping.\n",
      "Missing keypoint 11 at frame 23, skipping.\n",
      "Missing keypoint 11 at frame 24, skipping.\n",
      "Missing keypoint 11 at frame 25, skipping.\n",
      "Missing keypoint 11 at frame 26, skipping.\n",
      "Missing keypoint 11 at frame 27, skipping.\n",
      "Missing keypoint 11 at frame 28, skipping.\n",
      "Missing keypoint 11 at frame 29, skipping.\n",
      "Missing keypoint 11 at frame 30, skipping.\n",
      "Missing keypoint 11 at frame 31, skipping.\n",
      "Missing keypoint 11 at frame 32, skipping.\n",
      "Missing keypoint 11 at frame 33, skipping.\n",
      "Missing keypoint 11 at frame 34, skipping.\n",
      "Missing keypoint 11 at frame 35, skipping.\n",
      "Missing keypoint 31 at frame 1, skipping.\n",
      "Missing keypoint 31 at frame 2, skipping.\n",
      "Missing keypoint 31 at frame 3, skipping.\n",
      "Missing keypoint 31 at frame 4, skipping.\n",
      "Missing keypoint 31 at frame 5, skipping.\n",
      "Missing keypoint 31 at frame 6, skipping.\n",
      "Missing keypoint 31 at frame 7, skipping.\n",
      "Missing keypoint 31 at frame 8, skipping.\n",
      "Missing keypoint 31 at frame 9, skipping.\n",
      "Missing keypoint 31 at frame 10, skipping.\n",
      "Missing keypoint 31 at frame 11, skipping.\n",
      "Missing keypoint 31 at frame 12, skipping.\n",
      "Missing keypoint 31 at frame 13, skipping.\n",
      "Missing keypoint 31 at frame 14, skipping.\n",
      "Missing keypoint 31 at frame 15, skipping.\n",
      "Missing keypoint 31 at frame 16, skipping.\n",
      "Missing keypoint 31 at frame 17, skipping.\n",
      "Missing keypoint 31 at frame 18, skipping.\n",
      "Missing keypoint 31 at frame 19, skipping.\n",
      "Missing keypoint 31 at frame 20, skipping.\n",
      "Missing keypoint 31 at frame 21, skipping.\n",
      "Missing keypoint 31 at frame 22, skipping.\n",
      "Missing keypoint 31 at frame 23, skipping.\n",
      "Missing keypoint 31 at frame 24, skipping.\n",
      "Missing keypoint 31 at frame 25, skipping.\n",
      "Missing keypoint 31 at frame 26, skipping.\n",
      "Missing keypoint 31 at frame 27, skipping.\n",
      "Missing keypoint 31 at frame 28, skipping.\n",
      "Missing keypoint 31 at frame 29, skipping.\n",
      "Missing keypoint 31 at frame 30, skipping.\n",
      "Missing keypoint 31 at frame 31, skipping.\n",
      "Missing keypoint 31 at frame 32, skipping.\n",
      "Missing keypoint 31 at frame 33, skipping.\n",
      "Missing keypoint 31 at frame 34, skipping.\n",
      "Missing keypoint 31 at frame 35, skipping.\n",
      "Combined features saved for 1_user2\n",
      "Missing keypoint 11 at frame 1, skipping.\n",
      "Missing keypoint 11 at frame 2, skipping.\n",
      "Missing keypoint 11 at frame 3, skipping.\n",
      "Missing keypoint 11 at frame 4, skipping.\n",
      "Missing keypoint 11 at frame 5, skipping.\n",
      "Missing keypoint 11 at frame 6, skipping.\n",
      "Missing keypoint 11 at frame 7, skipping.\n",
      "Missing keypoint 11 at frame 8, skipping.\n",
      "Missing keypoint 11 at frame 9, skipping.\n",
      "Missing keypoint 11 at frame 10, skipping.\n",
      "Missing keypoint 11 at frame 11, skipping.\n",
      "Missing keypoint 11 at frame 12, skipping.\n",
      "Missing keypoint 11 at frame 13, skipping.\n",
      "Missing keypoint 11 at frame 14, skipping.\n",
      "Missing keypoint 11 at frame 15, skipping.\n",
      "Missing keypoint 11 at frame 16, skipping.\n",
      "Missing keypoint 11 at frame 17, skipping.\n",
      "Missing keypoint 11 at frame 18, skipping.\n",
      "Missing keypoint 11 at frame 19, skipping.\n",
      "Missing keypoint 11 at frame 20, skipping.\n",
      "Missing keypoint 11 at frame 21, skipping.\n",
      "Missing keypoint 11 at frame 22, skipping.\n",
      "Missing keypoint 11 at frame 23, skipping.\n",
      "Missing keypoint 11 at frame 24, skipping.\n",
      "Missing keypoint 11 at frame 25, skipping.\n",
      "Missing keypoint 11 at frame 26, skipping.\n",
      "Missing keypoint 11 at frame 27, skipping.\n",
      "Missing keypoint 11 at frame 28, skipping.\n",
      "Missing keypoint 31 at frame 1, skipping.\n",
      "Missing keypoint 31 at frame 2, skipping.\n",
      "Missing keypoint 31 at frame 3, skipping.\n",
      "Missing keypoint 31 at frame 4, skipping.\n",
      "Missing keypoint 31 at frame 5, skipping.\n",
      "Missing keypoint 31 at frame 6, skipping.\n",
      "Missing keypoint 31 at frame 7, skipping.\n",
      "Missing keypoint 31 at frame 8, skipping.\n",
      "Missing keypoint 31 at frame 9, skipping.\n",
      "Missing keypoint 31 at frame 10, skipping.\n",
      "Missing keypoint 31 at frame 11, skipping.\n",
      "Missing keypoint 31 at frame 12, skipping.\n",
      "Missing keypoint 31 at frame 13, skipping.\n",
      "Missing keypoint 31 at frame 14, skipping.\n",
      "Missing keypoint 31 at frame 15, skipping.\n",
      "Missing keypoint 31 at frame 16, skipping.\n",
      "Missing keypoint 31 at frame 17, skipping.\n",
      "Missing keypoint 31 at frame 18, skipping.\n",
      "Missing keypoint 31 at frame 19, skipping.\n",
      "Missing keypoint 31 at frame 20, skipping.\n",
      "Missing keypoint 31 at frame 21, skipping.\n",
      "Missing keypoint 31 at frame 22, skipping.\n",
      "Missing keypoint 31 at frame 23, skipping.\n",
      "Missing keypoint 31 at frame 24, skipping.\n",
      "Missing keypoint 31 at frame 25, skipping.\n",
      "Missing keypoint 31 at frame 26, skipping.\n",
      "Missing keypoint 31 at frame 27, skipping.\n",
      "Missing keypoint 31 at frame 28, skipping.\n",
      "Combined features saved for 0_user1\n",
      "Missing keypoint 11 at frame 1, skipping.\n",
      "Missing keypoint 11 at frame 2, skipping.\n",
      "Missing keypoint 11 at frame 3, skipping.\n",
      "Missing keypoint 11 at frame 4, skipping.\n",
      "Missing keypoint 11 at frame 5, skipping.\n",
      "Missing keypoint 11 at frame 6, skipping.\n",
      "Missing keypoint 11 at frame 7, skipping.\n",
      "Missing keypoint 11 at frame 8, skipping.\n",
      "Missing keypoint 11 at frame 9, skipping.\n",
      "Missing keypoint 11 at frame 10, skipping.\n",
      "Missing keypoint 11 at frame 11, skipping.\n",
      "Missing keypoint 11 at frame 12, skipping.\n",
      "Missing keypoint 11 at frame 13, skipping.\n",
      "Missing keypoint 11 at frame 14, skipping.\n",
      "Missing keypoint 11 at frame 15, skipping.\n",
      "Missing keypoint 11 at frame 16, skipping.\n",
      "Missing keypoint 11 at frame 17, skipping.\n",
      "Missing keypoint 11 at frame 18, skipping.\n",
      "Missing keypoint 11 at frame 19, skipping.\n",
      "Missing keypoint 11 at frame 20, skipping.\n",
      "Missing keypoint 11 at frame 21, skipping.\n",
      "Missing keypoint 11 at frame 22, skipping.\n",
      "Missing keypoint 11 at frame 23, skipping.\n",
      "Missing keypoint 11 at frame 24, skipping.\n",
      "Missing keypoint 11 at frame 25, skipping.\n",
      "Missing keypoint 11 at frame 26, skipping.\n",
      "Missing keypoint 11 at frame 27, skipping.\n",
      "Missing keypoint 31 at frame 1, skipping.\n",
      "Missing keypoint 31 at frame 2, skipping.\n",
      "Missing keypoint 31 at frame 3, skipping.\n",
      "Missing keypoint 31 at frame 4, skipping.\n",
      "Missing keypoint 31 at frame 5, skipping.\n",
      "Missing keypoint 31 at frame 6, skipping.\n",
      "Missing keypoint 31 at frame 7, skipping.\n",
      "Missing keypoint 31 at frame 8, skipping.\n",
      "Missing keypoint 31 at frame 9, skipping.\n",
      "Missing keypoint 31 at frame 10, skipping.\n",
      "Missing keypoint 31 at frame 11, skipping.\n",
      "Missing keypoint 31 at frame 12, skipping.\n",
      "Missing keypoint 31 at frame 13, skipping.\n",
      "Missing keypoint 31 at frame 14, skipping.\n",
      "Missing keypoint 31 at frame 15, skipping.\n",
      "Missing keypoint 31 at frame 16, skipping.\n",
      "Missing keypoint 31 at frame 17, skipping.\n",
      "Missing keypoint 31 at frame 18, skipping.\n",
      "Missing keypoint 31 at frame 19, skipping.\n",
      "Missing keypoint 31 at frame 20, skipping.\n",
      "Missing keypoint 31 at frame 21, skipping.\n",
      "Missing keypoint 31 at frame 22, skipping.\n",
      "Missing keypoint 31 at frame 23, skipping.\n",
      "Missing keypoint 31 at frame 24, skipping.\n",
      "Missing keypoint 31 at frame 25, skipping.\n",
      "Missing keypoint 31 at frame 26, skipping.\n",
      "Missing keypoint 31 at frame 27, skipping.\n",
      "Combined features saved for 1_user5\n",
      "Missing keypoint 11 at frame 1, skipping.\n",
      "Missing keypoint 11 at frame 2, skipping.\n",
      "Missing keypoint 11 at frame 3, skipping.\n",
      "Missing keypoint 11 at frame 4, skipping.\n",
      "Missing keypoint 11 at frame 5, skipping.\n",
      "Missing keypoint 11 at frame 6, skipping.\n",
      "Missing keypoint 11 at frame 7, skipping.\n",
      "Missing keypoint 11 at frame 8, skipping.\n",
      "Missing keypoint 11 at frame 9, skipping.\n",
      "Missing keypoint 11 at frame 10, skipping.\n",
      "Missing keypoint 11 at frame 11, skipping.\n",
      "Missing keypoint 11 at frame 12, skipping.\n",
      "Missing keypoint 11 at frame 13, skipping.\n",
      "Missing keypoint 11 at frame 14, skipping.\n",
      "Missing keypoint 11 at frame 15, skipping.\n",
      "Missing keypoint 11 at frame 16, skipping.\n",
      "Missing keypoint 11 at frame 17, skipping.\n",
      "Missing keypoint 11 at frame 18, skipping.\n",
      "Missing keypoint 11 at frame 19, skipping.\n",
      "Missing keypoint 11 at frame 20, skipping.\n",
      "Missing keypoint 11 at frame 21, skipping.\n",
      "Missing keypoint 11 at frame 22, skipping.\n",
      "Missing keypoint 11 at frame 23, skipping.\n",
      "Missing keypoint 11 at frame 24, skipping.\n",
      "Missing keypoint 11 at frame 25, skipping.\n",
      "Missing keypoint 11 at frame 26, skipping.\n",
      "Missing keypoint 11 at frame 27, skipping.\n",
      "Missing keypoint 11 at frame 28, skipping.\n",
      "Missing keypoint 11 at frame 29, skipping.\n",
      "Missing keypoint 11 at frame 30, skipping.\n",
      "Missing keypoint 11 at frame 31, skipping.\n",
      "Missing keypoint 11 at frame 32, skipping.\n",
      "Missing keypoint 11 at frame 33, skipping.\n",
      "Missing keypoint 11 at frame 34, skipping.\n",
      "Missing keypoint 11 at frame 35, skipping.\n",
      "Missing keypoint 11 at frame 36, skipping.\n",
      "Missing keypoint 11 at frame 37, skipping.\n",
      "Missing keypoint 11 at frame 38, skipping.\n",
      "Missing keypoint 11 at frame 39, skipping.\n",
      "Missing keypoint 11 at frame 40, skipping.\n",
      "Missing keypoint 11 at frame 41, skipping.\n",
      "Missing keypoint 11 at frame 42, skipping.\n",
      "Missing keypoint 31 at frame 1, skipping.\n",
      "Missing keypoint 31 at frame 2, skipping.\n",
      "Missing keypoint 31 at frame 3, skipping.\n",
      "Missing keypoint 31 at frame 4, skipping.\n",
      "Missing keypoint 31 at frame 5, skipping.\n",
      "Missing keypoint 31 at frame 6, skipping.\n",
      "Missing keypoint 31 at frame 7, skipping.\n",
      "Missing keypoint 31 at frame 8, skipping.\n",
      "Missing keypoint 31 at frame 9, skipping.\n",
      "Missing keypoint 31 at frame 10, skipping.\n",
      "Missing keypoint 31 at frame 11, skipping.\n",
      "Missing keypoint 31 at frame 12, skipping.\n",
      "Missing keypoint 31 at frame 13, skipping.\n",
      "Missing keypoint 31 at frame 14, skipping.\n",
      "Missing keypoint 31 at frame 15, skipping.\n",
      "Missing keypoint 31 at frame 16, skipping.\n",
      "Missing keypoint 31 at frame 17, skipping.\n",
      "Missing keypoint 31 at frame 18, skipping.\n",
      "Missing keypoint 31 at frame 19, skipping.\n",
      "Missing keypoint 31 at frame 20, skipping.\n",
      "Missing keypoint 31 at frame 21, skipping.\n",
      "Missing keypoint 31 at frame 22, skipping.\n",
      "Missing keypoint 31 at frame 23, skipping.\n",
      "Missing keypoint 31 at frame 24, skipping.\n",
      "Missing keypoint 31 at frame 25, skipping.\n",
      "Missing keypoint 31 at frame 26, skipping.\n",
      "Missing keypoint 31 at frame 27, skipping.\n",
      "Missing keypoint 31 at frame 28, skipping.\n",
      "Missing keypoint 31 at frame 29, skipping.\n",
      "Missing keypoint 31 at frame 30, skipping.\n",
      "Missing keypoint 31 at frame 31, skipping.\n",
      "Missing keypoint 31 at frame 32, skipping.\n",
      "Missing keypoint 31 at frame 33, skipping.\n",
      "Missing keypoint 31 at frame 34, skipping.\n",
      "Missing keypoint 31 at frame 35, skipping.\n",
      "Missing keypoint 31 at frame 36, skipping.\n",
      "Missing keypoint 31 at frame 37, skipping.\n",
      "Missing keypoint 31 at frame 38, skipping.\n",
      "Missing keypoint 31 at frame 39, skipping.\n",
      "Missing keypoint 31 at frame 40, skipping.\n",
      "Missing keypoint 31 at frame 41, skipping.\n",
      "Missing keypoint 31 at frame 42, skipping.\n",
      "Combined features saved for 1_user12\n",
      "Missing keypoint 11 at frame 1, skipping.\n",
      "Missing keypoint 11 at frame 2, skipping.\n",
      "Missing keypoint 11 at frame 3, skipping.\n",
      "Missing keypoint 11 at frame 4, skipping.\n",
      "Missing keypoint 11 at frame 5, skipping.\n",
      "Missing keypoint 11 at frame 6, skipping.\n",
      "Missing keypoint 11 at frame 7, skipping.\n",
      "Missing keypoint 11 at frame 8, skipping.\n",
      "Missing keypoint 11 at frame 9, skipping.\n",
      "Missing keypoint 11 at frame 10, skipping.\n",
      "Missing keypoint 11 at frame 11, skipping.\n",
      "Missing keypoint 11 at frame 12, skipping.\n",
      "Missing keypoint 11 at frame 13, skipping.\n",
      "Missing keypoint 11 at frame 14, skipping.\n",
      "Missing keypoint 11 at frame 15, skipping.\n",
      "Missing keypoint 11 at frame 16, skipping.\n",
      "Missing keypoint 11 at frame 17, skipping.\n",
      "Missing keypoint 11 at frame 18, skipping.\n",
      "Missing keypoint 11 at frame 19, skipping.\n",
      "Missing keypoint 11 at frame 20, skipping.\n",
      "Missing keypoint 11 at frame 21, skipping.\n",
      "Missing keypoint 11 at frame 22, skipping.\n",
      "Missing keypoint 11 at frame 23, skipping.\n",
      "Missing keypoint 11 at frame 24, skipping.\n",
      "Missing keypoint 11 at frame 25, skipping.\n",
      "Missing keypoint 11 at frame 26, skipping.\n",
      "Missing keypoint 11 at frame 27, skipping.\n",
      "Missing keypoint 11 at frame 28, skipping.\n",
      "Missing keypoint 11 at frame 29, skipping.\n",
      "Missing keypoint 11 at frame 30, skipping.\n",
      "Missing keypoint 11 at frame 31, skipping.\n",
      "Missing keypoint 11 at frame 32, skipping.\n",
      "Missing keypoint 11 at frame 33, skipping.\n",
      "Missing keypoint 11 at frame 34, skipping.\n",
      "Missing keypoint 31 at frame 1, skipping.\n",
      "Missing keypoint 31 at frame 2, skipping.\n",
      "Missing keypoint 31 at frame 3, skipping.\n",
      "Missing keypoint 31 at frame 4, skipping.\n",
      "Missing keypoint 31 at frame 5, skipping.\n",
      "Missing keypoint 31 at frame 6, skipping.\n",
      "Missing keypoint 31 at frame 7, skipping.\n",
      "Missing keypoint 31 at frame 8, skipping.\n",
      "Missing keypoint 31 at frame 9, skipping.\n",
      "Missing keypoint 31 at frame 10, skipping.\n",
      "Missing keypoint 31 at frame 11, skipping.\n",
      "Missing keypoint 31 at frame 12, skipping.\n",
      "Missing keypoint 31 at frame 13, skipping.\n",
      "Missing keypoint 31 at frame 14, skipping.\n",
      "Missing keypoint 31 at frame 15, skipping.\n",
      "Missing keypoint 31 at frame 16, skipping.\n",
      "Missing keypoint 31 at frame 17, skipping.\n",
      "Missing keypoint 31 at frame 18, skipping.\n",
      "Missing keypoint 31 at frame 19, skipping.\n",
      "Missing keypoint 31 at frame 20, skipping.\n",
      "Missing keypoint 31 at frame 21, skipping.\n",
      "Missing keypoint 31 at frame 22, skipping.\n",
      "Missing keypoint 31 at frame 23, skipping.\n",
      "Missing keypoint 31 at frame 24, skipping.\n",
      "Missing keypoint 31 at frame 25, skipping.\n",
      "Missing keypoint 31 at frame 26, skipping.\n",
      "Missing keypoint 31 at frame 27, skipping.\n",
      "Missing keypoint 31 at frame 28, skipping.\n",
      "Missing keypoint 31 at frame 29, skipping.\n",
      "Missing keypoint 31 at frame 30, skipping.\n",
      "Missing keypoint 31 at frame 31, skipping.\n",
      "Missing keypoint 31 at frame 32, skipping.\n",
      "Missing keypoint 31 at frame 33, skipping.\n",
      "Missing keypoint 31 at frame 34, skipping.\n",
      "Combined features saved for 1_user13\n",
      "Missing keypoint 11 at frame 1, skipping.\n",
      "Missing keypoint 11 at frame 2, skipping.\n",
      "Missing keypoint 11 at frame 3, skipping.\n",
      "Missing keypoint 11 at frame 4, skipping.\n",
      "Missing keypoint 11 at frame 5, skipping.\n",
      "Missing keypoint 11 at frame 6, skipping.\n",
      "Missing keypoint 11 at frame 7, skipping.\n",
      "Missing keypoint 11 at frame 8, skipping.\n",
      "Missing keypoint 11 at frame 9, skipping.\n",
      "Missing keypoint 11 at frame 10, skipping.\n",
      "Missing keypoint 11 at frame 11, skipping.\n",
      "Missing keypoint 11 at frame 12, skipping.\n",
      "Missing keypoint 11 at frame 13, skipping.\n",
      "Missing keypoint 11 at frame 14, skipping.\n",
      "Missing keypoint 11 at frame 15, skipping.\n",
      "Missing keypoint 11 at frame 16, skipping.\n",
      "Missing keypoint 11 at frame 17, skipping.\n",
      "Missing keypoint 11 at frame 18, skipping.\n",
      "Missing keypoint 11 at frame 19, skipping.\n",
      "Missing keypoint 11 at frame 20, skipping.\n",
      "Missing keypoint 31 at frame 1, skipping.\n",
      "Missing keypoint 31 at frame 2, skipping.\n",
      "Missing keypoint 31 at frame 3, skipping.\n",
      "Missing keypoint 31 at frame 4, skipping.\n",
      "Missing keypoint 31 at frame 5, skipping.\n",
      "Missing keypoint 31 at frame 6, skipping.\n",
      "Missing keypoint 31 at frame 7, skipping.\n",
      "Missing keypoint 31 at frame 8, skipping.\n",
      "Missing keypoint 31 at frame 9, skipping.\n",
      "Missing keypoint 31 at frame 10, skipping.\n",
      "Missing keypoint 31 at frame 11, skipping.\n",
      "Missing keypoint 31 at frame 12, skipping.\n",
      "Missing keypoint 31 at frame 13, skipping.\n",
      "Missing keypoint 31 at frame 14, skipping.\n",
      "Missing keypoint 31 at frame 15, skipping.\n",
      "Missing keypoint 31 at frame 16, skipping.\n",
      "Missing keypoint 31 at frame 17, skipping.\n",
      "Missing keypoint 31 at frame 18, skipping.\n",
      "Missing keypoint 31 at frame 19, skipping.\n",
      "Missing keypoint 31 at frame 20, skipping.\n",
      "Combined features saved for 0_user22\n",
      "Missing keypoint 11 at frame 1, skipping.\n",
      "Missing keypoint 11 at frame 2, skipping.\n",
      "Missing keypoint 11 at frame 3, skipping.\n",
      "Missing keypoint 11 at frame 4, skipping.\n",
      "Missing keypoint 11 at frame 5, skipping.\n",
      "Missing keypoint 31 at frame 1, skipping.\n",
      "Missing keypoint 31 at frame 2, skipping.\n",
      "Missing keypoint 31 at frame 3, skipping.\n",
      "Missing keypoint 31 at frame 4, skipping.\n",
      "Missing keypoint 31 at frame 5, skipping.\n",
      "Combined features saved for 0_user20\n",
      "Missing keypoint 11 at frame 1, skipping.\n",
      "Missing keypoint 11 at frame 2, skipping.\n",
      "Missing keypoint 11 at frame 3, skipping.\n",
      "Missing keypoint 11 at frame 4, skipping.\n",
      "Missing keypoint 11 at frame 5, skipping.\n",
      "Missing keypoint 11 at frame 6, skipping.\n",
      "Missing keypoint 11 at frame 7, skipping.\n",
      "Missing keypoint 11 at frame 8, skipping.\n",
      "Missing keypoint 11 at frame 9, skipping.\n",
      "Missing keypoint 11 at frame 10, skipping.\n",
      "Missing keypoint 11 at frame 11, skipping.\n",
      "Missing keypoint 11 at frame 12, skipping.\n",
      "Missing keypoint 11 at frame 13, skipping.\n",
      "Missing keypoint 11 at frame 14, skipping.\n",
      "Missing keypoint 11 at frame 15, skipping.\n",
      "Missing keypoint 11 at frame 16, skipping.\n",
      "Missing keypoint 11 at frame 17, skipping.\n",
      "Missing keypoint 11 at frame 18, skipping.\n",
      "Missing keypoint 11 at frame 19, skipping.\n",
      "Missing keypoint 11 at frame 20, skipping.\n",
      "Missing keypoint 11 at frame 21, skipping.\n",
      "Missing keypoint 11 at frame 22, skipping.\n",
      "Missing keypoint 11 at frame 23, skipping.\n",
      "Missing keypoint 11 at frame 24, skipping.\n",
      "Missing keypoint 11 at frame 25, skipping.\n",
      "Missing keypoint 11 at frame 26, skipping.\n",
      "Missing keypoint 11 at frame 27, skipping.\n",
      "Missing keypoint 11 at frame 28, skipping.\n",
      "Missing keypoint 31 at frame 1, skipping.\n",
      "Missing keypoint 31 at frame 2, skipping.\n",
      "Missing keypoint 31 at frame 3, skipping.\n",
      "Missing keypoint 31 at frame 4, skipping.\n",
      "Missing keypoint 31 at frame 5, skipping.\n",
      "Missing keypoint 31 at frame 6, skipping.\n",
      "Missing keypoint 31 at frame 7, skipping.\n",
      "Missing keypoint 31 at frame 8, skipping.\n",
      "Missing keypoint 31 at frame 9, skipping.\n",
      "Missing keypoint 31 at frame 10, skipping.\n",
      "Missing keypoint 31 at frame 11, skipping.\n",
      "Missing keypoint 31 at frame 12, skipping.\n",
      "Missing keypoint 31 at frame 13, skipping.\n",
      "Missing keypoint 31 at frame 14, skipping.\n",
      "Missing keypoint 31 at frame 15, skipping.\n",
      "Missing keypoint 31 at frame 16, skipping.\n",
      "Missing keypoint 31 at frame 17, skipping.\n",
      "Missing keypoint 31 at frame 18, skipping.\n",
      "Missing keypoint 31 at frame 19, skipping.\n",
      "Missing keypoint 31 at frame 20, skipping.\n",
      "Missing keypoint 31 at frame 21, skipping.\n",
      "Missing keypoint 31 at frame 22, skipping.\n",
      "Missing keypoint 31 at frame 23, skipping.\n",
      "Missing keypoint 31 at frame 24, skipping.\n",
      "Missing keypoint 31 at frame 25, skipping.\n",
      "Missing keypoint 31 at frame 26, skipping.\n",
      "Missing keypoint 31 at frame 27, skipping.\n",
      "Missing keypoint 31 at frame 28, skipping.\n",
      "Combined features saved for 0.5_user6\n",
      "Feature combination completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fb/p7zywq8d7351kf4l4fwh2dmw0000gn/T/ipykernel_69824/3160202367.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  clip_data = torch.load(clip_path)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Paths\n",
    "keypoints_dir = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/keypoints\"\n",
    "clip_features_dir = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/clip_features\"\n",
    "combined_features_dir = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/combined_features\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(combined_features_dir, exist_ok=True)\n",
    "\n",
    "def calculate_upright_posture(keypoints):\n",
    "    \"\"\"\n",
    "    Detect upright posture based on torso angle.\n",
    "    \"\"\"\n",
    "    upright_frames = []\n",
    "    for i in range(1, len(keypoints)):\n",
    "        try:\n",
    "            # Extract keypoints for left and right shoulders, and the hip\n",
    "            left_shoulder = keypoints[i][11]  # Index 11 for LEFT_SHOULDER\n",
    "            right_shoulder = keypoints[i][12]  # Index 12 for RIGHT_SHOULDER\n",
    "            mid_hip = keypoints[i][24]  # Index 24 for MID_HIP (rough center between hips)\n",
    "        except KeyError as e:\n",
    "            print(f\"Missing keypoint {e} at frame {i}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Calculate the angle between the shoulders and the hips\n",
    "        shoulder_vector = np.array([right_shoulder['x'] - left_shoulder['x'], right_shoulder['y'] - left_shoulder['y']])\n",
    "        hip_vector = np.array([mid_hip['x'] - left_shoulder['x'], mid_hip['y'] - left_shoulder['y']])\n",
    "        \n",
    "        # Compute angle between the vectors\n",
    "        dot_product = np.dot(shoulder_vector, hip_vector)\n",
    "        norm_shoulder = np.linalg.norm(shoulder_vector)\n",
    "        norm_hip = np.linalg.norm(hip_vector)\n",
    "        angle = np.arccos(dot_product / (norm_shoulder * norm_hip))\n",
    "\n",
    "        # Define threshold for upright posture\n",
    "        if angle < np.pi / 4:  # 45 degrees or less is considered upright\n",
    "            upright_frames.append(i)\n",
    "\n",
    "    return upright_frames\n",
    "\n",
    "def calculate_acceleration(keypoints):\n",
    "    \"\"\"\n",
    "    Detect acceleration based on foot movement (using right foot index).\n",
    "    \"\"\"\n",
    "    accelerating_frames = []\n",
    "    for i in range(1, len(keypoints)):\n",
    "        try:\n",
    "            # Extract keypoints for the right foot index (ball of foot)\n",
    "            right_foot_index_prev = keypoints[i - 1][31]  # Index 31 corresponds to the right foot index\n",
    "            right_foot_index_curr = keypoints[i][31]\n",
    "        except KeyError as e:\n",
    "            print(f\"Missing keypoint {e} at frame {i}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Calculate the distance traveled by the foot\n",
    "        foot_distance = np.sqrt(\n",
    "            (right_foot_index_curr['x'] - right_foot_index_prev['x'])**2 +\n",
    "            (right_foot_index_curr['y'] - right_foot_index_prev['y'])**2\n",
    "        )\n",
    "        \n",
    "        # Use a threshold for acceleration detection\n",
    "        if foot_distance > 0.02:  # Adjust this threshold as necessary\n",
    "            accelerating_frames.append(i)\n",
    "\n",
    "    return accelerating_frames\n",
    "\n",
    "def combine_features(video_name, pose_path, clip_path, output_path):\n",
    "    \"\"\"\n",
    "    Combine pose-based features and CLIP embeddings for a video.\n",
    "    \"\"\"\n",
    "    # Load pose-based features\n",
    "    with open(pose_path, 'r') as f:\n",
    "        keypoints_data = json.load(f)\n",
    "\n",
    "    # Detect upright posture and acceleration\n",
    "    upright_frames = calculate_upright_posture(keypoints_data)\n",
    "    accelerating_frames = calculate_acceleration(keypoints_data)\n",
    "\n",
    "    # Load CLIP embeddings\n",
    "    clip_data = torch.load(clip_path)\n",
    "\n",
    "    # Combine features for each frame\n",
    "    combined_data = []\n",
    "    for i, clip_frame in enumerate(clip_data):\n",
    "        # Use pose features for the current frame\n",
    "        pose_features = {\n",
    "            \"upright_posture\": 1 if i in upright_frames else 0,  # Binary flag for upright posture\n",
    "            \"accelerating\": 1 if i in accelerating_frames else 0,  # Binary flag for acceleration\n",
    "        }\n",
    "        combined_frame = np.concatenate([clip_frame, list(pose_features.values())])\n",
    "        combined_data.append(combined_frame)\n",
    "\n",
    "    # Save combined features\n",
    "    torch.save(combined_data, output_path)\n",
    "\n",
    "# Process all videos\n",
    "for video_name in os.listdir(keypoints_dir):\n",
    "    if video_name.endswith(\"_keypoints.json\"):\n",
    "        video_name_base = video_name.replace(\"_keypoints.json\", \"\")\n",
    "        pose_path = os.path.join(keypoints_dir, video_name)\n",
    "        clip_path = os.path.join(clip_features_dir, f\"{video_name_base}_clip.pt\")\n",
    "        output_path = os.path.join(combined_features_dir, f\"{video_name_base}_combined.pt\")\n",
    "\n",
    "        if os.path.exists(clip_path):\n",
    "            combine_features(video_name_base, pose_path, clip_path, output_path)\n",
    "            print(f\"Combined features saved for {video_name_base}\")\n",
    "\n",
    "print(\"Feature combination completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created. Input size: 515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fb/p7zywq8d7351kf4l4fwh2dmw0000gn/T/ipykernel_69824/1696014522.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  video_features = torch.tensor(torch.load(os.path.join(combined_features_dir, file)), dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "combined_features_dir = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/combined_features\"\n",
    "\n",
    "# Hyperparameters\n",
    "sequence_length = 20  # Adjust as needed (still remains as sequence length)\n",
    "batch_size = 16       # Adjust as needed\n",
    "\n",
    "# Ensure input size is always 515\n",
    "input_size = 515\n",
    "\n",
    "class AthleticsDataset(Dataset):\n",
    "    def __init__(self, combined_features_dir, sequence_length, input_size):\n",
    "        \"\"\"\n",
    "        Handles loading and processing of combined features for athletics data.\n",
    "        Ensures input size is always 515.\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_size = input_size\n",
    "\n",
    "        for file in os.listdir(combined_features_dir):\n",
    "            if file.endswith(\"_combined.pt\"):\n",
    "                # Load combined features\n",
    "                video_features = torch.tensor(torch.load(os.path.join(combined_features_dir, file)), dtype=torch.float32)\n",
    "\n",
    "                # Truncate or pad sequences to the desired length\n",
    "                if video_features.shape[0] >= self.sequence_length:\n",
    "                    video_features = video_features[:self.sequence_length]\n",
    "                else:\n",
    "                    padding = torch.zeros((self.sequence_length - video_features.shape[0], video_features.shape[1]))\n",
    "                    video_features = torch.cat((video_features, padding), dim=0)\n",
    "\n",
    "                # Ensure features match the input size (515)\n",
    "                if video_features.shape[1] != self.input_size:\n",
    "                    padding = torch.zeros((video_features.shape[0], self.input_size - video_features.shape[1]))\n",
    "                    video_features = torch.cat((video_features, padding), dim=1)\n",
    "                self.data.append(video_features)\n",
    "\n",
    "                # Extract label from filename\n",
    "                label = float(file.split(\"_\")[0])  # Extract label from file name\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Initialize dataset and DataLoader\n",
    "def get_data_loaders(combined_features_dir, sequence_length, batch_size, input_size, train_split=0.8):\n",
    "    dataset = AthleticsDataset(combined_features_dir, sequence_length, input_size)\n",
    "    train_size = int(train_split * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, input_size  # Return loaders and input size\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader, val_loader, input_size = get_data_loaders(combined_features_dir, sequence_length, batch_size, input_size)\n",
    "\n",
    "print(f\"DataLoaders created. Input size: {input_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TemporalModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        \"\"\"\n",
    "        LSTM-based model for sequence prediction.\n",
    "        \"\"\"\n",
    "        super(TemporalModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.lstm(x)  # Use the final hidden state\n",
    "        output = self.fc(hidden[-1])  # Fully connected output\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "combined_features_dir = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/disc_throwing/stages/stage2/combined_features\"\n",
    "\n",
    "# Dataset and DataLoader\n",
    "class AthleticsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, combined_features_dir, sequence_length):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        for file in os.listdir(combined_features_dir):\n",
    "            if file.endswith(\"_combined.pt\"):\n",
    "                video_features = torch.tensor(torch.load(os.path.join(combined_features_dir, file)), dtype=torch.float32)\n",
    "\n",
    "                if video_features.shape[0] >= self.sequence_length:\n",
    "                    video_features = video_features[:self.sequence_length]\n",
    "                else:\n",
    "                    padding = torch.zeros((self.sequence_length - video_features.shape[0], video_features.shape[1]))\n",
    "                    video_features = torch.cat((video_features, padding), dim=0)\n",
    "\n",
    "                self.data.append(video_features)\n",
    "                label = float(file.split(\"_\")[0])  # Extract label from file name\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "def get_data_loaders(combined_features_dir, sequence_length, batch_size, train_split=0.8):\n",
    "    dataset = AthleticsDataset(combined_features_dir, sequence_length)\n",
    "    train_size = int(train_split * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, dataset[0][0].shape[1]\n",
    "\n",
    "# Define LSTM model\n",
    "class TemporalModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):\n",
    "        super(TemporalModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        output = self.fc(hidden[-1])\n",
    "        return output\n",
    "\n",
    "# Training function with early stopping\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=500, patience=100):\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), torch.tensor(labels, dtype=torch.float32).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features, labels = features.to(device), torch.tensor(labels, dtype=torch.float32).to(device)\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping logic with 100 epochs patience\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {patience} epochs without improvement!\")\n",
    "            break\n",
    "\n",
    "    return best_val_loss\n",
    "\n",
    "\n",
    "# Hyperparameter grid search\n",
    "# def hyperparameter_search():\n",
    "    # Hyperparameter grid\n",
    "    hidden_sizes = [32, 64, 128]\n",
    "    num_layers = [1, 2, 3]\n",
    "    learning_rates = [0.001, 0.005, 0.0001, 0.0005]\n",
    "    dropouts = [0.0, 0.2, 0.3]\n",
    "\n",
    "    # Initialize variables to track the best model\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_params = None\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Prepare data\n",
    "    train_loader, val_loader, input_size = get_data_loaders(combined_features_dir, sequence_length=20, batch_size=8)\n",
    "\n",
    "    # Iterate over all combinations of hyperparameters\n",
    "    for hidden_size, num_layer, learning_rate, dropout in itertools.product(hidden_sizes, num_layers, learning_rates, dropouts):\n",
    "        print(f\"Testing configuration: Hidden Size={hidden_size}, Num Layers={num_layer}, LR={learning_rate}, Dropout={dropout}\")\n",
    "        \n",
    "        # Initialize model, criterion, and optimizer\n",
    "        model = TemporalModel(input_size=input_size, hidden_size=hidden_size, num_layers=num_layer, output_size=1, dropout=dropout).to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Train the model\n",
    "        val_loss = train_model(model, train_loader, val_loader, criterion, optimizer, device)\n",
    "\n",
    "        # Update best model if this configuration is better\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_params = {\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"num_layers\": num_layer,\n",
    "                \"learning_rate\": learning_rate,\n",
    "                \"dropout\": dropout,\n",
    "            }\n",
    "\n",
    "    print(f\"Best Configuration: {best_params}, Validation Loss: {best_val_loss:.4f}\")\n",
    "    return best_params\n",
    "\n",
    "# Run hyperparameter search\n",
    "# best_params = hyperparameter_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size for the model: 513\n",
      "Epoch [1/500], Train Loss: 0.6406, Val Loss: 0.4965\n",
      "Epoch [2/500], Train Loss: 0.5162, Val Loss: 0.4736\n",
      "Epoch [3/500], Train Loss: 0.4802, Val Loss: 0.4334\n",
      "Epoch [4/500], Train Loss: 0.4176, Val Loss: 0.3845\n",
      "Epoch [5/500], Train Loss: 0.3554, Val Loss: 0.3332\n",
      "Epoch [6/500], Train Loss: 0.2969, Val Loss: 0.2805\n",
      "Epoch [7/500], Train Loss: 0.2323, Val Loss: 0.2558\n",
      "Epoch [8/500], Train Loss: 0.1686, Val Loss: 0.2895\n",
      "Epoch [9/500], Train Loss: 0.1458, Val Loss: 0.3085\n",
      "Epoch [10/500], Train Loss: 0.1803, Val Loss: 0.2871\n",
      "Epoch [11/500], Train Loss: 0.1577, Val Loss: 0.2829\n",
      "Epoch [12/500], Train Loss: 0.1348, Val Loss: 0.2893\n",
      "Epoch [13/500], Train Loss: 0.1293, Val Loss: 0.2927\n",
      "Epoch [14/500], Train Loss: 0.1244, Val Loss: 0.2994\n",
      "Epoch [15/500], Train Loss: 0.1188, Val Loss: 0.3079\n",
      "Epoch [16/500], Train Loss: 0.1182, Val Loss: 0.3192\n",
      "Epoch [17/500], Train Loss: 0.1201, Val Loss: 0.3294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fb/p7zywq8d7351kf4l4fwh2dmw0000gn/T/ipykernel_69824/505168142.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  video_features = torch.tensor(torch.load(os.path.join(combined_features_dir, file)), dtype=torch.float32)\n",
      "/var/folders/fb/p7zywq8d7351kf4l4fwh2dmw0000gn/T/ipykernel_69824/505168142.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features, labels = features.to(device), torch.tensor(labels, dtype=torch.float32).to(device)\n",
      "/var/folders/fb/p7zywq8d7351kf4l4fwh2dmw0000gn/T/ipykernel_69824/505168142.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features, labels = features.to(device), torch.tensor(labels, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/500], Train Loss: 0.1204, Val Loss: 0.3368\n",
      "Epoch [19/500], Train Loss: 0.1173, Val Loss: 0.3440\n",
      "Epoch [20/500], Train Loss: 0.1095, Val Loss: 0.3522\n",
      "Epoch [21/500], Train Loss: 0.1016, Val Loss: 0.3640\n",
      "Epoch [22/500], Train Loss: 0.0952, Val Loss: 0.3809\n",
      "Epoch [23/500], Train Loss: 0.0917, Val Loss: 0.4016\n",
      "Epoch [24/500], Train Loss: 0.0898, Val Loss: 0.4236\n",
      "Epoch [25/500], Train Loss: 0.0883, Val Loss: 0.4448\n",
      "Epoch [26/500], Train Loss: 0.0858, Val Loss: 0.4644\n",
      "Epoch [27/500], Train Loss: 0.0820, Val Loss: 0.4842\n",
      "Epoch [28/500], Train Loss: 0.0772, Val Loss: 0.5193\n",
      "Epoch [29/500], Train Loss: 0.0722, Val Loss: 0.5308\n",
      "Epoch [30/500], Train Loss: 0.0671, Val Loss: 0.5583\n",
      "Epoch [31/500], Train Loss: 0.0613, Val Loss: 0.5640\n",
      "Epoch [32/500], Train Loss: 0.0550, Val Loss: 0.5536\n",
      "Epoch [33/500], Train Loss: 0.0478, Val Loss: 0.5370\n",
      "Epoch [34/500], Train Loss: 0.0398, Val Loss: 0.5193\n",
      "Epoch [35/500], Train Loss: 0.0319, Val Loss: 0.5009\n",
      "Epoch [36/500], Train Loss: 0.0248, Val Loss: 0.4813\n",
      "Epoch [37/500], Train Loss: 0.0191, Val Loss: 0.4602\n",
      "Epoch [38/500], Train Loss: 0.0145, Val Loss: 0.4386\n",
      "Epoch [39/500], Train Loss: 0.0108, Val Loss: 0.4179\n",
      "Epoch [40/500], Train Loss: 0.0077, Val Loss: 0.4002\n",
      "Epoch [41/500], Train Loss: 0.0049, Val Loss: 0.3866\n",
      "Epoch [42/500], Train Loss: 0.0029, Val Loss: 0.3773\n",
      "Epoch [43/500], Train Loss: 0.0018, Val Loss: 0.3712\n",
      "Epoch [44/500], Train Loss: 0.0016, Val Loss: 0.3660\n",
      "Epoch [45/500], Train Loss: 0.0018, Val Loss: 0.3635\n",
      "Epoch [46/500], Train Loss: 0.0021, Val Loss: 0.3633\n",
      "Epoch [47/500], Train Loss: 0.0021, Val Loss: 0.3646\n",
      "Epoch [48/500], Train Loss: 0.0022, Val Loss: 0.3680\n",
      "Epoch [49/500], Train Loss: 0.0022, Val Loss: 0.3742\n",
      "Epoch [50/500], Train Loss: 0.0021, Val Loss: 0.3830\n",
      "Epoch [51/500], Train Loss: 0.0018, Val Loss: 0.3933\n",
      "Epoch [52/500], Train Loss: 0.0015, Val Loss: 0.4028\n",
      "Epoch [53/500], Train Loss: 0.0011, Val Loss: 0.4108\n",
      "Epoch [54/500], Train Loss: 0.0010, Val Loss: 0.4161\n",
      "Epoch [55/500], Train Loss: 0.0008, Val Loss: 0.4187\n",
      "Epoch [56/500], Train Loss: 0.0007, Val Loss: 0.4196\n",
      "Epoch [57/500], Train Loss: 0.0005, Val Loss: 0.4207\n",
      "Epoch [58/500], Train Loss: 0.0005, Val Loss: 0.4232\n",
      "Epoch [59/500], Train Loss: 0.0005, Val Loss: 0.4277\n",
      "Epoch [60/500], Train Loss: 0.0004, Val Loss: 0.4336\n",
      "Epoch [61/500], Train Loss: 0.0003, Val Loss: 0.4399\n",
      "Epoch [62/500], Train Loss: 0.0003, Val Loss: 0.4450\n",
      "Epoch [63/500], Train Loss: 0.0003, Val Loss: 0.4483\n",
      "Epoch [64/500], Train Loss: 0.0003, Val Loss: 0.4500\n",
      "Epoch [65/500], Train Loss: 0.0003, Val Loss: 0.4512\n",
      "Epoch [66/500], Train Loss: 0.0003, Val Loss: 0.4531\n",
      "Epoch [67/500], Train Loss: 0.0003, Val Loss: 0.4559\n",
      "Epoch [68/500], Train Loss: 0.0003, Val Loss: 0.4596\n",
      "Epoch [69/500], Train Loss: 0.0003, Val Loss: 0.4631\n",
      "Epoch [70/500], Train Loss: 0.0003, Val Loss: 0.4653\n",
      "Epoch [71/500], Train Loss: 0.0003, Val Loss: 0.4656\n",
      "Epoch [72/500], Train Loss: 0.0002, Val Loss: 0.4640\n",
      "Epoch [73/500], Train Loss: 0.0002, Val Loss: 0.4613\n",
      "Epoch [74/500], Train Loss: 0.0002, Val Loss: 0.4586\n",
      "Epoch [75/500], Train Loss: 0.0002, Val Loss: 0.4568\n",
      "Epoch [76/500], Train Loss: 0.0002, Val Loss: 0.4562\n",
      "Epoch [77/500], Train Loss: 0.0001, Val Loss: 0.4563\n",
      "Epoch [78/500], Train Loss: 0.0001, Val Loss: 0.4564\n",
      "Epoch [79/500], Train Loss: 0.0001, Val Loss: 0.4560\n",
      "Epoch [80/500], Train Loss: 0.0001, Val Loss: 0.4549\n",
      "Epoch [81/500], Train Loss: 0.0001, Val Loss: 0.4536\n",
      "Epoch [82/500], Train Loss: 0.0001, Val Loss: 0.4525\n",
      "Epoch [83/500], Train Loss: 0.0001, Val Loss: 0.4523\n",
      "Epoch [84/500], Train Loss: 0.0001, Val Loss: 0.4530\n",
      "Epoch [85/500], Train Loss: 0.0000, Val Loss: 0.4542\n",
      "Epoch [86/500], Train Loss: 0.0000, Val Loss: 0.4553\n",
      "Epoch [87/500], Train Loss: 0.0000, Val Loss: 0.4559\n",
      "Epoch [88/500], Train Loss: 0.0000, Val Loss: 0.4558\n",
      "Epoch [89/500], Train Loss: 0.0000, Val Loss: 0.4552\n",
      "Epoch [90/500], Train Loss: 0.0000, Val Loss: 0.4548\n",
      "Epoch [91/500], Train Loss: 0.0000, Val Loss: 0.4548\n",
      "Epoch [92/500], Train Loss: 0.0000, Val Loss: 0.4554\n",
      "Epoch [93/500], Train Loss: 0.0000, Val Loss: 0.4562\n",
      "Epoch [94/500], Train Loss: 0.0000, Val Loss: 0.4569\n",
      "Epoch [95/500], Train Loss: 0.0000, Val Loss: 0.4573\n",
      "Epoch [96/500], Train Loss: 0.0000, Val Loss: 0.4572\n",
      "Epoch [97/500], Train Loss: 0.0000, Val Loss: 0.4570\n",
      "Epoch [98/500], Train Loss: 0.0000, Val Loss: 0.4570\n",
      "Epoch [99/500], Train Loss: 0.0000, Val Loss: 0.4574\n",
      "Epoch [100/500], Train Loss: 0.0000, Val Loss: 0.4584\n",
      "Epoch [101/500], Train Loss: 0.0000, Val Loss: 0.4595\n",
      "Epoch [102/500], Train Loss: 0.0000, Val Loss: 0.4604\n",
      "Epoch [103/500], Train Loss: 0.0000, Val Loss: 0.4610\n",
      "Epoch [104/500], Train Loss: 0.0000, Val Loss: 0.4612\n",
      "Epoch [105/500], Train Loss: 0.0000, Val Loss: 0.4613\n",
      "Epoch [106/500], Train Loss: 0.0000, Val Loss: 0.4615\n",
      "Epoch [107/500], Train Loss: 0.0000, Val Loss: 0.4620\n",
      "Early stopping triggered after 100 epochs without improvement!\n",
      "Final model trained. Validation Loss: 0.2558\n"
     ]
    }
   ],
   "source": [
    "# Train the final model with the best configuration\n",
    "final_hidden_size = 128\n",
    "final_num_layers = 1\n",
    "final_learning_rate = 0.002\n",
    "final_dropout = 0.5\n",
    "\n",
    "# Prepare DataLoaders (use full dataset for training)\n",
    "train_loader, val_loader, input_size = get_data_loaders(combined_features_dir, sequence_length=20, batch_size=16)\n",
    "print(f\"Input size for the model: {input_size}\")\n",
    "\n",
    "# Initialize final model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "final_model = TemporalModel(input_size=input_size, hidden_size=final_hidden_size, num_layers=final_num_layers, output_size=1, dropout=final_dropout).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=final_learning_rate)\n",
    "\n",
    "# Train final model\n",
    "final_val_loss = train_model(final_model, train_loader, val_loader, criterion, optimizer, device, num_epochs=500, patience=100)\n",
    "print(f\"Final model trained. Validation Loss: {final_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_and_collect_predictions(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the provided DataLoader and collect true vs. predicted values.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in data_loader:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Get model predictions\n",
    "            outputs = model(features).squeeze()\n",
    "            predicted_labels.extend(outputs.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return true_labels, predicted_labels\n",
    "\n",
    "# Use validation set for evaluation\n",
    "true_labels, predicted_labels = evaluate_and_collect_predictions(final_model, val_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736958445.763351 4325357 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n",
      "W0000 00:00:1736958445.818127 4342581 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1736958445.847727 4342581 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: 1_user2.mp4\n",
      "Prediction: 1.0034\n",
      "Processing video: 1_user5.mp4\n",
      "Prediction: 0.8159\n",
      "Processing video: 1_user12.mp4\n",
      "Prediction: 0.9887\n",
      "Processing video: 1_user7.mp4\n",
      "Prediction: 0.8763\n",
      "Processing video: 1_user13.mp4\n",
      "Prediction: 0.9860\n",
      "Processing video: 0_user3.mp4\n",
      "Prediction: 0.9738\n",
      "Processing video: 0_user1.mp4\n",
      "Prediction: 1.0015\n",
      "Processing video: 0_user22.mp4\n",
      "Prediction: 0.8893\n",
      "Processing video: 0_user20.mp4\n",
      "Prediction: 0.9199\n",
      "Processing video: 0_user10.mp4\n",
      "Prediction: 0.6549\n",
      "Processing video: 1_user23.mp4\n",
      "Prediction: 0.6381\n",
      "Processing video: 1_user21.mp4\n",
      "Prediction: 0.6663\n",
      "Processing video: 1_user8.mp4\n",
      "Prediction: 0.9939\n",
      "Processing video: 1_user9.mp4\n",
      "Prediction: 0.9343\n",
      "Processing video: 0.5_user6.mp4\n",
      "Prediction: 0.3795\n",
      "\n",
      "Prediction Results:\n",
      "1_user2.mp4: 1.0034\n",
      "1_user5.mp4: 0.8159\n",
      "1_user12.mp4: 0.9887\n",
      "1_user7.mp4: 0.8763\n",
      "1_user13.mp4: 0.9860\n",
      "0_user3.mp4: 0.9738\n",
      "0_user1.mp4: 1.0015\n",
      "0_user22.mp4: 0.8893\n",
      "0_user20.mp4: 0.9199\n",
      "0_user10.mp4: 0.6549\n",
      "1_user23.mp4: 0.6381\n",
      "1_user21.mp4: 0.6663\n",
      "1_user8.mp4: 0.9939\n",
      "1_user9.mp4: 0.9343\n",
      "0.5_user6.mp4: 0.3795\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import mediapipe as mp\n",
    "\n",
    "# Paths\n",
    "video_dir = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/videos\"\n",
    "sequence_length = 20  # Sequence length for LSTM\n",
    "\n",
    "# Initialize CLIP and MediaPipe\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=True, model_complexity=2, enable_segmentation=False)\n",
    "\n",
    "# Ensure input size is always 515\n",
    "input_size = 515\n",
    "\n",
    "# Helper functions\n",
    "def extract_frames(video_path, interval=5):\n",
    "    \"\"\"\n",
    "    Extract frames from a video at a given interval.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if count % interval == 0:\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(rgb_frame)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def extract_keypoints(frames):\n",
    "    \"\"\"\n",
    "    Extract pose keypoints from frames using MediaPipe.\n",
    "    \"\"\"\n",
    "    keypoints = []\n",
    "    for frame in frames:\n",
    "        result = pose.process(frame)\n",
    "        if result.pose_landmarks:\n",
    "            keypoints.append([\n",
    "                {\"x\": lm.x, \"y\": lm.y, \"z\": lm.z, \"visibility\": lm.visibility}\n",
    "                for lm in result.pose_landmarks.landmark\n",
    "            ])\n",
    "    return keypoints\n",
    "\n",
    "def calculate_velocity_and_acceleration(keypoints):\n",
    "    \"\"\"\n",
    "    Calculate velocity and acceleration using the torso and hip keypoints.\n",
    "    Assumes that torso and hip points are relevant for assessing posture.\n",
    "    \"\"\"\n",
    "    velocities, accelerations = [], []\n",
    "    for i in range(1, len(keypoints)):\n",
    "        # Calculate velocity using distance between torso and hips\n",
    "        torso_prev = keypoints[i - 1][11]  # Left shoulder\n",
    "        torso_curr = keypoints[i][11]  # Left shoulder\n",
    "\n",
    "        # Calculate velocity as Euclidean distance between two points\n",
    "        velocity = np.sqrt((torso_curr['x'] - torso_prev['x'])**2 + (torso_curr['y'] - torso_prev['y'])**2)\n",
    "        velocities.append(velocity)\n",
    "\n",
    "        if i > 1:\n",
    "            accelerations.append(velocities[-1] - velocities[-2])\n",
    "    return velocities, accelerations\n",
    "\n",
    "def assess_upright_posture(keypoints):\n",
    "    \"\"\"\n",
    "    Assess the upright posture based on the angle between the torso and legs.\n",
    "    A small angle indicates a more upright posture.\n",
    "    \"\"\"\n",
    "    angles = []\n",
    "    for i in range(1, len(keypoints)):\n",
    "        # Compute the angle between the torso and the thighs (using shoulder, hip, and knee keypoints)\n",
    "        shoulder = keypoints[i][11]  # Left shoulder\n",
    "        hip = keypoints[i][23]  # Left hip\n",
    "        knee = keypoints[i][25]  # Left knee\n",
    "\n",
    "        # Calculate vectors for the torso and thigh\n",
    "        torso_vector = np.array([shoulder['x'] - hip['x'], shoulder['y'] - hip['y']])\n",
    "        thigh_vector = np.array([knee['x'] - hip['x'], knee['y'] - hip['y']])\n",
    "\n",
    "        # Compute the angle between the torso and thigh using dot product\n",
    "        dot_product = np.dot(torso_vector, thigh_vector)\n",
    "        magnitude_torso = np.linalg.norm(torso_vector)\n",
    "        magnitude_thigh = np.linalg.norm(thigh_vector)\n",
    "\n",
    "        # Angle in radians\n",
    "        angle = np.arccos(dot_product / (magnitude_torso * magnitude_thigh))\n",
    "        angles.append(np.degrees(angle))  # Convert to degrees\n",
    "\n",
    "    return angles\n",
    "\n",
    "def extract_clip_features(frames):\n",
    "    \"\"\"\n",
    "    Extract CLIP embeddings for each frame.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    for frame in frames:\n",
    "        image = Image.fromarray(frame)\n",
    "        inputs = clip_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            embedding = clip_model.get_image_features(**inputs).cpu().numpy().flatten()\n",
    "            embeddings.append(embedding)\n",
    "    return embeddings\n",
    "\n",
    "def combine_features(clip_embeddings, velocities, accelerations, posture_angles):\n",
    "    \"\"\"\n",
    "    Combine CLIP embeddings, velocities, accelerations, and posture angles into a single feature tensor.\n",
    "    Ensure the final feature vector has 513 features.\n",
    "    \"\"\"\n",
    "    combined_features = []\n",
    "    for i, clip_embedding in enumerate(clip_embeddings):\n",
    "        # Combine features with pose features (velocity, acceleration, and posture angle)\n",
    "        feature_vector = np.concatenate([clip_embedding, \n",
    "                                        [velocities[i] if i < len(velocities) else 0],\n",
    "                                        [accelerations[i] if i < len(accelerations) else 0],\n",
    "                                        [posture_angles[i] if i < len(posture_angles) else 0]])\n",
    "\n",
    "        # Ensure the feature vector has 513 features\n",
    "        if len(feature_vector) > 513:\n",
    "            feature_vector = feature_vector[:513]  # Truncate if there are more than 513 features\n",
    "        elif len(feature_vector) < 513:\n",
    "            padding = np.zeros(513 - len(feature_vector))  # Pad with zeros if there are fewer than 513 features\n",
    "            feature_vector = np.concatenate([feature_vector, padding])\n",
    "\n",
    "        combined_features.append(feature_vector)\n",
    "    \n",
    "    return torch.tensor(combined_features, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def process_and_predict(video_path, model, sequence_length):\n",
    "    \"\"\"\n",
    "    Process a single video and predict its score.\n",
    "    \"\"\"\n",
    "    print(f\"Processing video: {os.path.basename(video_path)}\")\n",
    "    # Step 1: Extract frames\n",
    "    frames = extract_frames(video_path)\n",
    "\n",
    "    # Step 2: Extract keypoints\n",
    "    keypoints = extract_keypoints(frames)\n",
    "\n",
    "    # Step 3: Calculate pose-based features (velocity, acceleration, posture)\n",
    "    velocities, accelerations = calculate_velocity_and_acceleration(keypoints)\n",
    "    posture_angles = assess_upright_posture(keypoints)  # Assess posture\n",
    "\n",
    "    # Step 4: Extract CLIP features\n",
    "    clip_embeddings = extract_clip_features(frames)\n",
    "\n",
    "    # Step 5: Combine features\n",
    "    combined_features = combine_features(clip_embeddings, velocities, accelerations, posture_angles)\n",
    "\n",
    "    # Step 6: Truncate or pad sequences to fixed length (515 features)\n",
    "    if combined_features.shape[0] >= sequence_length:\n",
    "        combined_features = combined_features[:sequence_length]\n",
    "    else:\n",
    "        padding = torch.zeros((sequence_length - combined_features.shape[0], combined_features.shape[1]))\n",
    "        combined_features = torch.cat((combined_features, padding), dim=0)\n",
    "\n",
    "    # Step 7: Predict using the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        combined_features = combined_features.unsqueeze(0).to(device)  # Add batch dimension\n",
    "        prediction = model(combined_features).squeeze().cpu().item()\n",
    "\n",
    "    print(f\"Prediction: {prediction:.4f}\")\n",
    "    return prediction\n",
    "\n",
    "# Process all videos in the directory and predict\n",
    "results = {}\n",
    "for video_file in os.listdir(video_dir):\n",
    "    if video_file.endswith(\".mp4\"):\n",
    "        video_path = os.path.join(video_dir, video_file)\n",
    "        prediction = process_and_predict(video_path, final_model, sequence_length)\n",
    "        results[video_file] = prediction\n",
    "\n",
    "# Print results\n",
    "print(\"\\nPrediction Results:\")\n",
    "for video, prediction in results.items():\n",
    "    print(f\"{video}: {prediction:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(final_model.state_dict(), \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/stage1_height.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feedback generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_with_metadata(video_path, model, sequence_length):\n",
    "    \"\"\"\n",
    "    Process a video and return structured metadata with predictions and pose metrics.\n",
    "    \"\"\"\n",
    "    print(f\"Processing video: {os.path.basename(video_path)}\")\n",
    "    \n",
    "    # Step 1: Extract frames\n",
    "    frames = extract_frames(video_path)\n",
    "    \n",
    "    # Step 2: Extract keypoints\n",
    "    keypoints = extract_keypoints(frames)\n",
    "\n",
    "    # Step 3: Calculate pose-based features\n",
    "    velocities, accelerations = calculate_velocity_and_acceleration(keypoints)\n",
    "    stride_lengths = calculate_stride_length(keypoints)\n",
    "\n",
    "    # Pose metrics\n",
    "    pose_metrics = {\n",
    "        \"average_velocity\": np.mean(velocities) if velocities else 0,\n",
    "        \"max_stride_length\": np.max(stride_lengths) if stride_lengths else 0,\n",
    "        \"average_acceleration\": np.mean(accelerations) if accelerations else 0\n",
    "    }\n",
    "\n",
    "    # Step 4: Extract CLIP features\n",
    "    clip_embeddings = extract_clip_features(frames)\n",
    "\n",
    "    # CLIP insights\n",
    "    clip_summary = \"High contextual alignment with accelerating motion.\"  # Placeholder for now\n",
    "\n",
    "    # Step 5: Combine features\n",
    "    combined_features = combine_features(clip_embeddings, velocities, accelerations, stride_lengths)\n",
    "\n",
    "    # Step 6: Truncate or pad sequences\n",
    "    if combined_features.shape[0] >= sequence_length:\n",
    "        combined_features = combined_features[:sequence_length]\n",
    "    else:\n",
    "        padding = torch.zeros((sequence_length - combined_features.shape[0], combined_features.shape[1]))\n",
    "        combined_features = torch.cat((combined_features, padding), dim=0)\n",
    "\n",
    "    # Step 7: Predict using the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        combined_features = combined_features.unsqueeze(0).to(device)  # Add batch dimension\n",
    "        prediction = model(combined_features).squeeze().cpu().item()\n",
    "\n",
    "    print(f\"Prediction: {prediction:.4f}\")\n",
    "\n",
    "    # Return structured metadata\n",
    "    return {\n",
    "        \"video_name\": os.path.basename(video_path),\n",
    "        \"prediction\": prediction,\n",
    "        \"pose_metrics\": pose_metrics,\n",
    "        \"clip_features\": {\"embedding_summary\": clip_summary}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "# result = generator(\"Explain the performance of an athlete based on metrics.\", max_length=50)\n",
    "# print(result[0]['generated_text'])\n",
    "\n",
    "\n",
    "# def validate_metadata(metadata):\n",
    "#     required_keys = {\n",
    "#         'video_name': str,\n",
    "#         'prediction': float,\n",
    "#         'pose_metrics': dict,\n",
    "#         'clip_features': dict,\n",
    "#     }\n",
    "#     pose_metrics_keys = ['average_velocity', 'max_stride_length', 'average_acceleration']\n",
    "#     clip_features_keys = ['embedding_summary']\n",
    "\n",
    "#     for key, expected_type in required_keys.items():\n",
    "#         if key not in metadata or not isinstance(metadata[key], expected_type):\n",
    "#             raise ValueError(f\"Invalid or missing key: {key}, expected type: {expected_type}\")\n",
    "    \n",
    "#     for key in pose_metrics_keys:\n",
    "#         if key not in metadata['pose_metrics']:\n",
    "#             raise ValueError(f\"Missing pose metric: {key}\")\n",
    "    \n",
    "#     for key in clip_features_keys:\n",
    "#         if key not in metadata['clip_features']:\n",
    "#             raise ValueError(f\"Missing clip feature: {key}\")\n",
    "\n",
    "# def generate_justification(metadata, max_length=150, num_return_sequences=1):\n",
    "#     validate_metadata(metadata)\n",
    "    \n",
    "#     # Dynamic prompt construction\n",
    "#     metrics_prompt = []\n",
    "#     for metric, value in metadata['pose_metrics'].items():\n",
    "#         metrics_prompt.append(f\"- {metric.replace('_', ' ').title()}: {value:.2f}\")\n",
    "#     metrics_text = \"\\n\".join(metrics_prompt)\n",
    "\n",
    "#     prompt = f\"\"\"\n",
    "#     Analyze the performance for {metadata['video_name']}.\n",
    "#     The predicted score is {metadata['prediction']:.2f}.\n",
    "#     Key metrics:\n",
    "#     {metrics_text}\n",
    "#     - CLIP embedding summary: {metadata['clip_features']['embedding_summary']}\n",
    "    \n",
    "#     Based on these metrics, explain why the score is appropriate and provide constructive feedback for improvement.\n",
    "#     \"\"\"\n",
    "#     print(\"Generated prompt:\", prompt)  # Debugging log\n",
    "#     result = generator(prompt, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "#     return result[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Directory containing videos\n",
    "# video_dir = \"/Users/cezar/Desktop/Team Project/AI/distance_jump/stage1/videos\"\n",
    "\n",
    "# # Dictionary to store results\n",
    "# results = {}\n",
    "\n",
    "# for video_file in os.listdir(video_dir):\n",
    "#     if video_file.endswith(\".mp4\"):\n",
    "#         video_path = os.path.join(video_dir, video_file)\n",
    "        \n",
    "#         # Step 1: Process video and generate metadata\n",
    "#         metadata = process_video_with_metadata(video_path, final_model, sequence_length=20)\n",
    "        \n",
    "#         # Step 2: Generate justification using Hugging Face model\n",
    "#         justification = generate_justification(metadata)\n",
    "#         metadata[\"justification\"] = justification\n",
    "        \n",
    "#         # Store results\n",
    "#         results[video_file] = metadata\n",
    "\n",
    "# # Print results\n",
    "# for video, data in results.items():\n",
    "#     print(f\"Video: {video}\")\n",
    "#     print(f\"Prediction: {data['prediction']:.4f}\")\n",
    "#     print(f\"Justification: {data['justification']}\")\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "# # Optional: Save results to JSON\n",
    "# # import json\n",
    "# # with open(\"video_predictions_with_justifications.json\", \"w\") as f:\n",
    "# #     json.dump(results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
