{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737661942.872876 10892581 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1737661942.926946 10892825 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737661942.935564 10892823 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737661942.947132 10892829 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upright posture analysis complete! JSON files saved in 'keypoints' folder.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to check if the athlete maintains an upright posture while accelerating\n",
    "def is_upright_posture(shoulder, hip, knee):\n",
    "    \"\"\"\n",
    "    Determines if the athlete maintains an upright posture by analyzing \n",
    "    the vertical alignment of the shoulder, hip, and knee.\n",
    "    Upright posture condition: shoulder should be aligned with the hip vertically.\n",
    "    \"\"\"\n",
    "    shoulder_x, shoulder_y = shoulder\n",
    "    hip_x, hip_y = hip\n",
    "    knee_x, knee_y = knee\n",
    "\n",
    "    # Upright posture if shoulder is nearly aligned with hip and knee is below hip\n",
    "    return abs(shoulder_x - hip_x) < 0.05 and hip_y < knee_y\n",
    "\n",
    "# Paths for the stage 1 videos and keypoints storage\n",
    "stage_path = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/videos\"\n",
    "keypoints_folder = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/keypoints\"\n",
    "\n",
    "# Ensure keypoints folder exists\n",
    "os.makedirs(keypoints_folder, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(stage_path):\n",
    "    if file.endswith(\".mp4\"):\n",
    "        video_file_path = os.path.join(stage_path, file)\n",
    "        cap = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "        keypoints_data = []  # Store keypoints for this video\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Convert frame to RGB for MediaPipe processing\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result = pose.process(frame_rgb)\n",
    "\n",
    "            if result.pose_landmarks:\n",
    "                landmarks = result.pose_landmarks.landmark\n",
    "\n",
    "                # Extract relevant keypoints for posture analysis\n",
    "                left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x, \n",
    "                                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y]\n",
    "                left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP].x, \n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_HIP].y]\n",
    "                left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x, \n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y]\n",
    "\n",
    "                right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x, \n",
    "                                  landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y]\n",
    "                right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x, \n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y]\n",
    "                right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x, \n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y]\n",
    "\n",
    "                # Check if the posture is upright\n",
    "                left_upright = is_upright_posture(left_shoulder, left_hip, left_knee)\n",
    "                right_upright = is_upright_posture(right_shoulder, right_hip, right_knee)\n",
    "\n",
    "                # Store data for this frame\n",
    "                keypoints_data.append({\n",
    "                    \"frame\": int(cap.get(cv2.CAP_PROP_POS_FRAMES)),\n",
    "                    \"left_upright\": left_upright,\n",
    "                    \"right_upright\": right_upright,\n",
    "                    \"left_shoulder\": left_shoulder,\n",
    "                    \"left_hip\": left_hip,\n",
    "                    \"left_knee\": left_knee,\n",
    "                    \"right_shoulder\": right_shoulder,\n",
    "                    \"right_hip\": right_hip,\n",
    "                    \"right_knee\": right_knee\n",
    "                })\n",
    "\n",
    "        # Release the video\n",
    "        cap.release()\n",
    "\n",
    "        # Save keypoints to the keypoints folder\n",
    "        json_filename = os.path.splitext(file)[0] + \"_keypoints.json\"\n",
    "        json_path = os.path.join(keypoints_folder, json_filename)\n",
    "        with open(json_path, \"w\") as json_file:\n",
    "            json.dump(keypoints_data, json_file, indent=4)\n",
    "\n",
    "print(\"Upright posture analysis complete! JSON files saved in 'keypoints' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 sequences with labels.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Path to the keypoints folder for upright posture analysis\n",
    "keypoints_folder = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/keypoints\"\n",
    "\n",
    "# Lists to store sequences and labels\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "# Process keypoint JSON files\n",
    "for file in os.listdir(keypoints_folder):\n",
    "    if file.endswith(\"_keypoints.json\"):\n",
    "        file_path = os.path.join(keypoints_folder, file)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Extract upright posture indicators across all frames\n",
    "        posture_data = [\n",
    "            [int(frame[\"left_upright\"]), int(frame[\"right_upright\"])]\n",
    "            for frame in data\n",
    "        ]\n",
    "        sequences.append(posture_data)\n",
    "\n",
    "        # Extract label from filename (assumes label is the first part of filename)\n",
    "        try:\n",
    "            label = float(file.split(\"_\")[0])  # Modify if filename structure differs\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Unable to extract label from {file}\")\n",
    "            continue\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "# Pad sequences to ensure uniform input shape\n",
    "if sequences:\n",
    "    max_len = max(len(seq) for seq in sequences)\n",
    "    sequences = pad_sequences(sequences, maxlen=max_len, padding='post', dtype='float32')\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    print(f\"Loaded {len(sequences)} sequences with labels.\")\n",
    "else:\n",
    "    print(\"No sequences found in the keypoints folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented dataset size: 75\n"
     ]
    }
   ],
   "source": [
    "def augment_data(sequence):\n",
    "    augmented_sequences = []\n",
    "\n",
    "    # Original\n",
    "    augmented_sequences.append(sequence)\n",
    "\n",
    "    # Mirrored (flip angles horizontally)\n",
    "    mirrored = -sequence\n",
    "    augmented_sequences.append(mirrored)\n",
    "\n",
    "    # Rotation (add a small angle offset)\n",
    "    rotated = sequence + np.random.uniform(-10, 10, size=sequence.shape)\n",
    "    augmented_sequences.append(rotated)\n",
    "\n",
    "    # Noise (add random Gaussian noise)\n",
    "    noisy = sequence + np.random.normal(0, 0.05, size=sequence.shape)\n",
    "    augmented_sequences.append(noisy)\n",
    "\n",
    "    # Scaled (adjust by a small percentage)\n",
    "    scaled = sequence * np.random.uniform(0.9, 1.1)\n",
    "    augmented_sequences.append(scaled)\n",
    "\n",
    "    return augmented_sequences\n",
    "\n",
    "augmented_sequences = []\n",
    "augmented_labels = []\n",
    "\n",
    "for seq, label in zip(sequences, labels):\n",
    "    augmented = augment_data(seq)\n",
    "    augmented_sequences.extend(augmented)\n",
    "    augmented_labels.extend([label] * len(augmented))\n",
    "\n",
    "augmented_sequences = np.array(augmented_sequences)\n",
    "augmented_labels = np.array(augmented_labels)\n",
    "\n",
    "print(f\"Augmented dataset size: {len(augmented_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 57, Validation samples: 18\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    augmented_sequences, augmented_labels, test_size=4/17, random_state=42\n",
    ")\n",
    "\n",
    "# Ensure correct shape for LSTM input (samples, timesteps, features)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 2))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 2))\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_10                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_11                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_9 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_10                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_11                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define enhanced LSTM model\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(128, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1], 2))),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Bidirectional(LSTM(64, activation='tanh', return_sequences=True)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Bidirectional(LSTM(32, activation='tanh', return_sequences=False)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output: Regression score\n",
    "])\n",
    "\n",
    "# Compile the model with a reduced learning rate for better convergence\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse', metrics=['mae'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - loss: 0.7033 - mae: 0.7257 - val_loss: 0.4382 - val_mae: 0.5452\n",
      "Epoch 2/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.5611 - mae: 0.6679 - val_loss: 0.3097 - val_mae: 0.5221\n",
      "Epoch 3/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.3507 - mae: 0.5405 - val_loss: 0.2823 - val_mae: 0.5011\n",
      "Epoch 4/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.2865 - mae: 0.4939 - val_loss: 0.2840 - val_mae: 0.4887\n",
      "Epoch 5/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.2198 - mae: 0.4025 - val_loss: 0.2893 - val_mae: 0.4857\n",
      "Epoch 6/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.2436 - mae: 0.4539 - val_loss: 0.2761 - val_mae: 0.5006\n",
      "Epoch 7/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.2038 - mae: 0.4164 - val_loss: 0.2861 - val_mae: 0.4962\n",
      "Epoch 8/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.1921 - mae: 0.3891 - val_loss: 0.3340 - val_mae: 0.4826\n",
      "Epoch 9/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.2140 - mae: 0.3753 - val_loss: 0.2524 - val_mae: 0.4812\n",
      "Epoch 10/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.2003 - mae: 0.4159 - val_loss: 0.2621 - val_mae: 0.4712\n",
      "Epoch 11/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.1654 - mae: 0.3580 - val_loss: 0.2855 - val_mae: 0.4639\n",
      "Epoch 12/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.1874 - mae: 0.3841 - val_loss: 0.2640 - val_mae: 0.4661\n",
      "Epoch 13/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1402 - mae: 0.3127 - val_loss: 0.2902 - val_mae: 0.4626\n",
      "Epoch 14/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.2312 - mae: 0.4144 - val_loss: 0.2726 - val_mae: 0.4677\n",
      "Epoch 15/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1677 - mae: 0.3559 - val_loss: 0.2785 - val_mae: 0.4623\n",
      "Epoch 16/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1581 - mae: 0.3281 - val_loss: 0.2614 - val_mae: 0.4671\n",
      "Epoch 17/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1668 - mae: 0.3733 - val_loss: 0.2641 - val_mae: 0.4648\n",
      "Epoch 18/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1539 - mae: 0.3437 - val_loss: 0.2556 - val_mae: 0.4623\n",
      "Epoch 19/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1451 - mae: 0.3378 - val_loss: 0.2596 - val_mae: 0.4470\n",
      "Epoch 20/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1536 - mae: 0.3472 - val_loss: 0.2565 - val_mae: 0.4564\n",
      "Epoch 21/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1939 - mae: 0.3982 - val_loss: 0.2760 - val_mae: 0.4528\n",
      "Epoch 22/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1498 - mae: 0.2874 - val_loss: 0.3205 - val_mae: 0.4549\n",
      "Epoch 23/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.2280 - mae: 0.3712 - val_loss: 0.2565 - val_mae: 0.4596\n",
      "Epoch 24/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1509 - mae: 0.3478 - val_loss: 0.2425 - val_mae: 0.4582\n",
      "Epoch 25/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.1379 - mae: 0.3050 - val_loss: 0.2627 - val_mae: 0.4469\n",
      "Epoch 26/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1837 - mae: 0.3660 - val_loss: 0.2766 - val_mae: 0.4475\n",
      "Epoch 27/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1760 - mae: 0.3455 - val_loss: 0.2724 - val_mae: 0.4452\n",
      "Epoch 28/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1649 - mae: 0.3349 - val_loss: 0.2767 - val_mae: 0.4490\n",
      "Epoch 29/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1652 - mae: 0.3368 - val_loss: 0.2595 - val_mae: 0.4578\n",
      "Epoch 30/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1567 - mae: 0.3297 - val_loss: 0.2547 - val_mae: 0.4583\n",
      "Epoch 31/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1554 - mae: 0.3263 - val_loss: 0.2519 - val_mae: 0.4547\n",
      "Epoch 32/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1635 - mae: 0.3587 - val_loss: 0.2548 - val_mae: 0.4512\n",
      "Epoch 33/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1644 - mae: 0.3416 - val_loss: 0.2731 - val_mae: 0.4693\n",
      "Epoch 34/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1521 - mae: 0.3258 - val_loss: 0.2828 - val_mae: 0.4619\n",
      "Epoch 35/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.1530 - mae: 0.3306 - val_loss: 0.2677 - val_mae: 0.4482\n",
      "Epoch 36/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1371 - mae: 0.3001 - val_loss: 0.2601 - val_mae: 0.4379\n",
      "Epoch 37/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1658 - mae: 0.3452 - val_loss: 0.2583 - val_mae: 0.4384\n",
      "Epoch 38/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1361 - mae: 0.3004 - val_loss: 0.2743 - val_mae: 0.4483\n",
      "Epoch 39/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1555 - mae: 0.3202 - val_loss: 0.2838 - val_mae: 0.4602\n",
      "Epoch 40/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1381 - mae: 0.2937 - val_loss: 0.2628 - val_mae: 0.4599\n",
      "Epoch 41/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1725 - mae: 0.3478 - val_loss: 0.2659 - val_mae: 0.4590\n",
      "Epoch 42/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1637 - mae: 0.3235 - val_loss: 0.2847 - val_mae: 0.4629\n",
      "Epoch 43/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.1181 - mae: 0.2734 - val_loss: 0.2994 - val_mae: 0.4608\n",
      "Epoch 44/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.1192 - mae: 0.2715 - val_loss: 0.2916 - val_mae: 0.4740\n",
      "Epoch 45/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1474 - mae: 0.3107 - val_loss: 0.2909 - val_mae: 0.4776\n",
      "Epoch 46/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1290 - mae: 0.2921 - val_loss: 0.2858 - val_mae: 0.4687\n",
      "Epoch 47/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1569 - mae: 0.3493 - val_loss: 0.2727 - val_mae: 0.4617\n",
      "Epoch 48/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1635 - mae: 0.3540 - val_loss: 0.2586 - val_mae: 0.4486\n",
      "Epoch 49/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1717 - mae: 0.3593 - val_loss: 0.2550 - val_mae: 0.4310\n",
      "Epoch 50/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.1439 - mae: 0.3010 - val_loss: 0.2586 - val_mae: 0.4389\n",
      "Epoch 51/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.1487 - mae: 0.3339 - val_loss: 0.2484 - val_mae: 0.4367\n",
      "Epoch 52/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.1415 - mae: 0.3080 - val_loss: 0.2572 - val_mae: 0.4452\n",
      "Epoch 53/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1433 - mae: 0.3141 - val_loss: 0.2581 - val_mae: 0.4328\n",
      "Epoch 54/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1555 - mae: 0.3271 - val_loss: 0.2494 - val_mae: 0.4281\n",
      "Epoch 55/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1301 - mae: 0.2993 - val_loss: 0.2322 - val_mae: 0.4212\n",
      "Epoch 56/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1478 - mae: 0.3283 - val_loss: 0.2005 - val_mae: 0.3926\n",
      "Epoch 57/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1703 - mae: 0.3368 - val_loss: 0.2076 - val_mae: 0.4100\n",
      "Epoch 58/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1676 - mae: 0.3396 - val_loss: 0.2536 - val_mae: 0.4459\n",
      "Epoch 59/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1344 - mae: 0.3038 - val_loss: 0.2343 - val_mae: 0.4404\n",
      "Epoch 60/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1427 - mae: 0.3235 - val_loss: 0.2421 - val_mae: 0.4462\n",
      "Epoch 61/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1540 - mae: 0.3329 - val_loss: 0.2643 - val_mae: 0.4456\n",
      "Epoch 62/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1808 - mae: 0.3460 - val_loss: 0.2659 - val_mae: 0.4467\n",
      "Epoch 63/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1510 - mae: 0.3154 - val_loss: 0.2579 - val_mae: 0.4457\n",
      "Epoch 64/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1345 - mae: 0.2972 - val_loss: 0.2486 - val_mae: 0.4508\n",
      "Epoch 65/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1617 - mae: 0.3359 - val_loss: 0.2464 - val_mae: 0.4474\n",
      "Epoch 66/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1509 - mae: 0.3350 - val_loss: 0.2522 - val_mae: 0.4392\n",
      "Epoch 67/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1526 - mae: 0.3289 - val_loss: 0.2580 - val_mae: 0.4376\n",
      "Epoch 68/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.1469 - mae: 0.3085 - val_loss: 0.2544 - val_mae: 0.4352\n",
      "Epoch 69/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - loss: 0.1181 - mae: 0.2727 - val_loss: 0.2523 - val_mae: 0.4400\n",
      "Epoch 70/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.1710 - mae: 0.3588 - val_loss: 0.2582 - val_mae: 0.4363\n",
      "Epoch 71/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.1446 - mae: 0.3095 - val_loss: 0.2617 - val_mae: 0.4397\n",
      "Epoch 72/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1602 - mae: 0.3293 - val_loss: 0.2673 - val_mae: 0.4485\n",
      "Epoch 73/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1595 - mae: 0.3349 - val_loss: 0.2778 - val_mae: 0.4515\n",
      "Epoch 74/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1251 - mae: 0.2726 - val_loss: 0.2821 - val_mae: 0.4589\n",
      "Epoch 75/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1440 - mae: 0.3124 - val_loss: 0.2684 - val_mae: 0.4580\n",
      "Epoch 76/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1355 - mae: 0.3076 - val_loss: 0.2509 - val_mae: 0.4477\n",
      "Epoch 77/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1681 - mae: 0.3532 - val_loss: 0.2508 - val_mae: 0.4440\n",
      "Epoch 78/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1384 - mae: 0.3016 - val_loss: 0.2681 - val_mae: 0.4568\n",
      "Epoch 79/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1570 - mae: 0.3371 - val_loss: 0.2878 - val_mae: 0.4664\n",
      "Epoch 80/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1172 - mae: 0.2761 - val_loss: 0.2747 - val_mae: 0.4445\n",
      "Epoch 81/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1415 - mae: 0.3224 - val_loss: 0.2723 - val_mae: 0.4459\n",
      "Epoch 82/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1440 - mae: 0.3080 - val_loss: 0.2739 - val_mae: 0.4467\n",
      "Epoch 83/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1400 - mae: 0.3172 - val_loss: 0.2870 - val_mae: 0.4644\n",
      "Epoch 84/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1376 - mae: 0.2879 - val_loss: 0.2868 - val_mae: 0.4575\n",
      "Epoch 85/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1619 - mae: 0.3282 - val_loss: 0.2708 - val_mae: 0.4441\n",
      "Epoch 86/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1813 - mae: 0.3705 - val_loss: 0.2657 - val_mae: 0.4457\n",
      "Epoch 87/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.1354 - mae: 0.3059 - val_loss: 0.2706 - val_mae: 0.4518\n",
      "Epoch 88/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1225 - mae: 0.2847 - val_loss: 0.2745 - val_mae: 0.4582\n",
      "Epoch 89/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.1362 - mae: 0.3007 - val_loss: 0.2691 - val_mae: 0.4528\n",
      "Epoch 90/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1714 - mae: 0.3558 - val_loss: 0.2706 - val_mae: 0.4497\n",
      "Epoch 91/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1362 - mae: 0.2986 - val_loss: 0.2745 - val_mae: 0.4521\n",
      "Epoch 92/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1260 - mae: 0.2777 - val_loss: 0.2635 - val_mae: 0.4399\n",
      "Epoch 93/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1772 - mae: 0.3567 - val_loss: 0.2627 - val_mae: 0.4504\n",
      "Epoch 94/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1580 - mae: 0.3463 - val_loss: 0.2778 - val_mae: 0.4602\n",
      "Epoch 95/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1235 - mae: 0.2867 - val_loss: 0.2631 - val_mae: 0.4492\n",
      "Epoch 96/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1443 - mae: 0.3044 - val_loss: 0.2655 - val_mae: 0.4470\n",
      "Epoch 97/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1554 - mae: 0.3366 - val_loss: 0.2687 - val_mae: 0.4447\n",
      "Epoch 98/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1637 - mae: 0.3314 - val_loss: 0.2744 - val_mae: 0.4517\n",
      "Epoch 99/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.1610 - mae: 0.3311 - val_loss: 0.2674 - val_mae: 0.4492\n",
      "Epoch 100/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1444 - mae: 0.3038 - val_loss: 0.2512 - val_mae: 0.4373\n",
      "Epoch 101/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1459 - mae: 0.3144 - val_loss: 0.2570 - val_mae: 0.4399\n",
      "Epoch 102/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1457 - mae: 0.3257 - val_loss: 0.2620 - val_mae: 0.4423\n",
      "Epoch 103/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1659 - mae: 0.3455 - val_loss: 0.2722 - val_mae: 0.4532\n",
      "Epoch 104/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1839 - mae: 0.3354 - val_loss: 0.2771 - val_mae: 0.4671\n",
      "Epoch 105/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1402 - mae: 0.3116 - val_loss: 0.2758 - val_mae: 0.4715\n",
      "Epoch 106/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1606 - mae: 0.3303 - val_loss: 0.2835 - val_mae: 0.4716\n",
      "Epoch 107/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.1461 - mae: 0.3055 - val_loss: 0.2777 - val_mae: 0.4681\n",
      "Epoch 108/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1393 - mae: 0.3159 - val_loss: 0.3087 - val_mae: 0.4720\n",
      "Epoch 109/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1479 - mae: 0.2864 - val_loss: 0.2770 - val_mae: 0.4632\n",
      "Epoch 110/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1718 - mae: 0.3451 - val_loss: 0.2665 - val_mae: 0.4647\n",
      "Epoch 111/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1598 - mae: 0.3316 - val_loss: 0.2626 - val_mae: 0.4627\n",
      "Epoch 112/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1601 - mae: 0.3435 - val_loss: 0.2595 - val_mae: 0.4518\n",
      "Epoch 113/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1455 - mae: 0.3094 - val_loss: 0.2533 - val_mae: 0.4429\n",
      "Epoch 114/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.1613 - mae: 0.3291 - val_loss: 0.2576 - val_mae: 0.4458\n",
      "Epoch 115/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.1330 - mae: 0.3089 - val_loss: 0.2606 - val_mae: 0.4470\n",
      "Epoch 116/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.1360 - mae: 0.3049 - val_loss: 0.2657 - val_mae: 0.4504\n",
      "Epoch 117/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1593 - mae: 0.3290 - val_loss: 0.2597 - val_mae: 0.4511\n",
      "Epoch 118/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1348 - mae: 0.3016 - val_loss: 0.2665 - val_mae: 0.4568\n",
      "Epoch 119/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1469 - mae: 0.3192 - val_loss: 0.2775 - val_mae: 0.4629\n",
      "Epoch 120/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1469 - mae: 0.2971 - val_loss: 0.2779 - val_mae: 0.4545\n",
      "Epoch 121/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1248 - mae: 0.2884 - val_loss: 0.2605 - val_mae: 0.4501\n",
      "Epoch 122/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.1332 - mae: 0.2874 - val_loss: 0.2606 - val_mae: 0.4540\n",
      "Epoch 123/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.1448 - mae: 0.3126 - val_loss: 0.2615 - val_mae: 0.4528\n",
      "Epoch 124/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1663 - mae: 0.3329 - val_loss: 0.2682 - val_mae: 0.4520\n",
      "Epoch 125/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.1674 - mae: 0.3442 - val_loss: 0.2795 - val_mae: 0.4546\n",
      "Epoch 126/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1635 - mae: 0.3173 - val_loss: 0.2755 - val_mae: 0.4531\n",
      "Epoch 127/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1601 - mae: 0.3284 - val_loss: 0.2609 - val_mae: 0.4533\n",
      "Epoch 128/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1228 - mae: 0.2796 - val_loss: 0.2579 - val_mae: 0.4493\n",
      "Epoch 129/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1540 - mae: 0.3315 - val_loss: 0.2608 - val_mae: 0.4481\n",
      "Epoch 130/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1621 - mae: 0.3374 - val_loss: 0.2791 - val_mae: 0.4817\n",
      "Epoch 131/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - loss: 0.1806 - mae: 0.3464 - val_loss: 0.2522 - val_mae: 0.4581\n",
      "Epoch 132/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.1599 - mae: 0.3341 - val_loss: 0.2528 - val_mae: 0.4469\n",
      "Epoch 133/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.1408 - mae: 0.3125 - val_loss: 0.2684 - val_mae: 0.4510\n",
      "Epoch 134/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1344 - mae: 0.2918 - val_loss: 0.2641 - val_mae: 0.4438\n",
      "Epoch 135/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1577 - mae: 0.3333 - val_loss: 0.2567 - val_mae: 0.4423\n",
      "Epoch 136/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1532 - mae: 0.3254 - val_loss: 0.2788 - val_mae: 0.4488\n",
      "Epoch 137/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1499 - mae: 0.3188 - val_loss: 0.2730 - val_mae: 0.4471\n",
      "Epoch 138/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1707 - mae: 0.3537 - val_loss: 0.2768 - val_mae: 0.4535\n",
      "Epoch 139/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.1467 - mae: 0.3166 - val_loss: 0.2886 - val_mae: 0.4819\n",
      "Epoch 140/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.1585 - mae: 0.3373 - val_loss: 0.2837 - val_mae: 0.4824\n",
      "Epoch 141/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1346 - mae: 0.3064 - val_loss: 0.2808 - val_mae: 0.4763\n",
      "Epoch 142/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1299 - mae: 0.2891 - val_loss: 0.2829 - val_mae: 0.4659\n",
      "Epoch 143/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.1501 - mae: 0.3275 - val_loss: 0.2657 - val_mae: 0.4584\n",
      "Epoch 144/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1325 - mae: 0.3033 - val_loss: 0.2663 - val_mae: 0.4529\n",
      "Epoch 145/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1415 - mae: 0.3067 - val_loss: 0.2599 - val_mae: 0.4493\n",
      "Epoch 146/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1608 - mae: 0.3387 - val_loss: 0.2573 - val_mae: 0.4431\n",
      "Epoch 147/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1500 - mae: 0.3244 - val_loss: 0.2594 - val_mae: 0.4451\n",
      "Epoch 148/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1356 - mae: 0.2990 - val_loss: 0.2664 - val_mae: 0.4514\n",
      "Epoch 149/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1638 - mae: 0.3379 - val_loss: 0.2713 - val_mae: 0.4471\n",
      "Epoch 150/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1503 - mae: 0.3159 - val_loss: 0.2716 - val_mae: 0.4459\n",
      "Epoch 151/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.1470 - mae: 0.3112 - val_loss: 0.2851 - val_mae: 0.4715\n",
      "Epoch 152/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1480 - mae: 0.3137 - val_loss: 0.2950 - val_mae: 0.4737\n",
      "Epoch 153/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1450 - mae: 0.2928 - val_loss: 0.2852 - val_mae: 0.4863\n",
      "Epoch 154/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1548 - mae: 0.3364 - val_loss: 0.2850 - val_mae: 0.4888\n",
      "Epoch 155/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1901 - mae: 0.3767 - val_loss: 0.2765 - val_mae: 0.4720\n",
      "Epoch 156/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1541 - mae: 0.3206 - val_loss: 0.2828 - val_mae: 0.4758\n",
      "Epoch 157/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.1596 - mae: 0.3421 - val_loss: 0.2732 - val_mae: 0.4603\n",
      "Epoch 158/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1633 - mae: 0.3357 - val_loss: 0.2694 - val_mae: 0.4457\n",
      "Epoch 159/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1159 - mae: 0.2718 - val_loss: 0.2654 - val_mae: 0.4486\n",
      "Epoch 160/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1324 - mae: 0.2915 - val_loss: 0.2729 - val_mae: 0.4520\n",
      "Epoch 161/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1294 - mae: 0.3051 - val_loss: 0.2728 - val_mae: 0.4518\n",
      "Epoch 162/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1458 - mae: 0.3002 - val_loss: 0.2586 - val_mae: 0.4513\n",
      "Epoch 163/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1464 - mae: 0.3202 - val_loss: 0.2584 - val_mae: 0.4499\n",
      "Epoch 164/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1372 - mae: 0.2963 - val_loss: 0.2589 - val_mae: 0.4489\n",
      "Epoch 165/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1440 - mae: 0.3165 - val_loss: 0.2591 - val_mae: 0.4459\n",
      "Epoch 166/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.1347 - mae: 0.2976 - val_loss: 0.2711 - val_mae: 0.4474\n",
      "Epoch 167/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.1441 - mae: 0.3054 - val_loss: 0.2649 - val_mae: 0.4445\n",
      "Epoch 168/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1391 - mae: 0.3039 - val_loss: 0.2704 - val_mae: 0.4444\n",
      "Epoch 169/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1378 - mae: 0.3022 - val_loss: 0.2818 - val_mae: 0.4543\n",
      "Epoch 170/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1553 - mae: 0.2992 - val_loss: 0.2747 - val_mae: 0.4481\n",
      "Epoch 171/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1386 - mae: 0.2980 - val_loss: 0.2659 - val_mae: 0.4433\n",
      "Epoch 172/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1753 - mae: 0.3416 - val_loss: 0.2623 - val_mae: 0.4418\n",
      "Epoch 173/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1412 - mae: 0.3100 - val_loss: 0.2773 - val_mae: 0.4578\n",
      "Epoch 174/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1479 - mae: 0.3266 - val_loss: 0.2661 - val_mae: 0.4404\n",
      "Epoch 175/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1396 - mae: 0.2933 - val_loss: 0.2704 - val_mae: 0.4424\n",
      "Epoch 176/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1361 - mae: 0.2870 - val_loss: 0.2675 - val_mae: 0.4486\n",
      "Epoch 177/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1439 - mae: 0.3101 - val_loss: 0.2729 - val_mae: 0.4557\n",
      "Epoch 178/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.1487 - mae: 0.3208 - val_loss: 0.2859 - val_mae: 0.4638\n",
      "Epoch 179/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1628 - mae: 0.3328 - val_loss: 0.2709 - val_mae: 0.4527\n",
      "Epoch 180/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1438 - mae: 0.3072 - val_loss: 0.2557 - val_mae: 0.4390\n",
      "Epoch 181/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1330 - mae: 0.2964 - val_loss: 0.2492 - val_mae: 0.4402\n",
      "Epoch 182/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1535 - mae: 0.3353 - val_loss: 0.2530 - val_mae: 0.4395\n",
      "Epoch 183/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.1408 - mae: 0.3035 - val_loss: 0.2601 - val_mae: 0.4395\n",
      "Epoch 184/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1340 - mae: 0.3020 - val_loss: 0.2658 - val_mae: 0.4448\n",
      "Epoch 185/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1348 - mae: 0.2819 - val_loss: 0.2709 - val_mae: 0.4449\n",
      "Epoch 186/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1445 - mae: 0.3033 - val_loss: 0.2612 - val_mae: 0.4414\n",
      "Epoch 187/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1087 - mae: 0.2479 - val_loss: 0.2529 - val_mae: 0.4420\n",
      "Epoch 188/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1257 - mae: 0.2850 - val_loss: 0.2431 - val_mae: 0.4459\n",
      "Epoch 189/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.1473 - mae: 0.3068 - val_loss: 0.2491 - val_mae: 0.4414\n",
      "Epoch 190/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1426 - mae: 0.3126 - val_loss: 0.2671 - val_mae: 0.4417\n",
      "Epoch 191/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1197 - mae: 0.2742 - val_loss: 0.2696 - val_mae: 0.4437\n",
      "Epoch 192/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1549 - mae: 0.3232 - val_loss: 0.2586 - val_mae: 0.4392\n",
      "Epoch 193/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.1494 - mae: 0.3169 - val_loss: 0.2605 - val_mae: 0.4411\n",
      "Epoch 194/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.1599 - mae: 0.3428 - val_loss: 0.2759 - val_mae: 0.4532\n",
      "Epoch 195/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1379 - mae: 0.3202 - val_loss: 0.2710 - val_mae: 0.4490\n",
      "Epoch 196/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1660 - mae: 0.3483 - val_loss: 0.2554 - val_mae: 0.4405\n",
      "Epoch 197/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1649 - mae: 0.3319 - val_loss: 0.2459 - val_mae: 0.4406\n",
      "Epoch 198/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1484 - mae: 0.3055 - val_loss: 0.2496 - val_mae: 0.4449\n",
      "Epoch 199/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.1616 - mae: 0.3277 - val_loss: 0.2590 - val_mae: 0.4388\n",
      "Epoch 200/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1375 - mae: 0.3004 - val_loss: 0.2473 - val_mae: 0.4354\n",
      "Epoch 201/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1507 - mae: 0.3156 - val_loss: 0.2510 - val_mae: 0.4330\n",
      "Epoch 202/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.1459 - mae: 0.3070 - val_loss: 0.2640 - val_mae: 0.4489\n",
      "Epoch 203/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.1372 - mae: 0.2904 - val_loss: 0.2632 - val_mae: 0.4478\n",
      "Epoch 204/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1409 - mae: 0.3034 - val_loss: 0.2566 - val_mae: 0.4381\n",
      "Epoch 205/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1563 - mae: 0.3198 - val_loss: 0.2513 - val_mae: 0.4405\n",
      "Epoch 206/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1366 - mae: 0.3027 - val_loss: 0.2564 - val_mae: 0.4502\n",
      "Epoch 207/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1329 - mae: 0.2922 - val_loss: 0.2634 - val_mae: 0.4533\n",
      "Epoch 208/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1678 - mae: 0.3472 - val_loss: 0.2613 - val_mae: 0.4490\n",
      "Epoch 209/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1425 - mae: 0.3025 - val_loss: 0.2788 - val_mae: 0.4543\n",
      "Epoch 210/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - loss: 0.1452 - mae: 0.2993 - val_loss: 0.2777 - val_mae: 0.4534\n",
      "Epoch 211/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - loss: 0.1602 - mae: 0.3283 - val_loss: 0.2595 - val_mae: 0.4424\n",
      "Epoch 212/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.1529 - mae: 0.3159 - val_loss: 0.2532 - val_mae: 0.4380\n",
      "Epoch 213/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1753 - mae: 0.3541 - val_loss: 0.2541 - val_mae: 0.4408\n",
      "Epoch 214/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1328 - mae: 0.2825 - val_loss: 0.2581 - val_mae: 0.4396\n",
      "Epoch 215/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1311 - mae: 0.2826 - val_loss: 0.2665 - val_mae: 0.4504\n",
      "Epoch 216/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1250 - mae: 0.2847 - val_loss: 0.2729 - val_mae: 0.4527\n",
      "Epoch 217/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.1450 - mae: 0.3228 - val_loss: 0.2735 - val_mae: 0.4499\n",
      "Epoch 218/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - loss: 0.1638 - mae: 0.3296 - val_loss: 0.2668 - val_mae: 0.4427\n",
      "Epoch 219/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1308 - mae: 0.2869 - val_loss: 0.2688 - val_mae: 0.4435\n",
      "Epoch 220/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.1404 - mae: 0.2953 - val_loss: 0.2597 - val_mae: 0.4435\n",
      "Epoch 221/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1467 - mae: 0.3119 - val_loss: 0.2569 - val_mae: 0.4422\n",
      "Epoch 222/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1706 - mae: 0.3594 - val_loss: 0.2663 - val_mae: 0.4448\n",
      "Epoch 223/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1611 - mae: 0.3307 - val_loss: 0.2739 - val_mae: 0.4526\n",
      "Epoch 224/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1609 - mae: 0.3229 - val_loss: 0.2624 - val_mae: 0.4435\n",
      "Epoch 225/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1445 - mae: 0.3210 - val_loss: 0.2505 - val_mae: 0.4447\n",
      "Epoch 226/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - loss: 0.1656 - mae: 0.3385 - val_loss: 0.2492 - val_mae: 0.4461\n",
      "Epoch 227/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.1293 - mae: 0.2849 - val_loss: 0.2536 - val_mae: 0.4469\n",
      "Epoch 228/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - loss: 0.1507 - mae: 0.3204 - val_loss: 0.2555 - val_mae: 0.4450\n",
      "Epoch 229/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1520 - mae: 0.3328 - val_loss: 0.2609 - val_mae: 0.4444\n",
      "Epoch 230/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1552 - mae: 0.3290 - val_loss: 0.2676 - val_mae: 0.4472\n",
      "Epoch 231/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1279 - mae: 0.2940 - val_loss: 0.2785 - val_mae: 0.4603\n",
      "Epoch 232/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1402 - mae: 0.2948 - val_loss: 0.2630 - val_mae: 0.4453\n",
      "Epoch 233/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1374 - mae: 0.3063 - val_loss: 0.2581 - val_mae: 0.4379\n",
      "Epoch 234/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.1217 - mae: 0.2603 - val_loss: 0.2603 - val_mae: 0.4402\n",
      "Epoch 235/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.1335 - mae: 0.2770 - val_loss: 0.2582 - val_mae: 0.4392\n",
      "Epoch 236/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.1241 - mae: 0.2829 - val_loss: 0.2647 - val_mae: 0.4436\n",
      "Epoch 237/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - loss: 0.1246 - mae: 0.2787 - val_loss: 0.2699 - val_mae: 0.4477\n",
      "Epoch 238/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1592 - mae: 0.3300 - val_loss: 0.2640 - val_mae: 0.4448\n",
      "Epoch 239/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1482 - mae: 0.3055 - val_loss: 0.2659 - val_mae: 0.4448\n",
      "Epoch 240/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1393 - mae: 0.2968 - val_loss: 0.2775 - val_mae: 0.4589\n",
      "Epoch 241/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1362 - mae: 0.2988 - val_loss: 0.2829 - val_mae: 0.4628\n",
      "Epoch 242/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1245 - mae: 0.2827 - val_loss: 0.2809 - val_mae: 0.4620\n",
      "Epoch 243/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.1751 - mae: 0.3446 - val_loss: 0.2700 - val_mae: 0.4594\n",
      "Epoch 244/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 0.1465 - mae: 0.3155 - val_loss: 0.2684 - val_mae: 0.4584\n",
      "Epoch 245/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1732 - mae: 0.3495 - val_loss: 0.2787 - val_mae: 0.4574\n",
      "Epoch 246/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1615 - mae: 0.3313 - val_loss: 0.2839 - val_mae: 0.4559\n",
      "Epoch 247/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1487 - mae: 0.3072 - val_loss: 0.2853 - val_mae: 0.4535\n",
      "Epoch 248/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1382 - mae: 0.2884 - val_loss: 0.2715 - val_mae: 0.4528\n",
      "Epoch 249/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1469 - mae: 0.2946 - val_loss: 0.2551 - val_mae: 0.4482\n",
      "Epoch 250/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1538 - mae: 0.3319 - val_loss: 0.2551 - val_mae: 0.4482\n",
      "Epoch 251/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.1449 - mae: 0.3046 - val_loss: 0.2500 - val_mae: 0.4454\n",
      "Epoch 252/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1438 - mae: 0.3130 - val_loss: 0.2641 - val_mae: 0.4461\n",
      "Epoch 253/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1291 - mae: 0.2754 - val_loss: 0.2939 - val_mae: 0.4587\n",
      "Epoch 254/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.1540 - mae: 0.3199 - val_loss: 0.2704 - val_mae: 0.4481\n",
      "Epoch 255/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1507 - mae: 0.3122 - val_loss: 0.2626 - val_mae: 0.4525\n",
      "Epoch 256/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1578 - mae: 0.3224 - val_loss: 0.2697 - val_mae: 0.4515\n",
      "Epoch 257/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1422 - mae: 0.2983 - val_loss: 0.2702 - val_mae: 0.4504\n",
      "Epoch 258/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1410 - mae: 0.3132 - val_loss: 0.2806 - val_mae: 0.4568\n",
      "Epoch 259/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1599 - mae: 0.3239 - val_loss: 0.2795 - val_mae: 0.4546\n",
      "Epoch 260/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.1304 - mae: 0.2868 - val_loss: 0.2733 - val_mae: 0.4499\n",
      "Epoch 261/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1287 - mae: 0.2822 - val_loss: 0.2564 - val_mae: 0.4457\n",
      "Epoch 262/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.1221 - mae: 0.2762 - val_loss: 0.2565 - val_mae: 0.4470\n",
      "Epoch 263/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.1726 - mae: 0.3569 - val_loss: 0.2595 - val_mae: 0.4473\n",
      "Epoch 264/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1529 - mae: 0.3278 - val_loss: 0.2591 - val_mae: 0.4458\n",
      "Epoch 265/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1295 - mae: 0.2792 - val_loss: 0.2629 - val_mae: 0.4461\n",
      "Epoch 266/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1431 - mae: 0.2970 - val_loss: 0.2699 - val_mae: 0.4461\n",
      "Epoch 267/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1565 - mae: 0.3334 - val_loss: 0.2792 - val_mae: 0.4592\n",
      "Epoch 268/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1601 - mae: 0.3285 - val_loss: 0.2817 - val_mae: 0.4581\n",
      "Epoch 269/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1390 - mae: 0.2935 - val_loss: 0.2906 - val_mae: 0.4574\n",
      "Epoch 270/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.1394 - mae: 0.2954 - val_loss: 0.2661 - val_mae: 0.4417\n",
      "Epoch 271/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1352 - mae: 0.2968 - val_loss: 0.2582 - val_mae: 0.4423\n",
      "Epoch 272/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1596 - mae: 0.3253 - val_loss: 0.2586 - val_mae: 0.4433\n",
      "Epoch 273/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1666 - mae: 0.3352 - val_loss: 0.2725 - val_mae: 0.4503\n",
      "Epoch 274/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1497 - mae: 0.3080 - val_loss: 0.2761 - val_mae: 0.4536\n",
      "Epoch 275/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1368 - mae: 0.2964 - val_loss: 0.2761 - val_mae: 0.4517\n",
      "Epoch 276/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1344 - mae: 0.2908 - val_loss: 0.2646 - val_mae: 0.4491\n",
      "Epoch 277/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1361 - mae: 0.2840 - val_loss: 0.2590 - val_mae: 0.4483\n",
      "Epoch 278/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1263 - mae: 0.2742 - val_loss: 0.2692 - val_mae: 0.4488\n",
      "Epoch 279/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.1561 - mae: 0.3234 - val_loss: 0.2719 - val_mae: 0.4507\n",
      "Epoch 280/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1460 - mae: 0.2962 - val_loss: 0.2811 - val_mae: 0.4504\n",
      "Epoch 281/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1525 - mae: 0.3173 - val_loss: 0.2825 - val_mae: 0.4506\n",
      "Epoch 282/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1291 - mae: 0.2690 - val_loss: 0.2798 - val_mae: 0.4498\n",
      "Epoch 283/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1281 - mae: 0.2783 - val_loss: 0.2755 - val_mae: 0.4478\n",
      "Epoch 284/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1659 - mae: 0.3296 - val_loss: 0.2589 - val_mae: 0.4479\n",
      "Epoch 285/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1438 - mae: 0.3199 - val_loss: 0.2597 - val_mae: 0.4468\n",
      "Epoch 286/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1342 - mae: 0.2821 - val_loss: 0.2746 - val_mae: 0.4511\n",
      "Epoch 287/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 0.1403 - mae: 0.3085 - val_loss: 0.2876 - val_mae: 0.4579\n",
      "Epoch 288/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1493 - mae: 0.3185 - val_loss: 0.2694 - val_mae: 0.4505\n",
      "Epoch 289/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.1268 - mae: 0.2780 - val_loss: 0.2677 - val_mae: 0.4500\n",
      "Epoch 290/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1370 - mae: 0.2934 - val_loss: 0.2597 - val_mae: 0.4496\n",
      "Epoch 291/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1698 - mae: 0.3332 - val_loss: 0.2584 - val_mae: 0.4486\n",
      "Epoch 292/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1526 - mae: 0.3133 - val_loss: 0.2584 - val_mae: 0.4482\n",
      "Epoch 293/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1508 - mae: 0.3180 - val_loss: 0.2612 - val_mae: 0.4470\n",
      "Epoch 294/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - loss: 0.1396 - mae: 0.3056 - val_loss: 0.2647 - val_mae: 0.4471\n",
      "Epoch 295/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1269 - mae: 0.2803 - val_loss: 0.2665 - val_mae: 0.4477\n",
      "Epoch 296/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1423 - mae: 0.3041 - val_loss: 0.2628 - val_mae: 0.4449\n",
      "Epoch 297/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - loss: 0.1468 - mae: 0.3089 - val_loss: 0.2656 - val_mae: 0.4456\n",
      "Epoch 298/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1629 - mae: 0.3328 - val_loss: 0.2595 - val_mae: 0.4456\n",
      "Epoch 299/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1417 - mae: 0.3134 - val_loss: 0.2620 - val_mae: 0.4478\n",
      "Epoch 300/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1576 - mae: 0.3288 - val_loss: 0.2669 - val_mae: 0.4473\n",
      "Epoch 301/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1575 - mae: 0.3291 - val_loss: 0.2638 - val_mae: 0.4463\n",
      "Epoch 302/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.1471 - mae: 0.3065 - val_loss: 0.2702 - val_mae: 0.4459\n",
      "Epoch 303/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1489 - mae: 0.3172 - val_loss: 0.2825 - val_mae: 0.4528\n",
      "Epoch 304/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - loss: 0.1522 - mae: 0.3071 - val_loss: 0.2729 - val_mae: 0.4495\n",
      "Epoch 305/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.1491 - mae: 0.3020 - val_loss: 0.2634 - val_mae: 0.4542\n",
      "Epoch 306/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1562 - mae: 0.3326 - val_loss: 0.2796 - val_mae: 0.4552\n",
      "Epoch 307/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1460 - mae: 0.2938 - val_loss: 0.2882 - val_mae: 0.4578\n",
      "Epoch 308/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1544 - mae: 0.3210 - val_loss: 0.2840 - val_mae: 0.4583\n",
      "Epoch 309/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1298 - mae: 0.2906 - val_loss: 0.2829 - val_mae: 0.4572\n",
      "Epoch 310/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1378 - mae: 0.2888 - val_loss: 0.2734 - val_mae: 0.4538\n",
      "Epoch 311/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 0.1285 - mae: 0.2828 - val_loss: 0.2634 - val_mae: 0.4498\n",
      "Epoch 312/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1221 - mae: 0.2746 - val_loss: 0.2550 - val_mae: 0.4459\n",
      "Epoch 313/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1345 - mae: 0.2978 - val_loss: 0.2698 - val_mae: 0.4652\n",
      "Epoch 314/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.1270 - mae: 0.2731 - val_loss: 0.2795 - val_mae: 0.4673\n",
      "Epoch 315/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1447 - mae: 0.3081 - val_loss: 0.2847 - val_mae: 0.4696\n",
      "Epoch 316/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1370 - mae: 0.3022 - val_loss: 0.2759 - val_mae: 0.4669\n",
      "Epoch 317/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1331 - mae: 0.2991 - val_loss: 0.2765 - val_mae: 0.4694\n",
      "Epoch 318/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1311 - mae: 0.2934 - val_loss: 0.2801 - val_mae: 0.4691\n",
      "Epoch 319/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1409 - mae: 0.3003 - val_loss: 0.2867 - val_mae: 0.4773\n",
      "Epoch 320/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1517 - mae: 0.3224 - val_loss: 0.2791 - val_mae: 0.4703\n",
      "Epoch 321/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1348 - mae: 0.2948 - val_loss: 0.2802 - val_mae: 0.4725\n",
      "Epoch 322/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1362 - mae: 0.2978 - val_loss: 0.2755 - val_mae: 0.4699\n",
      "Epoch 323/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1287 - mae: 0.2924 - val_loss: 0.2820 - val_mae: 0.4726\n",
      "Epoch 324/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1241 - mae: 0.2634 - val_loss: 0.2874 - val_mae: 0.4740\n",
      "Epoch 325/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.1556 - mae: 0.3237 - val_loss: 0.2777 - val_mae: 0.4662\n",
      "Epoch 326/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1467 - mae: 0.3051 - val_loss: 0.2694 - val_mae: 0.4688\n",
      "Epoch 327/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1532 - mae: 0.3342 - val_loss: 0.2708 - val_mae: 0.4710\n",
      "Epoch 328/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1634 - mae: 0.3354 - val_loss: 0.2803 - val_mae: 0.4695\n",
      "Epoch 329/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.1214 - mae: 0.2732 - val_loss: 0.2855 - val_mae: 0.4702\n",
      "Epoch 330/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1421 - mae: 0.3125 - val_loss: 0.2777 - val_mae: 0.4686\n",
      "Epoch 331/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - loss: 0.1597 - mae: 0.3214 - val_loss: 0.2747 - val_mae: 0.4694\n",
      "Epoch 332/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1204 - mae: 0.2634 - val_loss: 0.2791 - val_mae: 0.4670\n",
      "Epoch 333/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1437 - mae: 0.3090 - val_loss: 0.2756 - val_mae: 0.4557\n",
      "Epoch 334/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1638 - mae: 0.3389 - val_loss: 0.2750 - val_mae: 0.4558\n",
      "Epoch 335/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.1480 - mae: 0.3065 - val_loss: 0.2702 - val_mae: 0.4527\n",
      "Epoch 336/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1539 - mae: 0.3098 - val_loss: 0.2594 - val_mae: 0.4516\n",
      "Epoch 337/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1546 - mae: 0.3168 - val_loss: 0.2521 - val_mae: 0.4537\n",
      "Epoch 338/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1518 - mae: 0.3265 - val_loss: 0.2593 - val_mae: 0.4501\n",
      "Epoch 339/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.1448 - mae: 0.2954 - val_loss: 0.2616 - val_mae: 0.4481\n",
      "Epoch 340/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1469 - mae: 0.3121 - val_loss: 0.2604 - val_mae: 0.4494\n",
      "Epoch 341/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1319 - mae: 0.2843 - val_loss: 0.2608 - val_mae: 0.4493\n",
      "Epoch 342/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 35s/step - loss: 0.1769 - mae: 0.3632 - val_loss: 0.2651 - val_mae: 0.4484\n",
      "Epoch 343/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1716 - mae: 0.3406 - val_loss: 0.2640 - val_mae: 0.4482\n",
      "Epoch 344/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.1625 - mae: 0.3354 - val_loss: 0.2654 - val_mae: 0.4507\n",
      "Epoch 345/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1545 - mae: 0.3040 - val_loss: 0.2649 - val_mae: 0.4510\n",
      "Epoch 346/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1226 - mae: 0.2780 - val_loss: 0.2687 - val_mae: 0.4514\n",
      "Epoch 347/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1182 - mae: 0.2602 - val_loss: 0.2830 - val_mae: 0.4529\n",
      "Epoch 348/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1573 - mae: 0.3012 - val_loss: 0.2790 - val_mae: 0.4490\n",
      "Epoch 349/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1544 - mae: 0.3013 - val_loss: 0.2682 - val_mae: 0.4521\n",
      "Epoch 350/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1446 - mae: 0.2932 - val_loss: 0.2630 - val_mae: 0.4548\n",
      "Epoch 351/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1196 - mae: 0.2699 - val_loss: 0.2568 - val_mae: 0.4570\n",
      "Epoch 352/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1359 - mae: 0.3017 - val_loss: 0.2563 - val_mae: 0.4569\n",
      "Epoch 353/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1608 - mae: 0.3349 - val_loss: 0.2581 - val_mae: 0.4531\n",
      "Epoch 354/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1444 - mae: 0.3149 - val_loss: 0.2624 - val_mae: 0.4447\n",
      "Epoch 355/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1312 - mae: 0.2885 - val_loss: 0.2680 - val_mae: 0.4472\n",
      "Epoch 356/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1371 - mae: 0.2965 - val_loss: 0.2668 - val_mae: 0.4479\n",
      "Epoch 357/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1423 - mae: 0.2995 - val_loss: 0.2684 - val_mae: 0.4482\n",
      "Epoch 358/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1444 - mae: 0.3119 - val_loss: 0.2622 - val_mae: 0.4496\n",
      "Epoch 359/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1568 - mae: 0.3297 - val_loss: 0.2583 - val_mae: 0.4506\n",
      "Epoch 360/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1612 - mae: 0.3286 - val_loss: 0.2593 - val_mae: 0.4446\n",
      "Epoch 361/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1323 - mae: 0.2998 - val_loss: 0.2620 - val_mae: 0.4398\n",
      "Epoch 362/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1386 - mae: 0.3031 - val_loss: 0.2627 - val_mae: 0.4408\n",
      "Epoch 363/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 149ms/step - loss: 0.1228 - mae: 0.2764 - val_loss: 0.2616 - val_mae: 0.4410\n",
      "Epoch 364/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1633 - mae: 0.3233 - val_loss: 0.2531 - val_mae: 0.4395\n",
      "Epoch 365/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1343 - mae: 0.2871 - val_loss: 0.2527 - val_mae: 0.4425\n",
      "Epoch 366/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1494 - mae: 0.3280 - val_loss: 0.2587 - val_mae: 0.4432\n",
      "Epoch 367/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1356 - mae: 0.2927 - val_loss: 0.2625 - val_mae: 0.4454\n",
      "Epoch 368/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1363 - mae: 0.3016 - val_loss: 0.2583 - val_mae: 0.4478\n",
      "Epoch 369/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1329 - mae: 0.2795 - val_loss: 0.2644 - val_mae: 0.4464\n",
      "Epoch 370/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1468 - mae: 0.3074 - val_loss: 0.2620 - val_mae: 0.4453\n",
      "Epoch 371/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1329 - mae: 0.2838 - val_loss: 0.2611 - val_mae: 0.4447\n",
      "Epoch 372/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1492 - mae: 0.3242 - val_loss: 0.2634 - val_mae: 0.4460\n",
      "Epoch 373/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1261 - mae: 0.2820 - val_loss: 0.2644 - val_mae: 0.4442\n",
      "Epoch 374/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1310 - mae: 0.2931 - val_loss: 0.2595 - val_mae: 0.4437\n",
      "Epoch 375/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1527 - mae: 0.3213 - val_loss: 0.2630 - val_mae: 0.4427\n",
      "Epoch 376/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1342 - mae: 0.2846 - val_loss: 0.2647 - val_mae: 0.4407\n",
      "Epoch 377/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1200 - mae: 0.2848 - val_loss: 0.2677 - val_mae: 0.4418\n",
      "Epoch 378/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1520 - mae: 0.3243 - val_loss: 0.2507 - val_mae: 0.4467\n",
      "Epoch 379/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1367 - mae: 0.2966 - val_loss: 0.2529 - val_mae: 0.4418\n",
      "Epoch 380/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1423 - mae: 0.3018 - val_loss: 0.2599 - val_mae: 0.4445\n",
      "Epoch 381/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1358 - mae: 0.2957 - val_loss: 0.2690 - val_mae: 0.4488\n",
      "Epoch 382/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1354 - mae: 0.2970 - val_loss: 0.2673 - val_mae: 0.4486\n",
      "Epoch 383/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1637 - mae: 0.3261 - val_loss: 0.2596 - val_mae: 0.4553\n",
      "Epoch 384/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1337 - mae: 0.2927 - val_loss: 0.2641 - val_mae: 0.4522\n",
      "Epoch 385/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1170 - mae: 0.2537 - val_loss: 0.2698 - val_mae: 0.4464\n",
      "Epoch 386/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1446 - mae: 0.3044 - val_loss: 0.2766 - val_mae: 0.4472\n",
      "Epoch 387/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1461 - mae: 0.3155 - val_loss: 0.2615 - val_mae: 0.4511\n",
      "Epoch 388/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1441 - mae: 0.3113 - val_loss: 0.2612 - val_mae: 0.4520\n",
      "Epoch 389/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1431 - mae: 0.2995 - val_loss: 0.2652 - val_mae: 0.4508\n",
      "Epoch 390/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1410 - mae: 0.3087 - val_loss: 0.2595 - val_mae: 0.4501\n",
      "Epoch 391/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1553 - mae: 0.3249 - val_loss: 0.2565 - val_mae: 0.4447\n",
      "Epoch 392/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1461 - mae: 0.3014 - val_loss: 0.2584 - val_mae: 0.4455\n",
      "Epoch 393/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1402 - mae: 0.3007 - val_loss: 0.2616 - val_mae: 0.4472\n",
      "Epoch 394/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1462 - mae: 0.3071 - val_loss: 0.2652 - val_mae: 0.4470\n",
      "Epoch 395/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1551 - mae: 0.3213 - val_loss: 0.2709 - val_mae: 0.4467\n",
      "Epoch 396/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1480 - mae: 0.3194 - val_loss: 0.2675 - val_mae: 0.4436\n",
      "Epoch 397/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1228 - mae: 0.2684 - val_loss: 0.2616 - val_mae: 0.4454\n",
      "Epoch 398/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1298 - mae: 0.2859 - val_loss: 0.2623 - val_mae: 0.4429\n",
      "Epoch 399/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1265 - mae: 0.2837 - val_loss: 0.2647 - val_mae: 0.4455\n",
      "Epoch 400/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1301 - mae: 0.2903 - val_loss: 0.2554 - val_mae: 0.4457\n",
      "Epoch 401/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1304 - mae: 0.2882 - val_loss: 0.2562 - val_mae: 0.4479\n",
      "Epoch 402/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1566 - mae: 0.3271 - val_loss: 0.2564 - val_mae: 0.4513\n",
      "Epoch 403/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1584 - mae: 0.3208 - val_loss: 0.2588 - val_mae: 0.4530\n",
      "Epoch 404/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1479 - mae: 0.3165 - val_loss: 0.2674 - val_mae: 0.4515\n",
      "Epoch 405/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1421 - mae: 0.3022 - val_loss: 0.2615 - val_mae: 0.4526\n",
      "Epoch 406/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1648 - mae: 0.3374 - val_loss: 0.2551 - val_mae: 0.4518\n",
      "Epoch 407/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1232 - mae: 0.2790 - val_loss: 0.2574 - val_mae: 0.4451\n",
      "Epoch 408/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1344 - mae: 0.2950 - val_loss: 0.2664 - val_mae: 0.4498\n",
      "Epoch 409/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1342 - mae: 0.2936 - val_loss: 0.2646 - val_mae: 0.4467\n",
      "Epoch 410/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1577 - mae: 0.3279 - val_loss: 0.2566 - val_mae: 0.4437\n",
      "Epoch 411/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1385 - mae: 0.2988 - val_loss: 0.2529 - val_mae: 0.4467\n",
      "Epoch 412/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1561 - mae: 0.3146 - val_loss: 0.2537 - val_mae: 0.4507\n",
      "Epoch 413/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1362 - mae: 0.2821 - val_loss: 0.2539 - val_mae: 0.4521\n",
      "Epoch 414/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1386 - mae: 0.2903 - val_loss: 0.2600 - val_mae: 0.4493\n",
      "Epoch 415/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1426 - mae: 0.2966 - val_loss: 0.2645 - val_mae: 0.4500\n",
      "Epoch 416/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.1196 - mae: 0.2669 - val_loss: 0.2591 - val_mae: 0.4524\n",
      "Epoch 417/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1381 - mae: 0.2983 - val_loss: 0.2566 - val_mae: 0.4532\n",
      "Epoch 418/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1446 - mae: 0.3044 - val_loss: 0.2584 - val_mae: 0.4493\n",
      "Epoch 419/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1203 - mae: 0.2733 - val_loss: 0.2567 - val_mae: 0.4466\n",
      "Epoch 420/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1382 - mae: 0.2987 - val_loss: 0.2608 - val_mae: 0.4475\n",
      "Epoch 421/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1333 - mae: 0.2868 - val_loss: 0.2634 - val_mae: 0.4492\n",
      "Epoch 422/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1367 - mae: 0.2974 - val_loss: 0.2650 - val_mae: 0.4486\n",
      "Epoch 423/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1347 - mae: 0.2994 - val_loss: 0.2607 - val_mae: 0.4479\n",
      "Epoch 424/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1468 - mae: 0.3228 - val_loss: 0.2586 - val_mae: 0.4486\n",
      "Epoch 425/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1377 - mae: 0.2827 - val_loss: 0.2479 - val_mae: 0.4517\n",
      "Epoch 426/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1302 - mae: 0.2885 - val_loss: 0.2523 - val_mae: 0.4500\n",
      "Epoch 427/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1476 - mae: 0.3171 - val_loss: 0.2588 - val_mae: 0.4482\n",
      "Epoch 428/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1126 - mae: 0.2573 - val_loss: 0.2668 - val_mae: 0.4469\n",
      "Epoch 429/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1462 - mae: 0.3141 - val_loss: 0.2686 - val_mae: 0.4484\n",
      "Epoch 430/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1330 - mae: 0.2902 - val_loss: 0.2552 - val_mae: 0.4513\n",
      "Epoch 431/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1328 - mae: 0.3017 - val_loss: 0.2470 - val_mae: 0.4490\n",
      "Epoch 432/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1504 - mae: 0.3126 - val_loss: 0.2426 - val_mae: 0.4463\n",
      "Epoch 433/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1387 - mae: 0.2974 - val_loss: 0.2436 - val_mae: 0.4412\n",
      "Epoch 434/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1304 - mae: 0.2931 - val_loss: 0.2550 - val_mae: 0.4412\n",
      "Epoch 435/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1337 - mae: 0.2974 - val_loss: 0.2527 - val_mae: 0.4436\n",
      "Epoch 436/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1445 - mae: 0.3147 - val_loss: 0.2522 - val_mae: 0.4427\n",
      "Epoch 437/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1287 - mae: 0.2766 - val_loss: 0.2527 - val_mae: 0.4426\n",
      "Epoch 438/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1419 - mae: 0.3008 - val_loss: 0.2490 - val_mae: 0.4443\n",
      "Epoch 439/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1345 - mae: 0.2962 - val_loss: 0.2514 - val_mae: 0.4432\n",
      "Epoch 440/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1346 - mae: 0.2965 - val_loss: 0.2550 - val_mae: 0.4422\n",
      "Epoch 441/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1234 - mae: 0.2806 - val_loss: 0.2545 - val_mae: 0.4424\n",
      "Epoch 442/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1252 - mae: 0.2701 - val_loss: 0.2578 - val_mae: 0.4430\n",
      "Epoch 443/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1629 - mae: 0.3279 - val_loss: 0.2533 - val_mae: 0.4466\n",
      "Epoch 444/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1557 - mae: 0.3306 - val_loss: 0.2503 - val_mae: 0.4458\n",
      "Epoch 445/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1513 - mae: 0.3187 - val_loss: 0.2600 - val_mae: 0.4434\n",
      "Epoch 446/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1051 - mae: 0.2414 - val_loss: 0.2764 - val_mae: 0.4452\n",
      "Epoch 447/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1502 - mae: 0.3223 - val_loss: 0.2802 - val_mae: 0.4452\n",
      "Epoch 448/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1420 - mae: 0.2991 - val_loss: 0.2640 - val_mae: 0.4468\n",
      "Epoch 449/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1410 - mae: 0.3005 - val_loss: 0.2594 - val_mae: 0.4494\n",
      "Epoch 450/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1228 - mae: 0.2809 - val_loss: 0.2583 - val_mae: 0.4493\n",
      "Epoch 451/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1373 - mae: 0.3007 - val_loss: 0.2534 - val_mae: 0.4462\n",
      "Epoch 452/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1383 - mae: 0.2964 - val_loss: 0.2527 - val_mae: 0.4420\n",
      "Epoch 453/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1577 - mae: 0.3089 - val_loss: 0.2507 - val_mae: 0.4416\n",
      "Epoch 454/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1372 - mae: 0.2971 - val_loss: 0.2484 - val_mae: 0.4423\n",
      "Epoch 455/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1249 - mae: 0.2735 - val_loss: 0.2521 - val_mae: 0.4438\n",
      "Epoch 456/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1453 - mae: 0.2999 - val_loss: 0.2497 - val_mae: 0.4445\n",
      "Epoch 457/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1531 - mae: 0.3214 - val_loss: 0.2412 - val_mae: 0.4435\n",
      "Epoch 458/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1447 - mae: 0.3056 - val_loss: 0.2401 - val_mae: 0.4389\n",
      "Epoch 459/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1355 - mae: 0.2881 - val_loss: 0.2403 - val_mae: 0.4380\n",
      "Epoch 460/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1514 - mae: 0.3179 - val_loss: 0.2465 - val_mae: 0.4383\n",
      "Epoch 461/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1248 - mae: 0.2814 - val_loss: 0.2453 - val_mae: 0.4401\n",
      "Epoch 462/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1270 - mae: 0.2828 - val_loss: 0.2403 - val_mae: 0.4422\n",
      "Epoch 463/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1098 - mae: 0.2486 - val_loss: 0.2450 - val_mae: 0.4411\n",
      "Epoch 464/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1467 - mae: 0.3115 - val_loss: 0.2547 - val_mae: 0.4415\n",
      "Epoch 465/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1439 - mae: 0.2999 - val_loss: 0.2566 - val_mae: 0.4460\n",
      "Epoch 466/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1677 - mae: 0.3272 - val_loss: 0.2534 - val_mae: 0.4466\n",
      "Epoch 467/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1291 - mae: 0.2931 - val_loss: 0.2568 - val_mae: 0.4443\n",
      "Epoch 468/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1290 - mae: 0.2784 - val_loss: 0.2570 - val_mae: 0.4436\n",
      "Epoch 469/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1302 - mae: 0.2713 - val_loss: 0.2562 - val_mae: 0.4408\n",
      "Epoch 470/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1410 - mae: 0.2901 - val_loss: 0.2576 - val_mae: 0.4407\n",
      "Epoch 471/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1439 - mae: 0.3171 - val_loss: 0.2603 - val_mae: 0.4447\n",
      "Epoch 472/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1396 - mae: 0.2969 - val_loss: 0.2503 - val_mae: 0.4498\n",
      "Epoch 473/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1464 - mae: 0.3137 - val_loss: 0.2511 - val_mae: 0.4539\n",
      "Epoch 474/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.1529 - mae: 0.3202 - val_loss: 0.2553 - val_mae: 0.4518\n",
      "Epoch 475/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1254 - mae: 0.2706 - val_loss: 0.2534 - val_mae: 0.4519\n",
      "Epoch 476/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1279 - mae: 0.2803 - val_loss: 0.2456 - val_mae: 0.4484\n",
      "Epoch 477/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1642 - mae: 0.3311 - val_loss: 0.2323 - val_mae: 0.4462\n",
      "Epoch 478/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1096 - mae: 0.2483 - val_loss: 0.2347 - val_mae: 0.4401\n",
      "Epoch 479/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1368 - mae: 0.2998 - val_loss: 0.2357 - val_mae: 0.4340\n",
      "Epoch 480/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1327 - mae: 0.2899 - val_loss: 0.2404 - val_mae: 0.4312\n",
      "Epoch 481/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1360 - mae: 0.2948 - val_loss: 0.2403 - val_mae: 0.4322\n",
      "Epoch 482/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1514 - mae: 0.3098 - val_loss: 0.2430 - val_mae: 0.4350\n",
      "Epoch 483/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.1587 - mae: 0.3163 - val_loss: 0.2447 - val_mae: 0.4382\n",
      "Epoch 484/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1327 - mae: 0.2817 - val_loss: 0.2466 - val_mae: 0.4395\n",
      "Epoch 485/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1260 - mae: 0.2922 - val_loss: 0.2455 - val_mae: 0.4407\n",
      "Epoch 486/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1306 - mae: 0.2917 - val_loss: 0.2349 - val_mae: 0.4415\n",
      "Epoch 487/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1355 - mae: 0.3035 - val_loss: 0.2349 - val_mae: 0.4396\n",
      "Epoch 488/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1349 - mae: 0.2911 - val_loss: 0.2412 - val_mae: 0.4391\n",
      "Epoch 489/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1520 - mae: 0.3122 - val_loss: 0.2368 - val_mae: 0.4423\n",
      "Epoch 490/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1381 - mae: 0.2959 - val_loss: 0.2396 - val_mae: 0.4410\n",
      "Epoch 491/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1484 - mae: 0.3044 - val_loss: 0.2435 - val_mae: 0.4337\n",
      "Epoch 492/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - loss: 0.1377 - mae: 0.3032 - val_loss: 0.2483 - val_mae: 0.4364\n",
      "Epoch 493/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1408 - mae: 0.2929 - val_loss: 0.2525 - val_mae: 0.4406\n",
      "Epoch 494/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1435 - mae: 0.2965 - val_loss: 0.2439 - val_mae: 0.4452\n",
      "Epoch 495/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1472 - mae: 0.3031 - val_loss: 0.2442 - val_mae: 0.4478\n",
      "Epoch 496/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1504 - mae: 0.3219 - val_loss: 0.2535 - val_mae: 0.4468\n",
      "Epoch 497/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1394 - mae: 0.2985 - val_loss: 0.2535 - val_mae: 0.4406\n",
      "Epoch 498/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.1409 - mae: 0.2868 - val_loss: 0.2572 - val_mae: 0.4381\n",
      "Epoch 499/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1421 - mae: 0.2950 - val_loss: 0.2571 - val_mae: 0.4402\n",
      "Epoch 500/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1327 - mae: 0.2919 - val_loss: 0.2556 - val_mae: 0.4417\n"
     ]
    }
   ],
   "source": [
    "# Train the LSTM model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=500,  # You can adjust based on convergence\n",
    "    batch_size=8,  # Smaller batch size for augmented data\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2556, Validation MAE: 0.4417\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_mae = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation MAE: {val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "Predicted: 0.61, Actual: 0.00\n",
      "Predicted: 0.62, Actual: 0.00\n",
      "Predicted: 0.62, Actual: 1.00\n",
      "Predicted: 0.62, Actual: 0.00\n",
      "Predicted: 0.62, Actual: 1.00\n",
      "Predicted: 0.52, Actual: 0.00\n",
      "Predicted: 0.62, Actual: 0.00\n",
      "Predicted: 0.30, Actual: 1.00\n",
      "Predicted: 0.62, Actual: 0.00\n",
      "Predicted: 0.63, Actual: 0.00\n",
      "Predicted: 0.62, Actual: 1.00\n",
      "Predicted: 0.89, Actual: 0.00\n",
      "Predicted: 0.62, Actual: 1.00\n",
      "Predicted: 0.96, Actual: 1.00\n",
      "Predicted: 0.96, Actual: 1.00\n",
      "Predicted: 0.91, Actual: 1.00\n",
      "Predicted: 0.96, Actual: 1.00\n",
      "Predicted: 0.62, Actual: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Predict scores on validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Print predictions vs. actual\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Predicted: {pred[0]:.2f}, Actual: {y_val[i]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatter plot of predictions vs. actual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_val, predictions, c='blue', label='Predicted vs Actual')\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Perfect Match')  # Reference line\n",
    "plt.xlabel('Actual Scores')\n",
    "plt.ylabel('Predicted Scores')\n",
    "plt.title('Model Predictions vs. Actual Scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737664010.547159 10892581 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n",
      "W0000 00:00:1737664010.653473 10992625 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737664010.663512 10992629 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x3b02cb880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
      "Predicted Score: 0.62\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to check if the athlete maintains an upright posture while accelerating\n",
    "def is_upright_posture(shoulder, hip, ankle):\n",
    "    \"\"\"\n",
    "    Determines if the athlete maintains an upright posture by analyzing the alignment\n",
    "    of the shoulder, hip, and ankle on the vertical axis.\n",
    "    \"\"\"\n",
    "    shoulder_x, shoulder_y = shoulder\n",
    "    hip_x, hip_y = hip\n",
    "    ankle_x, ankle_y = ankle\n",
    "\n",
    "    # Condition for upright posture: vertical alignment with small deviation\n",
    "    posture_upright = abs(shoulder_x - hip_x) < 0.05 and abs(hip_x - ankle_x) < 0.05\n",
    "    return posture_upright\n",
    "\n",
    "# Path for the new test video\n",
    "new_video_path = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/test_videos/1_user8.mp4\"\n",
    "\n",
    "# Extract keypoints for the new video\n",
    "new_keypoints = []\n",
    "cap = cv2.VideoCapture(new_video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB for MediaPipe processing\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = pose.process(frame_rgb)\n",
    "\n",
    "    if result.pose_landmarks:\n",
    "        landmarks = result.pose_landmarks.landmark\n",
    "\n",
    "        # Extract keypoints for upright posture analysis\n",
    "        left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y]\n",
    "        left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.LEFT_HIP].y]\n",
    "        left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y]\n",
    "\n",
    "        right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y]\n",
    "        right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y]\n",
    "        right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].y]\n",
    "\n",
    "        # Check if upright posture is maintained for both sides\n",
    "        left_upright = is_upright_posture(left_shoulder, left_hip, left_ankle)\n",
    "        right_upright = is_upright_posture(right_shoulder, right_hip, right_ankle)\n",
    "\n",
    "        # Store the binary values (0 or 1) for analysis\n",
    "        new_keypoints.append([int(left_upright), int(right_upright)])\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Pad the sequence to match training input length\n",
    "max_seq_length = X_train.shape[1]  # Ensure it's the same length used during training\n",
    "new_keypoints_padded = pad_sequences([new_keypoints], maxlen=max_seq_length, padding='post', dtype='float32')\n",
    "\n",
    "# Reshape to match model input (samples, timesteps, features)\n",
    "new_keypoints_padded = new_keypoints_padded.reshape((new_keypoints_padded.shape[0], new_keypoints_padded.shape[1], 2))\n",
    "\n",
    "# Predict score for the new video\n",
    "predicted_score = model.predict(new_keypoints_padded)\n",
    "print(f\"Predicted Score: {predicted_score[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_score(prediction):\n",
    "    \"\"\"Classify the prediction into 0, 0.5, or 1 based on thresholds.\"\"\"\n",
    "    if prediction >= 0.6:\n",
    "        return 1.0\n",
    "    elif prediction >= 0.4:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Classified: 1.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 0.5, Actual: 0.0\n",
      "Classified: 1.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Predict scores on validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Apply classification logic\n",
    "classified_predictions = [classify_score(pred[0]) for pred in predictions]\n",
    "\n",
    "# Print classified predictions vs actual scores\n",
    "for i, (pred, actual) in enumerate(zip(classified_predictions, y_val)):\n",
    "    print(f\"Classified: {pred}, Actual: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def weighted_mse(y_true, y_pred):\n",
    "    \"\"\"Weighted Mean Squared Error to prioritize true negatives.\"\"\"\n",
    "    weights = K.switch(y_true < 0.70, 2.0, 1.0)  # Weight true negatives higher\n",
    "    return K.mean(weights * K.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=weighted_mse, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
      "Classification Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "# Predict and classify scores\n",
    "classified_predictions = [classify_score(pred[0]) for pred in model.predict(X_val)]\n",
    "\n",
    "# Evaluate accuracy of classification\n",
    "correct = sum(1 for pred, actual in zip(classified_predictions, y_val) if pred == actual)\n",
    "accuracy = correct / len(y_val)\n",
    "\n",
    "print(f\"Classification Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage1/models/highjump_stage1.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
