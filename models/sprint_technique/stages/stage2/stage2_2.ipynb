{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737649844.714732 8979125 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1737649844.774937 9204629 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737649844.786154 9204631 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737649844.800105 9204634 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knee position extraction complete! JSON files saved in 'keypoints' folder.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to determine if knees are high\n",
    "def is_knee_high(hip, knee):\n",
    "    # Knee should be at or above hip level in the y-axis (inverted coordinate system)\n",
    "    return knee[1] <= hip[1] - 0.05\n",
    "\n",
    "# Paths for the stage 2 videos and keypoints storage\n",
    "stage_path = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/sprint_technique/stages/stage2/videos\"\n",
    "keypoints_folder = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/sprint_technique/stages/stage2/keypoints\"\n",
    "\n",
    "# Ensure keypoints folder exists\n",
    "os.makedirs(keypoints_folder, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(stage_path):\n",
    "    if file.endswith(\".mp4\"):\n",
    "        video_file_path = os.path.join(stage_path, file)\n",
    "        cap = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "        keypoints_data = []  # Store keypoints for this video\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Convert frame to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result = pose.process(frame_rgb)\n",
    "\n",
    "            if result.pose_landmarks:\n",
    "                landmarks = result.pose_landmarks.landmark\n",
    "\n",
    "                # Extract relevant keypoints for knees and hips\n",
    "                left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_HIP].y]\n",
    "                left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y]\n",
    "\n",
    "                right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y]\n",
    "                right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y]\n",
    "\n",
    "                # Check if knees are high\n",
    "                left_knee_high = is_knee_high(left_hip, left_knee)\n",
    "                right_knee_high = is_knee_high(right_hip, right_knee)\n",
    "\n",
    "                # Store data for this frame\n",
    "                keypoints_data.append({\n",
    "                    \"frame\": int(cap.get(cv2.CAP_PROP_POS_FRAMES)),\n",
    "                    \"left_knee_high\": left_knee_high,\n",
    "                    \"right_knee_high\": right_knee_high,\n",
    "                    \"left_hip\": left_hip,\n",
    "                    \"left_knee\": left_knee,\n",
    "                    \"right_hip\": right_hip,\n",
    "                    \"right_knee\": right_knee\n",
    "                })\n",
    "\n",
    "        # Release the video\n",
    "        cap.release()\n",
    "\n",
    "        # Save keypoints to the keypoints folder\n",
    "        json_filename = os.path.splitext(file)[0] + \"_keypoints.json\"\n",
    "        json_path = os.path.join(keypoints_folder, json_filename)\n",
    "        with open(json_path, \"w\") as json_file:\n",
    "            json.dump(keypoints_data, json_file, indent=4)\n",
    "\n",
    "print(\"Knee position extraction complete! JSON files saved in 'keypoints' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 sequences with labels.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Path to the keypoints folder for stage 2 (knees high)\n",
    "keypoints_folder = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/sprint_technique/stages/stage2/keypoints\"\n",
    "\n",
    "# Lists to store sequences and labels\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "# Process keypoint JSON files\n",
    "for file in os.listdir(keypoints_folder):\n",
    "    if file.endswith(\"_keypoints.json\"):\n",
    "        file_path = os.path.join(keypoints_folder, file)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Extract knee position indicators across all frames\n",
    "        knee_positions = [\n",
    "            [int(frame[\"left_knee_high\"]), int(frame[\"right_knee_high\"])]\n",
    "            for frame in data\n",
    "        ]\n",
    "        sequences.append(knee_positions)\n",
    "\n",
    "        # Extract label from filename (assumes label is the first part of filename)\n",
    "        try:\n",
    "            label = float(file.split(\"_\")[0])  # Modify if filename structure differs\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Unable to extract label from {file}\")\n",
    "            continue\n",
    "        \n",
    "        labels.append(label)\n",
    "\n",
    "# Pad sequences to the same length\n",
    "if sequences:\n",
    "    max_len = max(len(seq) for seq in sequences)\n",
    "    sequences = pad_sequences(sequences, maxlen=max_len, padding='post', dtype='float32')\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    print(f\"Loaded {len(sequences)} sequences with labels.\")\n",
    "else:\n",
    "    print(\"No sequences found in the keypoints folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented dataset size: 80\n"
     ]
    }
   ],
   "source": [
    "def augment_data(sequence):\n",
    "    augmented_sequences = []\n",
    "\n",
    "    # Original\n",
    "    augmented_sequences.append(sequence)\n",
    "\n",
    "    # Mirrored (flip angles horizontally)\n",
    "    mirrored = -sequence\n",
    "    augmented_sequences.append(mirrored)\n",
    "\n",
    "    # Rotation (add a small angle offset)\n",
    "    rotated = sequence + np.random.uniform(-10, 10, size=sequence.shape)\n",
    "    augmented_sequences.append(rotated)\n",
    "\n",
    "    # Noise (add random Gaussian noise)\n",
    "    noisy = sequence + np.random.normal(0, 0.05, size=sequence.shape)\n",
    "    augmented_sequences.append(noisy)\n",
    "\n",
    "    # Scaled (adjust by a small percentage)\n",
    "    scaled = sequence * np.random.uniform(0.9, 1.1)\n",
    "    augmented_sequences.append(scaled)\n",
    "\n",
    "    return augmented_sequences\n",
    "\n",
    "augmented_sequences = []\n",
    "augmented_labels = []\n",
    "\n",
    "for seq, label in zip(sequences, labels):\n",
    "    augmented = augment_data(seq)\n",
    "    augmented_sequences.extend(augmented)\n",
    "    augmented_labels.extend([label] * len(augmented))\n",
    "\n",
    "augmented_sequences = np.array(augmented_sequences)\n",
    "augmented_labels = np.array(augmented_labels)\n",
    "\n",
    "print(f\"Augmented dataset size: {len(augmented_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 61, Validation samples: 19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    augmented_sequences, augmented_labels, test_size=4/17, random_state=42\n",
    ")\n",
    "\n",
    "# Ensure correct shape for LSTM input (samples, timesteps, features)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 2))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 2))\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define enhanced LSTM model\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(128, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1], 2))),\n",
    "    Dropout(0.5),\n",
    "    Bidirectional(LSTM(32, activation='tanh', return_sequences=False)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output: Regression score\n",
    "])\n",
    "\n",
    "# Compile the model with a reduced learning rate for better convergence\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse', metrics=['mae'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - loss: 0.7084 - mae: 0.7283 - val_loss: 0.4801 - val_mae: 0.5604\n",
      "Epoch 2/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.6488 - mae: 0.7519 - val_loss: 0.3522 - val_mae: 0.5285\n",
      "Epoch 3/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.4084 - mae: 0.6083 - val_loss: 0.2708 - val_mae: 0.4840\n",
      "Epoch 4/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.2270 - mae: 0.3968 - val_loss: 0.2993 - val_mae: 0.4539\n",
      "Epoch 5/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.1504 - mae: 0.3238 - val_loss: 0.2574 - val_mae: 0.4813\n",
      "Epoch 6/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.1905 - mae: 0.3919 - val_loss: 0.2818 - val_mae: 0.4801\n",
      "Epoch 7/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.1400 - mae: 0.2999 - val_loss: 0.3387 - val_mae: 0.4604\n",
      "Epoch 8/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.1952 - mae: 0.3498 - val_loss: 0.2812 - val_mae: 0.4671\n",
      "Epoch 9/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.1509 - mae: 0.3184 - val_loss: 0.2915 - val_mae: 0.4591\n",
      "Epoch 10/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.1321 - mae: 0.2868 - val_loss: 0.3088 - val_mae: 0.4553\n",
      "Epoch 11/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.1635 - mae: 0.3206 - val_loss: 0.2791 - val_mae: 0.4642\n",
      "Epoch 12/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.1378 - mae: 0.3070 - val_loss: 0.3068 - val_mae: 0.4581\n",
      "Epoch 13/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.1291 - mae: 0.2794 - val_loss: 0.2823 - val_mae: 0.4685\n",
      "Epoch 14/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1297 - mae: 0.2894 - val_loss: 0.2806 - val_mae: 0.4680\n",
      "Epoch 15/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1455 - mae: 0.3077 - val_loss: 0.2878 - val_mae: 0.4622\n",
      "Epoch 16/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.1141 - mae: 0.2528 - val_loss: 0.3071 - val_mae: 0.4585\n",
      "Epoch 17/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1767 - mae: 0.3297 - val_loss: 0.2839 - val_mae: 0.4690\n",
      "Epoch 18/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1651 - mae: 0.3159 - val_loss: 0.2892 - val_mae: 0.4653\n",
      "Epoch 19/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1170 - mae: 0.2580 - val_loss: 0.3244 - val_mae: 0.4557\n",
      "Epoch 20/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1138 - mae: 0.2419 - val_loss: 0.2855 - val_mae: 0.4660\n",
      "Epoch 21/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1244 - mae: 0.2946 - val_loss: 0.2696 - val_mae: 0.4650\n",
      "Epoch 22/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1515 - mae: 0.3269 - val_loss: 0.2737 - val_mae: 0.4632\n",
      "Epoch 23/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.1456 - mae: 0.3118 - val_loss: 0.2864 - val_mae: 0.4561\n",
      "Epoch 24/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.1416 - mae: 0.3033 - val_loss: 0.2897 - val_mae: 0.4620\n",
      "Epoch 25/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.1486 - mae: 0.3076 - val_loss: 0.2872 - val_mae: 0.4629\n",
      "Epoch 26/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1698 - mae: 0.3176 - val_loss: 0.3055 - val_mae: 0.4547\n",
      "Epoch 27/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1729 - mae: 0.3122 - val_loss: 0.2879 - val_mae: 0.4586\n",
      "Epoch 28/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1217 - mae: 0.2744 - val_loss: 0.2778 - val_mae: 0.4648\n",
      "Epoch 29/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1454 - mae: 0.3061 - val_loss: 0.2840 - val_mae: 0.4622\n",
      "Epoch 30/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1509 - mae: 0.2906 - val_loss: 0.2928 - val_mae: 0.4563\n",
      "Epoch 31/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1185 - mae: 0.2673 - val_loss: 0.3054 - val_mae: 0.4628\n",
      "Epoch 32/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1235 - mae: 0.2714 - val_loss: 0.2974 - val_mae: 0.4715\n",
      "Epoch 33/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1528 - mae: 0.3012 - val_loss: 0.2968 - val_mae: 0.4714\n",
      "Epoch 34/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1069 - mae: 0.2468 - val_loss: 0.3137 - val_mae: 0.4588\n",
      "Epoch 35/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1322 - mae: 0.2548 - val_loss: 0.2784 - val_mae: 0.4716\n",
      "Epoch 36/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1408 - mae: 0.3158 - val_loss: 0.3049 - val_mae: 0.4582\n",
      "Epoch 37/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1246 - mae: 0.2492 - val_loss: 0.3198 - val_mae: 0.4531\n",
      "Epoch 38/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1658 - mae: 0.2966 - val_loss: 0.3015 - val_mae: 0.4594\n",
      "Epoch 39/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0880 - mae: 0.2225 - val_loss: 0.3006 - val_mae: 0.4589\n",
      "Epoch 40/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1399 - mae: 0.2871 - val_loss: 0.2922 - val_mae: 0.4627\n",
      "Epoch 41/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1594 - mae: 0.3134 - val_loss: 0.2792 - val_mae: 0.4701\n",
      "Epoch 42/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1719 - mae: 0.3421 - val_loss: 0.2983 - val_mae: 0.4569\n",
      "Epoch 43/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1365 - mae: 0.2634 - val_loss: 0.3131 - val_mae: 0.4475\n",
      "Epoch 44/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1441 - mae: 0.2665 - val_loss: 0.2860 - val_mae: 0.4528\n",
      "Epoch 45/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1213 - mae: 0.2637 - val_loss: 0.2837 - val_mae: 0.4592\n",
      "Epoch 46/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.1287 - mae: 0.2636 - val_loss: 0.2927 - val_mae: 0.4619\n",
      "Epoch 47/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1361 - mae: 0.2804 - val_loss: 0.3021 - val_mae: 0.4604\n",
      "Epoch 48/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1016 - mae: 0.2219 - val_loss: 0.3121 - val_mae: 0.4532\n",
      "Epoch 49/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1045 - mae: 0.2359 - val_loss: 0.2717 - val_mae: 0.4626\n",
      "Epoch 50/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1532 - mae: 0.3201 - val_loss: 0.2736 - val_mae: 0.4545\n",
      "Epoch 51/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1612 - mae: 0.3123 - val_loss: 0.2893 - val_mae: 0.4482\n",
      "Epoch 52/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1365 - mae: 0.2800 - val_loss: 0.3113 - val_mae: 0.4429\n",
      "Epoch 53/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1785 - mae: 0.3137 - val_loss: 0.2770 - val_mae: 0.4647\n",
      "Epoch 54/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1268 - mae: 0.2871 - val_loss: 0.2892 - val_mae: 0.4578\n",
      "Epoch 55/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0945 - mae: 0.2266 - val_loss: 0.3062 - val_mae: 0.4541\n",
      "Epoch 56/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1437 - mae: 0.2843 - val_loss: 0.2751 - val_mae: 0.4689\n",
      "Epoch 57/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1165 - mae: 0.2725 - val_loss: 0.2937 - val_mae: 0.4625\n",
      "Epoch 58/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1143 - mae: 0.2400 - val_loss: 0.3112 - val_mae: 0.4557\n",
      "Epoch 59/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0953 - mae: 0.2170 - val_loss: 0.2830 - val_mae: 0.4667\n",
      "Epoch 60/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1543 - mae: 0.3120 - val_loss: 0.2788 - val_mae: 0.4611\n",
      "Epoch 61/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1545 - mae: 0.2924 - val_loss: 0.3024 - val_mae: 0.4512\n",
      "Epoch 62/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0901 - mae: 0.2088 - val_loss: 0.2959 - val_mae: 0.4560\n",
      "Epoch 63/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1096 - mae: 0.2566 - val_loss: 0.2772 - val_mae: 0.4676\n",
      "Epoch 64/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1153 - mae: 0.2571 - val_loss: 0.2932 - val_mae: 0.4607\n",
      "Epoch 65/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1154 - mae: 0.2429 - val_loss: 0.3112 - val_mae: 0.4539\n",
      "Epoch 66/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1331 - mae: 0.2635 - val_loss: 0.2706 - val_mae: 0.4698\n",
      "Epoch 67/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1154 - mae: 0.2724 - val_loss: 0.2832 - val_mae: 0.4600\n",
      "Epoch 68/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1740 - mae: 0.3223 - val_loss: 0.2787 - val_mae: 0.4575\n",
      "Epoch 69/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1214 - mae: 0.2551 - val_loss: 0.2933 - val_mae: 0.4492\n",
      "Epoch 70/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0987 - mae: 0.2308 - val_loss: 0.2821 - val_mae: 0.4559\n",
      "Epoch 71/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0972 - mae: 0.2361 - val_loss: 0.2817 - val_mae: 0.4610\n",
      "Epoch 72/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1227 - mae: 0.2665 - val_loss: 0.2835 - val_mae: 0.4684\n",
      "Epoch 73/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1086 - mae: 0.2598 - val_loss: 0.3089 - val_mae: 0.4593\n",
      "Epoch 74/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1100 - mae: 0.2267 - val_loss: 0.2857 - val_mae: 0.4667\n",
      "Epoch 75/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1263 - mae: 0.2851 - val_loss: 0.2692 - val_mae: 0.4724\n",
      "Epoch 76/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1080 - mae: 0.2595 - val_loss: 0.3044 - val_mae: 0.4561\n",
      "Epoch 77/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1121 - mae: 0.2355 - val_loss: 0.2794 - val_mae: 0.4668\n",
      "Epoch 78/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1147 - mae: 0.2706 - val_loss: 0.2880 - val_mae: 0.4673\n",
      "Epoch 79/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.1255 - mae: 0.2716 - val_loss: 0.2861 - val_mae: 0.4729\n",
      "Epoch 80/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1166 - mae: 0.2689 - val_loss: 0.3108 - val_mae: 0.4675\n",
      "Epoch 81/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1053 - mae: 0.2467 - val_loss: 0.2956 - val_mae: 0.4741\n",
      "Epoch 82/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1210 - mae: 0.2631 - val_loss: 0.2790 - val_mae: 0.4772\n",
      "Epoch 83/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1227 - mae: 0.2670 - val_loss: 0.2813 - val_mae: 0.4730\n",
      "Epoch 84/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1758 - mae: 0.3311 - val_loss: 0.3029 - val_mae: 0.4603\n",
      "Epoch 85/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1167 - mae: 0.2410 - val_loss: 0.2902 - val_mae: 0.4604\n",
      "Epoch 86/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1085 - mae: 0.2549 - val_loss: 0.2843 - val_mae: 0.4599\n",
      "Epoch 87/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0815 - mae: 0.2173 - val_loss: 0.3002 - val_mae: 0.4557\n",
      "Epoch 88/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1005 - mae: 0.2336 - val_loss: 0.2783 - val_mae: 0.4679\n",
      "Epoch 89/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1332 - mae: 0.2925 - val_loss: 0.2858 - val_mae: 0.4646\n",
      "Epoch 90/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1244 - mae: 0.2572 - val_loss: 0.2888 - val_mae: 0.4655\n",
      "Epoch 91/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1597 - mae: 0.3032 - val_loss: 0.2895 - val_mae: 0.4627\n",
      "Epoch 92/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1077 - mae: 0.2431 - val_loss: 0.3136 - val_mae: 0.4606\n",
      "Epoch 93/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1234 - mae: 0.2483 - val_loss: 0.2797 - val_mae: 0.4694\n",
      "Epoch 94/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1265 - mae: 0.2817 - val_loss: 0.2908 - val_mae: 0.4646\n",
      "Epoch 95/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1367 - mae: 0.2801 - val_loss: 0.3012 - val_mae: 0.4607\n",
      "Epoch 96/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1793 - mae: 0.3259 - val_loss: 0.2949 - val_mae: 0.4650\n",
      "Epoch 97/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0948 - mae: 0.2247 - val_loss: 0.3268 - val_mae: 0.4568\n",
      "Epoch 98/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1227 - mae: 0.2342 - val_loss: 0.2797 - val_mae: 0.4721\n",
      "Epoch 99/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1417 - mae: 0.3012 - val_loss: 0.2777 - val_mae: 0.4703\n",
      "Epoch 100/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0987 - mae: 0.2464 - val_loss: 0.3103 - val_mae: 0.4559\n",
      "Epoch 101/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1323 - mae: 0.2704 - val_loss: 0.2866 - val_mae: 0.4644\n",
      "Epoch 102/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1041 - mae: 0.2553 - val_loss: 0.2878 - val_mae: 0.4672\n",
      "Epoch 103/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0861 - mae: 0.2272 - val_loss: 0.2985 - val_mae: 0.4632\n",
      "Epoch 104/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1625 - mae: 0.2926 - val_loss: 0.2906 - val_mae: 0.4642\n",
      "Epoch 105/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1396 - mae: 0.2803 - val_loss: 0.2974 - val_mae: 0.4603\n",
      "Epoch 106/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1412 - mae: 0.2838 - val_loss: 0.3022 - val_mae: 0.4607\n",
      "Epoch 107/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1444 - mae: 0.2908 - val_loss: 0.2913 - val_mae: 0.4684\n",
      "Epoch 108/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1138 - mae: 0.2567 - val_loss: 0.3035 - val_mae: 0.4662\n",
      "Epoch 109/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1437 - mae: 0.2834 - val_loss: 0.2983 - val_mae: 0.4694\n",
      "Epoch 110/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0909 - mae: 0.2252 - val_loss: 0.3117 - val_mae: 0.4693\n",
      "Epoch 111/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0984 - mae: 0.2252 - val_loss: 0.3122 - val_mae: 0.4696\n",
      "Epoch 112/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1513 - mae: 0.2966 - val_loss: 0.2913 - val_mae: 0.4738\n",
      "Epoch 113/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1051 - mae: 0.2423 - val_loss: 0.3065 - val_mae: 0.4671\n",
      "Epoch 114/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1119 - mae: 0.2507 - val_loss: 0.2977 - val_mae: 0.4668\n",
      "Epoch 115/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1282 - mae: 0.2679 - val_loss: 0.2934 - val_mae: 0.4659\n",
      "Epoch 116/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1202 - mae: 0.2620 - val_loss: 0.2957 - val_mae: 0.4678\n",
      "Epoch 117/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1086 - mae: 0.2469 - val_loss: 0.3000 - val_mae: 0.4679\n",
      "Epoch 118/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1699 - mae: 0.3217 - val_loss: 0.2918 - val_mae: 0.4675\n",
      "Epoch 119/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1200 - mae: 0.2615 - val_loss: 0.3093 - val_mae: 0.4671\n",
      "Epoch 120/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0845 - mae: 0.2091 - val_loss: 0.3126 - val_mae: 0.4724\n",
      "Epoch 121/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1382 - mae: 0.2845 - val_loss: 0.2856 - val_mae: 0.4807\n",
      "Epoch 122/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1434 - mae: 0.2970 - val_loss: 0.2936 - val_mae: 0.4736\n",
      "Epoch 123/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1385 - mae: 0.2705 - val_loss: 0.3179 - val_mae: 0.4648\n",
      "Epoch 124/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1503 - mae: 0.2658 - val_loss: 0.3104 - val_mae: 0.4649\n",
      "Epoch 125/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1150 - mae: 0.2341 - val_loss: 0.2897 - val_mae: 0.4715\n",
      "Epoch 126/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1333 - mae: 0.2780 - val_loss: 0.2845 - val_mae: 0.4736\n",
      "Epoch 127/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1319 - mae: 0.2860 - val_loss: 0.3200 - val_mae: 0.4610\n",
      "Epoch 128/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1334 - mae: 0.2599 - val_loss: 0.3097 - val_mae: 0.4624\n",
      "Epoch 129/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1094 - mae: 0.2338 - val_loss: 0.2898 - val_mae: 0.4733\n",
      "Epoch 130/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1198 - mae: 0.2767 - val_loss: 0.2904 - val_mae: 0.4751\n",
      "Epoch 131/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1323 - mae: 0.2904 - val_loss: 0.2958 - val_mae: 0.4739\n",
      "Epoch 132/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1584 - mae: 0.3135 - val_loss: 0.3138 - val_mae: 0.4680\n",
      "Epoch 133/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0932 - mae: 0.1917 - val_loss: 0.3127 - val_mae: 0.4674\n",
      "Epoch 134/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1145 - mae: 0.2422 - val_loss: 0.2896 - val_mae: 0.4737\n",
      "Epoch 135/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1117 - mae: 0.2622 - val_loss: 0.3071 - val_mae: 0.4664\n",
      "Epoch 136/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1385 - mae: 0.2757 - val_loss: 0.2905 - val_mae: 0.4716\n",
      "Epoch 137/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.1616 - mae: 0.3201 - val_loss: 0.2864 - val_mae: 0.4709\n",
      "Epoch 138/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1084 - mae: 0.2505 - val_loss: 0.3108 - val_mae: 0.4702\n",
      "Epoch 139/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1302 - mae: 0.2591 - val_loss: 0.3007 - val_mae: 0.4759\n",
      "Epoch 140/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1159 - mae: 0.2563 - val_loss: 0.3149 - val_mae: 0.4718\n",
      "Epoch 141/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0912 - mae: 0.2121 - val_loss: 0.3233 - val_mae: 0.4738\n",
      "Epoch 142/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1157 - mae: 0.2395 - val_loss: 0.3090 - val_mae: 0.4799\n",
      "Epoch 143/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1198 - mae: 0.2656 - val_loss: 0.3053 - val_mae: 0.4800\n",
      "Epoch 144/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1091 - mae: 0.2453 - val_loss: 0.3069 - val_mae: 0.4804\n",
      "Epoch 145/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1254 - mae: 0.2730 - val_loss: 0.3019 - val_mae: 0.4823\n",
      "Epoch 146/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1159 - mae: 0.2513 - val_loss: 0.3071 - val_mae: 0.4783\n",
      "Epoch 147/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1336 - mae: 0.2701 - val_loss: 0.3043 - val_mae: 0.4776\n",
      "Epoch 148/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1625 - mae: 0.2979 - val_loss: 0.2939 - val_mae: 0.4812\n",
      "Epoch 149/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1195 - mae: 0.2695 - val_loss: 0.3142 - val_mae: 0.4712\n",
      "Epoch 150/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1343 - mae: 0.2693 - val_loss: 0.3147 - val_mae: 0.4731\n",
      "Epoch 151/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1138 - mae: 0.2469 - val_loss: 0.3084 - val_mae: 0.4810\n",
      "Epoch 152/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1150 - mae: 0.2562 - val_loss: 0.3021 - val_mae: 0.4854\n",
      "Epoch 153/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1362 - mae: 0.2795 - val_loss: 0.3119 - val_mae: 0.4833\n",
      "Epoch 154/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1061 - mae: 0.2294 - val_loss: 0.3235 - val_mae: 0.4797\n",
      "Epoch 155/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1362 - mae: 0.2816 - val_loss: 0.2963 - val_mae: 0.4861\n",
      "Epoch 156/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1358 - mae: 0.2868 - val_loss: 0.2979 - val_mae: 0.4841\n",
      "Epoch 157/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1275 - mae: 0.2780 - val_loss: 0.3090 - val_mae: 0.4783\n",
      "Epoch 158/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1235 - mae: 0.2602 - val_loss: 0.3083 - val_mae: 0.4777\n",
      "Epoch 159/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1337 - mae: 0.2776 - val_loss: 0.3044 - val_mae: 0.4797\n",
      "Epoch 160/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1076 - mae: 0.2456 - val_loss: 0.3116 - val_mae: 0.4739\n",
      "Epoch 161/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1472 - mae: 0.2795 - val_loss: 0.2893 - val_mae: 0.4822\n",
      "Epoch 162/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1110 - mae: 0.2637 - val_loss: 0.2931 - val_mae: 0.4798\n",
      "Epoch 163/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1520 - mae: 0.3085 - val_loss: 0.2982 - val_mae: 0.4799\n",
      "Epoch 164/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1172 - mae: 0.2574 - val_loss: 0.3054 - val_mae: 0.4790\n",
      "Epoch 165/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0953 - mae: 0.2252 - val_loss: 0.3114 - val_mae: 0.4766\n",
      "Epoch 166/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1068 - mae: 0.2384 - val_loss: 0.2916 - val_mae: 0.4806\n",
      "Epoch 167/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1290 - mae: 0.2764 - val_loss: 0.2894 - val_mae: 0.4800\n",
      "Epoch 168/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1192 - mae: 0.2639 - val_loss: 0.3139 - val_mae: 0.4755\n",
      "Epoch 169/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1772 - mae: 0.2984 - val_loss: 0.3053 - val_mae: 0.4834\n",
      "Epoch 170/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1197 - mae: 0.2652 - val_loss: 0.3281 - val_mae: 0.4822\n",
      "Epoch 171/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1239 - mae: 0.2475 - val_loss: 0.3146 - val_mae: 0.4862\n",
      "Epoch 172/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0886 - mae: 0.2202 - val_loss: 0.3069 - val_mae: 0.4876\n",
      "Epoch 173/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0914 - mae: 0.2321 - val_loss: 0.2974 - val_mae: 0.4876\n",
      "Epoch 174/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1302 - mae: 0.2863 - val_loss: 0.3011 - val_mae: 0.4871\n",
      "Epoch 175/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1385 - mae: 0.2791 - val_loss: 0.3027 - val_mae: 0.4878\n",
      "Epoch 176/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1238 - mae: 0.2640 - val_loss: 0.3212 - val_mae: 0.4822\n",
      "Epoch 177/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0883 - mae: 0.1996 - val_loss: 0.3145 - val_mae: 0.4850\n",
      "Epoch 178/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1485 - mae: 0.2857 - val_loss: 0.3018 - val_mae: 0.4921\n",
      "Epoch 179/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - loss: 0.1285 - mae: 0.2716 - val_loss: 0.3137 - val_mae: 0.4881\n",
      "Epoch 180/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1505 - mae: 0.2700 - val_loss: 0.3192 - val_mae: 0.4852\n",
      "Epoch 181/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1189 - mae: 0.2382 - val_loss: 0.3192 - val_mae: 0.4877\n",
      "Epoch 182/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1184 - mae: 0.2420 - val_loss: 0.3176 - val_mae: 0.4899\n",
      "Epoch 183/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1069 - mae: 0.2374 - val_loss: 0.3190 - val_mae: 0.4876\n",
      "Epoch 184/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1263 - mae: 0.2625 - val_loss: 0.3132 - val_mae: 0.4911\n",
      "Epoch 185/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0977 - mae: 0.2291 - val_loss: 0.3265 - val_mae: 0.4881\n",
      "Epoch 186/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1499 - mae: 0.2918 - val_loss: 0.3181 - val_mae: 0.4914\n",
      "Epoch 187/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0989 - mae: 0.2290 - val_loss: 0.3148 - val_mae: 0.4908\n",
      "Epoch 188/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1446 - mae: 0.2845 - val_loss: 0.3000 - val_mae: 0.4920\n",
      "Epoch 189/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1071 - mae: 0.2440 - val_loss: 0.3132 - val_mae: 0.4852\n",
      "Epoch 190/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1071 - mae: 0.2419 - val_loss: 0.3149 - val_mae: 0.4839\n",
      "Epoch 191/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1346 - mae: 0.2783 - val_loss: 0.3058 - val_mae: 0.4879\n",
      "Epoch 192/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1053 - mae: 0.2408 - val_loss: 0.3092 - val_mae: 0.4865\n",
      "Epoch 193/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1477 - mae: 0.2826 - val_loss: 0.3046 - val_mae: 0.4860\n",
      "Epoch 194/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.1350 - mae: 0.2742 - val_loss: 0.3148 - val_mae: 0.4797\n",
      "Epoch 195/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0951 - mae: 0.2167 - val_loss: 0.3237 - val_mae: 0.4778\n",
      "Epoch 196/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1263 - mae: 0.2669 - val_loss: 0.2925 - val_mae: 0.4895\n",
      "Epoch 197/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1003 - mae: 0.2409 - val_loss: 0.3014 - val_mae: 0.4830\n",
      "Epoch 198/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0904 - mae: 0.2279 - val_loss: 0.3131 - val_mae: 0.4815\n",
      "Epoch 199/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1320 - mae: 0.2707 - val_loss: 0.3013 - val_mae: 0.4870\n",
      "Epoch 200/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 0.1071 - mae: 0.2432 - val_loss: 0.3167 - val_mae: 0.4849\n",
      "Epoch 201/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.0935 - mae: 0.2103 - val_loss: 0.3084 - val_mae: 0.4869\n",
      "Epoch 202/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1329 - mae: 0.2697 - val_loss: 0.3026 - val_mae: 0.4846\n",
      "Epoch 203/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1222 - mae: 0.2663 - val_loss: 0.3206 - val_mae: 0.4775\n",
      "Epoch 204/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1200 - mae: 0.2411 - val_loss: 0.3121 - val_mae: 0.4811\n",
      "Epoch 205/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0857 - mae: 0.2200 - val_loss: 0.3069 - val_mae: 0.4857\n",
      "Epoch 206/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1090 - mae: 0.2481 - val_loss: 0.2981 - val_mae: 0.4896\n",
      "Epoch 207/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1036 - mae: 0.2521 - val_loss: 0.3041 - val_mae: 0.4863\n",
      "Epoch 208/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1260 - mae: 0.2764 - val_loss: 0.3042 - val_mae: 0.4879\n",
      "Epoch 209/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1351 - mae: 0.2769 - val_loss: 0.3176 - val_mae: 0.4862\n",
      "Epoch 210/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1345 - mae: 0.2618 - val_loss: 0.3211 - val_mae: 0.4878\n",
      "Epoch 211/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0910 - mae: 0.2226 - val_loss: 0.3214 - val_mae: 0.4898\n",
      "Epoch 212/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0926 - mae: 0.2227 - val_loss: 0.3110 - val_mae: 0.4886\n",
      "Epoch 213/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1630 - mae: 0.3123 - val_loss: 0.2939 - val_mae: 0.4904\n",
      "Epoch 214/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1341 - mae: 0.2994 - val_loss: 0.3187 - val_mae: 0.4825\n",
      "Epoch 215/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.1384 - mae: 0.2784 - val_loss: 0.3260 - val_mae: 0.4828\n",
      "Epoch 216/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1526 - mae: 0.2851 - val_loss: 0.3193 - val_mae: 0.4880\n",
      "Epoch 217/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.1216 - mae: 0.2473 - val_loss: 0.3196 - val_mae: 0.4886\n",
      "Epoch 218/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1285 - mae: 0.2696 - val_loss: 0.3253 - val_mae: 0.4862\n",
      "Epoch 219/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1445 - mae: 0.2791 - val_loss: 0.3263 - val_mae: 0.4861\n",
      "Epoch 220/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1689 - mae: 0.3033 - val_loss: 0.3124 - val_mae: 0.4900\n",
      "Epoch 221/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1270 - mae: 0.2771 - val_loss: 0.3287 - val_mae: 0.4879\n",
      "Epoch 222/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0928 - mae: 0.2082 - val_loss: 0.3279 - val_mae: 0.4898\n",
      "Epoch 223/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1587 - mae: 0.2984 - val_loss: 0.3091 - val_mae: 0.4980\n",
      "Epoch 224/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1449 - mae: 0.3028 - val_loss: 0.3232 - val_mae: 0.4915\n",
      "Epoch 225/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1407 - mae: 0.2742 - val_loss: 0.3245 - val_mae: 0.4891\n",
      "Epoch 226/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1337 - mae: 0.2645 - val_loss: 0.3272 - val_mae: 0.4891\n",
      "Epoch 227/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1378 - mae: 0.2744 - val_loss: 0.3222 - val_mae: 0.4918\n",
      "Epoch 228/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1101 - mae: 0.2364 - val_loss: 0.3292 - val_mae: 0.4906\n",
      "Epoch 229/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1342 - mae: 0.2704 - val_loss: 0.3286 - val_mae: 0.4910\n",
      "Epoch 230/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1085 - mae: 0.2356 - val_loss: 0.3219 - val_mae: 0.4930\n",
      "Epoch 231/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1306 - mae: 0.2635 - val_loss: 0.3201 - val_mae: 0.4937\n",
      "Epoch 232/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1383 - mae: 0.2675 - val_loss: 0.3179 - val_mae: 0.4930\n",
      "Epoch 233/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1198 - mae: 0.2424 - val_loss: 0.3333 - val_mae: 0.4899\n",
      "Epoch 234/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1295 - mae: 0.2535 - val_loss: 0.3150 - val_mae: 0.4880\n",
      "Epoch 235/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1435 - mae: 0.2881 - val_loss: 0.3121 - val_mae: 0.4884\n",
      "Epoch 236/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.1374 - mae: 0.2773 - val_loss: 0.3237 - val_mae: 0.4872\n",
      "Epoch 237/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1318 - mae: 0.2583 - val_loss: 0.3303 - val_mae: 0.4906\n",
      "Epoch 238/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.1420 - mae: 0.2835 - val_loss: 0.3293 - val_mae: 0.4923\n",
      "Epoch 239/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1149 - mae: 0.2489 - val_loss: 0.3202 - val_mae: 0.4909\n",
      "Epoch 240/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1180 - mae: 0.2527 - val_loss: 0.3226 - val_mae: 0.4885\n",
      "Epoch 241/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0849 - mae: 0.1992 - val_loss: 0.3221 - val_mae: 0.4898\n",
      "Epoch 242/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1001 - mae: 0.2221 - val_loss: 0.3172 - val_mae: 0.4930\n",
      "Epoch 243/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1105 - mae: 0.2507 - val_loss: 0.3239 - val_mae: 0.4950\n",
      "Epoch 244/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1143 - mae: 0.2521 - val_loss: 0.3182 - val_mae: 0.4968\n",
      "Epoch 245/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0996 - mae: 0.2349 - val_loss: 0.3246 - val_mae: 0.4927\n",
      "Epoch 246/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0887 - mae: 0.2152 - val_loss: 0.3241 - val_mae: 0.4899\n",
      "Epoch 247/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1376 - mae: 0.2819 - val_loss: 0.3038 - val_mae: 0.4972\n",
      "Epoch 248/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0891 - mae: 0.2379 - val_loss: 0.3369 - val_mae: 0.4950\n",
      "Epoch 249/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1090 - mae: 0.2344 - val_loss: 0.3322 - val_mae: 0.4995\n",
      "Epoch 250/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1185 - mae: 0.2559 - val_loss: 0.3411 - val_mae: 0.5019\n",
      "Epoch 251/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1536 - mae: 0.2916 - val_loss: 0.3359 - val_mae: 0.5073\n",
      "Epoch 252/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0838 - mae: 0.1971 - val_loss: 0.3657 - val_mae: 0.4947\n",
      "Epoch 253/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1133 - mae: 0.2252 - val_loss: 0.3195 - val_mae: 0.5046\n",
      "Epoch 254/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0879 - mae: 0.2239 - val_loss: 0.3255 - val_mae: 0.4987\n",
      "Epoch 255/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1008 - mae: 0.2388 - val_loss: 0.3254 - val_mae: 0.5080\n",
      "Epoch 256/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1081 - mae: 0.2416 - val_loss: 0.3363 - val_mae: 0.5091\n",
      "Epoch 257/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1301 - mae: 0.2702 - val_loss: 0.3335 - val_mae: 0.5094\n",
      "Epoch 258/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1299 - mae: 0.2694 - val_loss: 0.3449 - val_mae: 0.5035\n",
      "Epoch 259/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1320 - mae: 0.2606 - val_loss: 0.3417 - val_mae: 0.5075\n",
      "Epoch 260/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.1009 - mae: 0.2342 - val_loss: 0.3570 - val_mae: 0.5082\n",
      "Epoch 261/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0800 - mae: 0.1908 - val_loss: 0.3645 - val_mae: 0.5112\n",
      "Epoch 262/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0772 - mae: 0.1923 - val_loss: 0.3475 - val_mae: 0.5205\n",
      "Epoch 263/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1471 - mae: 0.3036 - val_loss: 0.3246 - val_mae: 0.5032\n",
      "Epoch 264/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0965 - mae: 0.2354 - val_loss: 0.3204 - val_mae: 0.4973\n",
      "Epoch 265/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1192 - mae: 0.2569 - val_loss: 0.3551 - val_mae: 0.4886\n",
      "Epoch 266/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0997 - mae: 0.2075 - val_loss: 0.3241 - val_mae: 0.4954\n",
      "Epoch 267/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1328 - mae: 0.2829 - val_loss: 0.3093 - val_mae: 0.5001\n",
      "Epoch 268/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1321 - mae: 0.2928 - val_loss: 0.3295 - val_mae: 0.4960\n",
      "Epoch 269/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1100 - mae: 0.2363 - val_loss: 0.3377 - val_mae: 0.4959\n",
      "Epoch 270/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1101 - mae: 0.2320 - val_loss: 0.3292 - val_mae: 0.4993\n",
      "Epoch 271/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1134 - mae: 0.2517 - val_loss: 0.3358 - val_mae: 0.5017\n",
      "Epoch 272/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0990 - mae: 0.2226 - val_loss: 0.3467 - val_mae: 0.5030\n",
      "Epoch 273/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1402 - mae: 0.2823 - val_loss: 0.3396 - val_mae: 0.5054\n",
      "Epoch 274/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1378 - mae: 0.2667 - val_loss: 0.3449 - val_mae: 0.5039\n",
      "Epoch 275/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0982 - mae: 0.2198 - val_loss: 0.3353 - val_mae: 0.5077\n",
      "Epoch 276/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0927 - mae: 0.2294 - val_loss: 0.3228 - val_mae: 0.5105\n",
      "Epoch 277/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1316 - mae: 0.2975 - val_loss: 0.3491 - val_mae: 0.5070\n",
      "Epoch 278/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1139 - mae: 0.2154 - val_loss: 0.3727 - val_mae: 0.5058\n",
      "Epoch 279/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1125 - mae: 0.2273 - val_loss: 0.3371 - val_mae: 0.5145\n",
      "Epoch 280/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1050 - mae: 0.2500 - val_loss: 0.3510 - val_mae: 0.5163\n",
      "Epoch 281/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1040 - mae: 0.2387 - val_loss: 0.3553 - val_mae: 0.5250\n",
      "Epoch 282/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1218 - mae: 0.2655 - val_loss: 0.3391 - val_mae: 0.5116\n",
      "Epoch 283/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1186 - mae: 0.2615 - val_loss: 0.3586 - val_mae: 0.4988\n",
      "Epoch 284/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1158 - mae: 0.2270 - val_loss: 0.3054 - val_mae: 0.4822\n",
      "Epoch 285/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1422 - mae: 0.2510 - val_loss: 0.3073 - val_mae: 0.4853\n",
      "Epoch 286/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1217 - mae: 0.2543 - val_loss: 0.3432 - val_mae: 0.4994\n",
      "Epoch 287/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1164 - mae: 0.2571 - val_loss: 0.3311 - val_mae: 0.5094\n",
      "Epoch 288/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0997 - mae: 0.2254 - val_loss: 0.3142 - val_mae: 0.5116\n",
      "Epoch 289/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1000 - mae: 0.2319 - val_loss: 0.3485 - val_mae: 0.5036\n",
      "Epoch 290/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0848 - mae: 0.2140 - val_loss: 0.3267 - val_mae: 0.5132\n",
      "Epoch 291/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1276 - mae: 0.2815 - val_loss: 0.3538 - val_mae: 0.5067\n",
      "Epoch 292/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1372 - mae: 0.2388 - val_loss: 0.3592 - val_mae: 0.4986\n",
      "Epoch 293/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1456 - mae: 0.2681 - val_loss: 0.3108 - val_mae: 0.5092\n",
      "Epoch 294/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1387 - mae: 0.2835 - val_loss: 0.3437 - val_mae: 0.5011\n",
      "Epoch 295/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0885 - mae: 0.1631 - val_loss: 0.3288 - val_mae: 0.5120\n",
      "Epoch 296/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1114 - mae: 0.2581 - val_loss: 0.3257 - val_mae: 0.5195\n",
      "Epoch 297/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1270 - mae: 0.2692 - val_loss: 0.4159 - val_mae: 0.5322\n",
      "Epoch 298/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1169 - mae: 0.2119 - val_loss: 0.3558 - val_mae: 0.4978\n",
      "Epoch 299/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1073 - mae: 0.2169 - val_loss: 0.3126 - val_mae: 0.4914\n",
      "Epoch 300/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1334 - mae: 0.2864 - val_loss: 0.3094 - val_mae: 0.5058\n",
      "Epoch 301/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1233 - mae: 0.2793 - val_loss: 0.3550 - val_mae: 0.5253\n",
      "Epoch 302/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1368 - mae: 0.2453 - val_loss: 0.4020 - val_mae: 0.5532\n",
      "Epoch 303/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1303 - mae: 0.2415 - val_loss: 0.4053 - val_mae: 0.5548\n",
      "Epoch 304/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0653 - mae: 0.1597 - val_loss: 0.3827 - val_mae: 0.5400\n",
      "Epoch 305/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1213 - mae: 0.2732 - val_loss: 0.3720 - val_mae: 0.5465\n",
      "Epoch 306/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1358 - mae: 0.2512 - val_loss: 0.3891 - val_mae: 0.5173\n",
      "Epoch 307/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1034 - mae: 0.1986 - val_loss: 0.3824 - val_mae: 0.5656\n",
      "Epoch 308/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1126 - mae: 0.2477 - val_loss: 0.3671 - val_mae: 0.4900\n",
      "Epoch 309/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1106 - mae: 0.2072 - val_loss: 0.3084 - val_mae: 0.4958\n",
      "Epoch 310/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1382 - mae: 0.2984 - val_loss: 0.3137 - val_mae: 0.4915\n",
      "Epoch 311/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1171 - mae: 0.2417 - val_loss: 0.3413 - val_mae: 0.4855\n",
      "Epoch 312/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0909 - mae: 0.1910 - val_loss: 0.3149 - val_mae: 0.4969\n",
      "Epoch 313/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1060 - mae: 0.2502 - val_loss: 0.3176 - val_mae: 0.4994\n",
      "Epoch 314/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1162 - mae: 0.2538 - val_loss: 0.4366 - val_mae: 0.5020\n",
      "Epoch 315/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1558 - mae: 0.2705 - val_loss: 0.2655 - val_mae: 0.4638\n",
      "Epoch 316/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1187 - mae: 0.2872 - val_loss: 0.2952 - val_mae: 0.4822\n",
      "Epoch 317/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1334 - mae: 0.2797 - val_loss: 0.3118 - val_mae: 0.4940\n",
      "Epoch 318/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1144 - mae: 0.2499 - val_loss: 0.3280 - val_mae: 0.4914\n",
      "Epoch 319/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0787 - mae: 0.2003 - val_loss: 0.3186 - val_mae: 0.4874\n",
      "Epoch 320/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.1219 - mae: 0.2547 - val_loss: 0.2966 - val_mae: 0.4918\n",
      "Epoch 321/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1073 - mae: 0.2539 - val_loss: 0.3076 - val_mae: 0.4884\n",
      "Epoch 322/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1608 - mae: 0.3052 - val_loss: 0.3030 - val_mae: 0.4861\n",
      "Epoch 323/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1234 - mae: 0.2554 - val_loss: 0.3156 - val_mae: 0.4834\n",
      "Epoch 324/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1294 - mae: 0.2449 - val_loss: 0.3022 - val_mae: 0.4888\n",
      "Epoch 325/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1569 - mae: 0.2969 - val_loss: 0.3013 - val_mae: 0.4897\n",
      "Epoch 326/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1027 - mae: 0.2358 - val_loss: 0.3333 - val_mae: 0.4800\n",
      "Epoch 327/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1364 - mae: 0.2626 - val_loss: 0.3066 - val_mae: 0.4916\n",
      "Epoch 328/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1364 - mae: 0.2783 - val_loss: 0.3325 - val_mae: 0.4896\n",
      "Epoch 329/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1207 - mae: 0.2330 - val_loss: 0.3513 - val_mae: 0.4918\n",
      "Epoch 330/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.1280 - mae: 0.2603 - val_loss: 0.3075 - val_mae: 0.5032\n",
      "Epoch 331/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.1176 - mae: 0.2703 - val_loss: 0.3405 - val_mae: 0.4972\n",
      "Epoch 332/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1128 - mae: 0.2072 - val_loss: 0.3395 - val_mae: 0.5079\n",
      "Epoch 333/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0873 - mae: 0.2036 - val_loss: 0.3574 - val_mae: 0.5300\n",
      "Epoch 334/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1072 - mae: 0.2338 - val_loss: 0.3503 - val_mae: 0.5408\n",
      "Epoch 335/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0957 - mae: 0.2269 - val_loss: 0.3949 - val_mae: 0.5441\n",
      "Epoch 336/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1147 - mae: 0.2219 - val_loss: 0.4028 - val_mae: 0.5629\n",
      "Epoch 337/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1077 - mae: 0.2240 - val_loss: 0.3964 - val_mae: 0.5701\n",
      "Epoch 338/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0860 - mae: 0.2128 - val_loss: 0.4248 - val_mae: 0.5744\n",
      "Epoch 339/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1193 - mae: 0.2399 - val_loss: 0.4223 - val_mae: 0.5789\n",
      "Epoch 340/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1152 - mae: 0.2352 - val_loss: 0.4176 - val_mae: 0.5730\n",
      "Epoch 341/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0841 - mae: 0.1986 - val_loss: 0.4096 - val_mae: 0.5616\n",
      "Epoch 342/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1085 - mae: 0.2199 - val_loss: 0.4077 - val_mae: 0.5680\n",
      "Epoch 343/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0804 - mae: 0.2008 - val_loss: 0.4414 - val_mae: 0.5785\n",
      "Epoch 344/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1073 - mae: 0.2142 - val_loss: 0.4113 - val_mae: 0.5862\n",
      "Epoch 345/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0768 - mae: 0.1949 - val_loss: 0.4227 - val_mae: 0.5692\n",
      "Epoch 346/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1149 - mae: 0.2145 - val_loss: 0.4002 - val_mae: 0.5651\n",
      "Epoch 347/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0872 - mae: 0.2011 - val_loss: 0.4119 - val_mae: 0.5660\n",
      "Epoch 348/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0992 - mae: 0.2036 - val_loss: 0.4165 - val_mae: 0.5674\n",
      "Epoch 349/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0816 - mae: 0.1779 - val_loss: 0.3803 - val_mae: 0.5482\n",
      "Epoch 350/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1433 - mae: 0.2608 - val_loss: 0.3668 - val_mae: 0.5425\n",
      "Epoch 351/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1308 - mae: 0.2617 - val_loss: 0.3922 - val_mae: 0.5506\n",
      "Epoch 352/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.1316 - mae: 0.2305 - val_loss: 0.3994 - val_mae: 0.5568\n",
      "Epoch 353/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - loss: 0.0832 - mae: 0.1779 - val_loss: 0.3978 - val_mae: 0.5612\n",
      "Epoch 354/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0778 - mae: 0.1837 - val_loss: 0.3791 - val_mae: 0.5513\n",
      "Epoch 355/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1183 - mae: 0.2381 - val_loss: 0.3715 - val_mae: 0.5483\n",
      "Epoch 356/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0997 - mae: 0.2169 - val_loss: 0.4032 - val_mae: 0.5505\n",
      "Epoch 357/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1337 - mae: 0.2397 - val_loss: 0.3949 - val_mae: 0.5530\n",
      "Epoch 358/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0950 - mae: 0.1971 - val_loss: 0.3934 - val_mae: 0.5521\n",
      "Epoch 359/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0957 - mae: 0.2101 - val_loss: 0.3994 - val_mae: 0.5656\n",
      "Epoch 360/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - loss: 0.0893 - mae: 0.1842 - val_loss: 0.3887 - val_mae: 0.5647\n",
      "Epoch 361/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1061 - mae: 0.2240 - val_loss: 0.3811 - val_mae: 0.5644\n",
      "Epoch 362/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1148 - mae: 0.2451 - val_loss: 0.4083 - val_mae: 0.5690\n",
      "Epoch 363/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0885 - mae: 0.1833 - val_loss: 0.4006 - val_mae: 0.5596\n",
      "Epoch 364/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0797 - mae: 0.1813 - val_loss: 0.3817 - val_mae: 0.5412\n",
      "Epoch 365/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0896 - mae: 0.1914 - val_loss: 0.3644 - val_mae: 0.5362\n",
      "Epoch 366/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1176 - mae: 0.2362 - val_loss: 0.3640 - val_mae: 0.5369\n",
      "Epoch 367/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0930 - mae: 0.2076 - val_loss: 0.4008 - val_mae: 0.5486\n",
      "Epoch 368/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1124 - mae: 0.2179 - val_loss: 0.3972 - val_mae: 0.5577\n",
      "Epoch 369/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0607 - mae: 0.1640 - val_loss: 0.4265 - val_mae: 0.5577\n",
      "Epoch 370/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1110 - mae: 0.2157 - val_loss: 0.3828 - val_mae: 0.5507\n",
      "Epoch 371/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - loss: 0.0869 - mae: 0.2037 - val_loss: 0.3915 - val_mae: 0.5483\n",
      "Epoch 372/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1129 - mae: 0.2263 - val_loss: 0.3956 - val_mae: 0.5518\n",
      "Epoch 373/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.1031 - mae: 0.2041 - val_loss: 0.3858 - val_mae: 0.5473\n",
      "Epoch 374/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.1471 - mae: 0.2642 - val_loss: 0.3751 - val_mae: 0.5454\n",
      "Epoch 375/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1386 - mae: 0.2558 - val_loss: 0.3934 - val_mae: 0.5485\n",
      "Epoch 376/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1154 - mae: 0.2225 - val_loss: 0.4002 - val_mae: 0.5528\n",
      "Epoch 377/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0720 - mae: 0.1609 - val_loss: 0.4041 - val_mae: 0.5506\n",
      "Epoch 378/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0827 - mae: 0.1750 - val_loss: 0.3866 - val_mae: 0.5505\n",
      "Epoch 379/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1250 - mae: 0.2632 - val_loss: 0.3710 - val_mae: 0.5531\n",
      "Epoch 380/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1176 - mae: 0.2560 - val_loss: 0.4096 - val_mae: 0.5535\n",
      "Epoch 381/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1126 - mae: 0.2115 - val_loss: 0.4012 - val_mae: 0.5460\n",
      "Epoch 382/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1123 - mae: 0.2031 - val_loss: 0.3875 - val_mae: 0.5559\n",
      "Epoch 383/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0767 - mae: 0.1913 - val_loss: 0.4037 - val_mae: 0.5563\n",
      "Epoch 384/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0777 - mae: 0.1813 - val_loss: 0.3914 - val_mae: 0.5553\n",
      "Epoch 385/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1214 - mae: 0.2440 - val_loss: 0.3971 - val_mae: 0.5564\n",
      "Epoch 386/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0868 - mae: 0.1887 - val_loss: 0.4047 - val_mae: 0.5589\n",
      "Epoch 387/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0706 - mae: 0.1744 - val_loss: 0.3911 - val_mae: 0.5597\n",
      "Epoch 388/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1253 - mae: 0.2457 - val_loss: 0.3698 - val_mae: 0.5445\n",
      "Epoch 389/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0828 - mae: 0.1899 - val_loss: 0.3819 - val_mae: 0.5382\n",
      "Epoch 390/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1283 - mae: 0.2214 - val_loss: 0.3648 - val_mae: 0.5318\n",
      "Epoch 391/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - loss: 0.0826 - mae: 0.1947 - val_loss: 0.3600 - val_mae: 0.5327\n",
      "Epoch 392/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1066 - mae: 0.2258 - val_loss: 0.3691 - val_mae: 0.5404\n",
      "Epoch 393/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0799 - mae: 0.1789 - val_loss: 0.3792 - val_mae: 0.5404\n",
      "Epoch 394/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - loss: 0.1048 - mae: 0.2126 - val_loss: 0.3837 - val_mae: 0.5410\n",
      "Epoch 395/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0928 - mae: 0.1840 - val_loss: 0.3717 - val_mae: 0.5317\n",
      "Epoch 396/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1420 - mae: 0.2576 - val_loss: 0.3696 - val_mae: 0.5412\n",
      "Epoch 397/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1134 - mae: 0.2316 - val_loss: 0.3886 - val_mae: 0.5458\n",
      "Epoch 398/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1011 - mae: 0.1990 - val_loss: 0.3992 - val_mae: 0.5468\n",
      "Epoch 399/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0950 - mae: 0.1874 - val_loss: 0.3884 - val_mae: 0.5423\n",
      "Epoch 400/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0933 - mae: 0.1997 - val_loss: 0.3763 - val_mae: 0.5430\n",
      "Epoch 401/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1083 - mae: 0.2357 - val_loss: 0.3799 - val_mae: 0.5594\n",
      "Epoch 402/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0735 - mae: 0.1780 - val_loss: 0.4108 - val_mae: 0.5471\n",
      "Epoch 403/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0670 - mae: 0.1412 - val_loss: 0.3718 - val_mae: 0.5351\n",
      "Epoch 404/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0978 - mae: 0.2128 - val_loss: 0.3513 - val_mae: 0.5359\n",
      "Epoch 405/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1136 - mae: 0.2417 - val_loss: 0.3416 - val_mae: 0.5112\n",
      "Epoch 406/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0926 - mae: 0.2042 - val_loss: 0.3556 - val_mae: 0.5098\n",
      "Epoch 407/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1015 - mae: 0.1946 - val_loss: 0.3569 - val_mae: 0.5318\n",
      "Epoch 408/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0782 - mae: 0.1917 - val_loss: 0.3664 - val_mae: 0.5358\n",
      "Epoch 409/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1092 - mae: 0.2134 - val_loss: 0.3580 - val_mae: 0.5310\n",
      "Epoch 410/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0821 - mae: 0.1854 - val_loss: 0.3680 - val_mae: 0.5338\n",
      "Epoch 411/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - loss: 0.0932 - mae: 0.2097 - val_loss: 0.3729 - val_mae: 0.5354\n",
      "Epoch 412/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1243 - mae: 0.2433 - val_loss: 0.3694 - val_mae: 0.5348\n",
      "Epoch 413/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0784 - mae: 0.1774 - val_loss: 0.3756 - val_mae: 0.5282\n",
      "Epoch 414/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0933 - mae: 0.1961 - val_loss: 0.3570 - val_mae: 0.5315\n",
      "Epoch 415/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1078 - mae: 0.2400 - val_loss: 0.3666 - val_mae: 0.5292\n",
      "Epoch 416/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0899 - mae: 0.1880 - val_loss: 0.3740 - val_mae: 0.5265\n",
      "Epoch 417/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0936 - mae: 0.1935 - val_loss: 0.3729 - val_mae: 0.5329\n",
      "Epoch 418/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1092 - mae: 0.2248 - val_loss: 0.3603 - val_mae: 0.5393\n",
      "Epoch 419/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0988 - mae: 0.2324 - val_loss: 0.3735 - val_mae: 0.5386\n",
      "Epoch 420/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0831 - mae: 0.1844 - val_loss: 0.3898 - val_mae: 0.5382\n",
      "Epoch 421/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0939 - mae: 0.1937 - val_loss: 0.3732 - val_mae: 0.5392\n",
      "Epoch 422/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - loss: 0.1371 - mae: 0.2580 - val_loss: 0.3593 - val_mae: 0.5400\n",
      "Epoch 423/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - loss: 0.0988 - mae: 0.2183 - val_loss: 0.3807 - val_mae: 0.5402\n",
      "Epoch 424/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - loss: 0.1099 - mae: 0.2108 - val_loss: 0.3904 - val_mae: 0.5443\n",
      "Epoch 425/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0968 - mae: 0.1840 - val_loss: 0.3767 - val_mae: 0.5468\n",
      "Epoch 426/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1247 - mae: 0.2402 - val_loss: 0.3667 - val_mae: 0.5481\n",
      "Epoch 427/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0681 - mae: 0.1850 - val_loss: 0.4028 - val_mae: 0.5363\n",
      "Epoch 428/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1010 - mae: 0.1868 - val_loss: 0.3565 - val_mae: 0.5341\n",
      "Epoch 429/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0879 - mae: 0.2103 - val_loss: 0.3526 - val_mae: 0.5332\n",
      "Epoch 430/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0758 - mae: 0.1969 - val_loss: 0.3731 - val_mae: 0.5231\n",
      "Epoch 431/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1362 - mae: 0.2374 - val_loss: 0.3499 - val_mae: 0.5224\n",
      "Epoch 432/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - loss: 0.0823 - mae: 0.1920 - val_loss: 0.3648 - val_mae: 0.5266\n",
      "Epoch 433/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0979 - mae: 0.2022 - val_loss: 0.3619 - val_mae: 0.5269\n",
      "Epoch 434/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0967 - mae: 0.1958 - val_loss: 0.3625 - val_mae: 0.5270\n",
      "Epoch 435/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1036 - mae: 0.2070 - val_loss: 0.3606 - val_mae: 0.5254\n",
      "Epoch 436/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0900 - mae: 0.2044 - val_loss: 0.3658 - val_mae: 0.5278\n",
      "Epoch 437/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0895 - mae: 0.2041 - val_loss: 0.3614 - val_mae: 0.5319\n",
      "Epoch 438/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1320 - mae: 0.2547 - val_loss: 0.3628 - val_mae: 0.5310\n",
      "Epoch 439/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1138 - mae: 0.2227 - val_loss: 0.3739 - val_mae: 0.5287\n",
      "Epoch 440/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1021 - mae: 0.2086 - val_loss: 0.3743 - val_mae: 0.5335\n",
      "Epoch 441/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0707 - mae: 0.1664 - val_loss: 0.3747 - val_mae: 0.5380\n",
      "Epoch 442/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0782 - mae: 0.1890 - val_loss: 0.3644 - val_mae: 0.5448\n",
      "Epoch 443/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0836 - mae: 0.2098 - val_loss: 0.3787 - val_mae: 0.5446\n",
      "Epoch 444/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - loss: 0.1136 - mae: 0.2262 - val_loss: 0.3858 - val_mae: 0.5464\n",
      "Epoch 445/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1127 - mae: 0.2232 - val_loss: 0.3790 - val_mae: 0.5459\n",
      "Epoch 446/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0748 - mae: 0.1836 - val_loss: 0.3842 - val_mae: 0.5496\n",
      "Epoch 447/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1109 - mae: 0.2231 - val_loss: 0.3778 - val_mae: 0.5427\n",
      "Epoch 448/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1164 - mae: 0.2366 - val_loss: 0.3926 - val_mae: 0.5409\n",
      "Epoch 449/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0948 - mae: 0.1828 - val_loss: 0.3754 - val_mae: 0.5403\n",
      "Epoch 450/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1165 - mae: 0.2340 - val_loss: 0.3780 - val_mae: 0.5441\n",
      "Epoch 451/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1347 - mae: 0.2560 - val_loss: 0.3756 - val_mae: 0.5423\n",
      "Epoch 452/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0876 - mae: 0.2011 - val_loss: 0.3952 - val_mae: 0.5431\n",
      "Epoch 453/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.1001 - mae: 0.2085 - val_loss: 0.3879 - val_mae: 0.5405\n",
      "Epoch 454/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.1212 - mae: 0.2429 - val_loss: 0.3664 - val_mae: 0.5453\n",
      "Epoch 455/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0855 - mae: 0.1972 - val_loss: 0.3787 - val_mae: 0.5345\n",
      "Epoch 456/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0917 - mae: 0.2050 - val_loss: 0.3754 - val_mae: 0.5357\n",
      "Epoch 457/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0735 - mae: 0.1864 - val_loss: 0.3826 - val_mae: 0.5349\n",
      "Epoch 458/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0808 - mae: 0.1842 - val_loss: 0.3682 - val_mae: 0.5358\n",
      "Epoch 459/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0772 - mae: 0.1926 - val_loss: 0.3716 - val_mae: 0.5457\n",
      "Epoch 460/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.0901 - mae: 0.2157 - val_loss: 0.3795 - val_mae: 0.5366\n",
      "Epoch 461/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1214 - mae: 0.2259 - val_loss: 0.3744 - val_mae: 0.5338\n",
      "Epoch 462/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0865 - mae: 0.2008 - val_loss: 0.4021 - val_mae: 0.5321\n",
      "Epoch 463/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.1169 - mae: 0.2016 - val_loss: 0.3719 - val_mae: 0.5306\n",
      "Epoch 464/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0737 - mae: 0.1658 - val_loss: 0.3661 - val_mae: 0.5286\n",
      "Epoch 465/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0665 - mae: 0.1806 - val_loss: 0.3725 - val_mae: 0.5300\n",
      "Epoch 466/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1097 - mae: 0.2189 - val_loss: 0.3564 - val_mae: 0.5272\n",
      "Epoch 467/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1081 - mae: 0.2219 - val_loss: 0.3672 - val_mae: 0.5396\n",
      "Epoch 468/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1464 - mae: 0.2732 - val_loss: 0.3884 - val_mae: 0.5364\n",
      "Epoch 469/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1084 - mae: 0.2171 - val_loss: 0.4087 - val_mae: 0.5428\n",
      "Epoch 470/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1271 - mae: 0.2180 - val_loss: 0.3942 - val_mae: 0.5379\n",
      "Epoch 471/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0670 - mae: 0.1608 - val_loss: 0.3999 - val_mae: 0.5378\n",
      "Epoch 472/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.0830 - mae: 0.1655 - val_loss: 0.3735 - val_mae: 0.5468\n",
      "Epoch 473/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0987 - mae: 0.2155 - val_loss: 0.3740 - val_mae: 0.5495\n",
      "Epoch 474/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1258 - mae: 0.2471 - val_loss: 0.3709 - val_mae: 0.5381\n",
      "Epoch 475/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1478 - mae: 0.2765 - val_loss: 0.4002 - val_mae: 0.5413\n",
      "Epoch 476/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1146 - mae: 0.2053 - val_loss: 0.4182 - val_mae: 0.5452\n",
      "Epoch 477/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1451 - mae: 0.2285 - val_loss: 0.3722 - val_mae: 0.5433\n",
      "Epoch 478/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.1572 - mae: 0.2842 - val_loss: 0.3706 - val_mae: 0.5392\n",
      "Epoch 479/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.1016 - mae: 0.2087 - val_loss: 0.4054 - val_mae: 0.5385\n",
      "Epoch 480/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.0974 - mae: 0.1801 - val_loss: 0.4047 - val_mae: 0.5367\n",
      "Epoch 481/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.1024 - mae: 0.1873 - val_loss: 0.3750 - val_mae: 0.5382\n",
      "Epoch 482/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1112 - mae: 0.2314 - val_loss: 0.3703 - val_mae: 0.5355\n",
      "Epoch 483/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1313 - mae: 0.2540 - val_loss: 0.3798 - val_mae: 0.5261\n",
      "Epoch 484/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0759 - mae: 0.1741 - val_loss: 0.3911 - val_mae: 0.5268\n",
      "Epoch 485/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.1081 - mae: 0.2052 - val_loss: 0.3607 - val_mae: 0.5277\n",
      "Epoch 486/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0858 - mae: 0.2106 - val_loss: 0.3849 - val_mae: 0.5322\n",
      "Epoch 487/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0999 - mae: 0.2136 - val_loss: 0.3786 - val_mae: 0.5357\n",
      "Epoch 488/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.1185 - mae: 0.2300 - val_loss: 0.3830 - val_mae: 0.5360\n",
      "Epoch 489/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0725 - mae: 0.1728 - val_loss: 0.4085 - val_mae: 0.5362\n",
      "Epoch 490/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0900 - mae: 0.1835 - val_loss: 0.3810 - val_mae: 0.5388\n",
      "Epoch 491/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1020 - mae: 0.2087 - val_loss: 0.3773 - val_mae: 0.5364\n",
      "Epoch 492/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.0947 - mae: 0.2036 - val_loss: 0.3833 - val_mae: 0.5345\n",
      "Epoch 493/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - loss: 0.0775 - mae: 0.1791 - val_loss: 0.3885 - val_mae: 0.5359\n",
      "Epoch 494/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - loss: 0.0909 - mae: 0.1949 - val_loss: 0.3781 - val_mae: 0.5358\n",
      "Epoch 495/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1216 - mae: 0.2434 - val_loss: 0.3654 - val_mae: 0.5331\n",
      "Epoch 496/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0940 - mae: 0.2086 - val_loss: 0.3863 - val_mae: 0.5357\n",
      "Epoch 497/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.1150 - mae: 0.2122 - val_loss: 0.3938 - val_mae: 0.5366\n",
      "Epoch 498/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1171 - mae: 0.2189 - val_loss: 0.3960 - val_mae: 0.5422\n",
      "Epoch 499/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1004 - mae: 0.2123 - val_loss: 0.3936 - val_mae: 0.5441\n",
      "Epoch 500/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - loss: 0.0576 - mae: 0.1554 - val_loss: 0.3982 - val_mae: 0.5434\n"
     ]
    }
   ],
   "source": [
    "# Train the LSTM model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=500,  # You can adjust based on convergence\n",
    "    batch_size=8,  # Smaller batch size for augmented data\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3982, Validation MAE: 0.5434\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_mae = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation MAE: {val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Predicted: 0.82, Actual: 1.00\n",
      "Predicted: 0.82, Actual: 0.00\n",
      "Predicted: 0.87, Actual: 1.00\n",
      "Predicted: 0.82, Actual: 1.00\n",
      "Predicted: 0.24, Actual: 1.00\n",
      "Predicted: 0.22, Actual: 1.00\n",
      "Predicted: 0.82, Actual: 0.00\n",
      "Predicted: 0.82, Actual: 0.00\n",
      "Predicted: 0.82, Actual: 0.00\n",
      "Predicted: 0.93, Actual: 0.00\n",
      "Predicted: 0.82, Actual: 0.00\n",
      "Predicted: 0.23, Actual: 1.00\n",
      "Predicted: 0.95, Actual: 1.00\n",
      "Predicted: 0.82, Actual: 1.00\n",
      "Predicted: 0.77, Actual: 1.00\n",
      "Predicted: 0.82, Actual: 0.00\n",
      "Predicted: 0.82, Actual: 0.00\n",
      "Predicted: 0.78, Actual: 1.00\n",
      "Predicted: 0.82, Actual: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Predict scores on validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Print predictions vs. actual\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Predicted: {pred[0]:.2f}, Actual: {y_val[i]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatter plot of predictions vs. actual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_val, predictions, c='blue', label='Predicted vs Actual')\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Perfect Match')  # Reference line\n",
    "plt.xlabel('Actual Scores')\n",
    "plt.ylabel('Predicted Scores')\n",
    "plt.title('Model Predictions vs. Actual Scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737650360.519576 8979125 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n",
      "W0000 00:00:1737650360.581330 9249569 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737650360.590711 9249578 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
      "Predicted Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to determine if knees are high\n",
    "def is_knee_high(hip, knee):\n",
    "    # Knee should be at or above hip level in the y-axis (inverted coordinate system)\n",
    "    return knee[1] <= hip[1]\n",
    "\n",
    "# Path for the new test video\n",
    "new_video_path = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/sprint_technique/stages/stage2/test_videos/VID20250113142648.mp4\"\n",
    "\n",
    "# Extract keypoints for the new video\n",
    "new_keypoints = []\n",
    "cap = cv2.VideoCapture(new_video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB for MediaPipe processing\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = pose.process(frame_rgb)\n",
    "\n",
    "    if result.pose_landmarks:\n",
    "        landmarks = result.pose_landmarks.landmark\n",
    "\n",
    "        # Extract relevant keypoints for knees and hips\n",
    "        left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.LEFT_HIP].y]\n",
    "        left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y]\n",
    "\n",
    "        right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y]\n",
    "        right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y]\n",
    "\n",
    "        # Check if knees are high\n",
    "        left_knee_high = is_knee_high(left_hip, left_knee)\n",
    "        right_knee_high = is_knee_high(right_hip, right_knee)\n",
    "\n",
    "        # Store the binary values (0 or 1) for analysis\n",
    "        new_keypoints.append([int(left_knee_high), int(right_knee_high)])\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Pad the sequence to match training input length\n",
    "max_seq_length = X_train.shape[1]  # Ensure it's the same length used during training\n",
    "new_keypoints_padded = pad_sequences([new_keypoints], maxlen=max_seq_length, padding='post', dtype='float32')\n",
    "\n",
    "new_keypoints_padded = new_keypoints_padded.reshape((new_keypoints_padded.shape[0], new_keypoints_padded.shape[1], 2))\n",
    "  # Add a feature dimension\n",
    "\n",
    "# Predict score for the new video\n",
    "predicted_score = model.predict(new_keypoints_padded)\n",
    "print(f\"Predicted Score: {predicted_score[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_score(prediction):\n",
    "    \"\"\"Classify the prediction into 0, 0.5, or 1 based on thresholds.\"\"\"\n",
    "    if prediction >= 0.8:\n",
    "        return 1.0\n",
    "    elif prediction >= 0.6:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 0.5, Actual: 1.0\n",
      "Classified: 1.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 0.0\n",
      "Classified: 0.5, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Predict scores on validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Apply classification logic\n",
    "classified_predictions = [classify_score(pred[0]) for pred in predictions]\n",
    "\n",
    "# Print classified predictions vs actual scores\n",
    "for i, (pred, actual) in enumerate(zip(classified_predictions, y_val)):\n",
    "    print(f\"Classified: {pred}, Actual: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def weighted_mse(y_true, y_pred):\n",
    "    \"\"\"Weighted Mean Squared Error to prioritize true negatives.\"\"\"\n",
    "    weights = K.switch(y_true < 0.70, 2.0, 1.0)  # Weight true negatives higher\n",
    "    return K.mean(weights * K.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=weighted_mse, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
      "Classification Accuracy: 0.32\n"
     ]
    }
   ],
   "source": [
    "# Predict and classify scores\n",
    "classified_predictions = [classify_score(pred[0]) for pred in model.predict(X_val)]\n",
    "\n",
    "# Evaluate accuracy of classification\n",
    "correct = sum(1 for pred, actual in zip(classified_predictions, y_val) if pred == actual)\n",
    "accuracy = correct / len(y_val)\n",
    "\n",
    "print(f\"Classification Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/sprint_technique/stages/stage2/models/sprint_stage2.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
