{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Both legs push off powerfully, causing imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized keypoints saved to stage3-keypoints\\user100_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user100_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user100_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user100_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user100_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user101_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user101_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user101_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user101_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user101_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user102_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user102_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user102_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user102_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user102_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user10_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user10_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user10_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user10_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user10_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user11_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user11_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user11_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user11_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user11_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user12_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user12_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user12_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user12_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user12_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user13_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user13_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user13_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user13_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user13_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user14_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user14_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user14_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user14_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user14_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user17_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user17_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user17_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user17_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user17_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user19_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user19_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user19_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user19_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user19_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user1_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user1_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user1_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user1_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user1_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user20_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user20_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user20_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user20_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user20_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user21_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user21_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user21_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user21_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user21_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user22_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user22_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user22_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user22_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user22_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user2_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user2_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user2_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user2_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user2_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user3_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user3_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user3_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user3_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user3_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user4_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user4_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user4_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user4_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user4_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user5_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user5_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user5_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user5_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user5_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user6_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user6_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user6_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user6_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user6_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user7_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user7_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user7_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user7_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user7_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user8_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user8_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user8_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user8_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user8_rotate_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user9_brightness_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user9_mirrored_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user9_noise_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user9_original_normalized_keypoints.json\n",
      "Normalized keypoints saved to stage3-keypoints\\user9_rotate_normalized_keypoints.json\n",
      "Normalized keypoint extraction completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, model_complexity=2, enable_segmentation=False)\n",
    "\n",
    "# Paths\n",
    "videos_dir = \"stage3-dataset\"  # Directory containing input videos\n",
    "output_dir = \"stage3-keypoints\"  # Directory to save keypoints\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def normalize_keypoints(keypoints, reference_length):\n",
    "    \"\"\"\n",
    "    Normalize keypoints using a reference length.\n",
    "\n",
    "    Args:\n",
    "        keypoints (list): List of keypoints for a single frame.\n",
    "        reference_length (float): Reference length (e.g., shoulder width) for normalization.\n",
    "\n",
    "    Returns:\n",
    "        normalized_keypoints: List of normalized keypoints for a single frame.\n",
    "    \"\"\"\n",
    "    if reference_length == 0:  # Avoid division by zero\n",
    "        reference_length = 1\n",
    "\n",
    "    normalized_keypoints = [\n",
    "        {\n",
    "            \"x\": kp[\"x\"] / reference_length,\n",
    "            \"y\": kp[\"y\"] / reference_length,\n",
    "            \"z\": kp[\"z\"] / reference_length,\n",
    "            \"visibility\": kp[\"visibility\"],  # Visibility is not normalized\n",
    "        }\n",
    "        for kp in keypoints\n",
    "    ]\n",
    "    return normalized_keypoints\n",
    "\n",
    "def extract_keypoints_with_normalization(frame):\n",
    "    \"\"\"\n",
    "    Extract and normalize keypoints from a single frame.\n",
    "    \"\"\"\n",
    "    h, w, _ = frame.shape\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = pose.process(frame_rgb)\n",
    "    \n",
    "    if not result.pose_landmarks:\n",
    "        return None  # Skip frames where no landmarks are detected\n",
    "\n",
    "    # Extract keypoints\n",
    "    keypoints = [\n",
    "        {\"x\": lm.x * w, \"y\": lm.y * h, \"z\": lm.z * w, \"visibility\": lm.visibility}\n",
    "        for lm in result.pose_landmarks.landmark\n",
    "    ]\n",
    "\n",
    "    # Calculate reference length (distance between shoulders)\n",
    "    left_shoulder = result.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "    right_shoulder = result.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "    reference_length = np.sqrt(\n",
    "        (left_shoulder.x * w - right_shoulder.x * w) ** 2 +\n",
    "        (left_shoulder.y * h - right_shoulder.y * h) ** 2\n",
    "    )\n",
    "\n",
    "    # Normalize keypoints\n",
    "    normalized_keypoints = normalize_keypoints(keypoints, reference_length)\n",
    "    return normalized_keypoints\n",
    "\n",
    "def process_video_with_normalization(video_path, output_path, frame_skip=1):\n",
    "    \"\"\"\n",
    "    Process a video to extract and normalize keypoints and save them as a JSON file.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the video file.\n",
    "        output_path (str): Path to save keypoints as JSON.\n",
    "        frame_skip (int): Number of frames to skip between processing.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Unable to open video {video_path}\")\n",
    "        return\n",
    "\n",
    "    frame_count = 0\n",
    "    keypoints_data = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Skip frames based on frame_skip\n",
    "        if frame_count % frame_skip == 0:\n",
    "            normalized_keypoints = extract_keypoints_with_normalization(frame)\n",
    "            if normalized_keypoints:\n",
    "                keypoints_data.append({\"frame\": frame_count, \"keypoints\": normalized_keypoints})\n",
    "        \n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Save keypoints to JSON\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(keypoints_data, f, indent=4)\n",
    "\n",
    "    print(f\"Normalized keypoints saved to {output_path}\")\n",
    "\n",
    "# Example Usage: Process videos with normalization and skip every 2 frames\n",
    "for video_file in os.listdir(videos_dir):\n",
    "    if video_file.endswith(\".mp4\"):\n",
    "        video_path = os.path.join(videos_dir, video_file)\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "        output_path = os.path.join(output_dir, f\"{video_name}_normalized_keypoints.json\")\n",
    "        process_video_with_normalization(video_path, output_path, frame_skip=3)  # Skip every 2 frames\n",
    "\n",
    "print(\"Normalized keypoint extraction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed features for user100_brightness_normalized_keypoints.json\n",
      "Processed features for user100_mirrored_normalized_keypoints.json\n",
      "Processed features for user100_noise_normalized_keypoints.json\n",
      "Processed features for user100_original_normalized_keypoints.json\n",
      "Processed features for user100_rotate_normalized_keypoints.json\n",
      "Processed features for user101_brightness_normalized_keypoints.json\n",
      "Processed features for user101_mirrored_normalized_keypoints.json\n",
      "Processed features for user101_noise_normalized_keypoints.json\n",
      "Processed features for user101_original_normalized_keypoints.json\n",
      "Processed features for user101_rotate_normalized_keypoints.json\n",
      "Processed features for user102_brightness_normalized_keypoints.json\n",
      "Processed features for user102_mirrored_normalized_keypoints.json\n",
      "Processed features for user102_noise_normalized_keypoints.json\n",
      "Processed features for user102_original_normalized_keypoints.json\n",
      "Processed features for user102_rotate_normalized_keypoints.json\n",
      "Processed features for user10_brightness_normalized_keypoints.json\n",
      "Processed features for user10_mirrored_normalized_keypoints.json\n",
      "Processed features for user10_noise_normalized_keypoints.json\n",
      "Processed features for user10_original_normalized_keypoints.json\n",
      "Processed features for user10_rotate_normalized_keypoints.json\n",
      "Processed features for user11_brightness_normalized_keypoints.json\n",
      "Processed features for user11_mirrored_normalized_keypoints.json\n",
      "Processed features for user11_noise_normalized_keypoints.json\n",
      "Processed features for user11_original_normalized_keypoints.json\n",
      "Processed features for user11_rotate_normalized_keypoints.json\n",
      "Processed features for user12_brightness_normalized_keypoints.json\n",
      "Processed features for user12_mirrored_normalized_keypoints.json\n",
      "Processed features for user12_noise_normalized_keypoints.json\n",
      "Processed features for user12_original_normalized_keypoints.json\n",
      "Processed features for user12_rotate_normalized_keypoints.json\n",
      "Processed features for user13_brightness_normalized_keypoints.json\n",
      "Processed features for user13_mirrored_normalized_keypoints.json\n",
      "Processed features for user13_noise_normalized_keypoints.json\n",
      "Processed features for user13_original_normalized_keypoints.json\n",
      "Processed features for user13_rotate_normalized_keypoints.json\n",
      "Processed features for user14_brightness_normalized_keypoints.json\n",
      "Processed features for user14_mirrored_normalized_keypoints.json\n",
      "Processed features for user14_noise_normalized_keypoints.json\n",
      "Processed features for user14_original_normalized_keypoints.json\n",
      "Processed features for user14_rotate_normalized_keypoints.json\n",
      "Processed features for user17_brightness_normalized_keypoints.json\n",
      "Processed features for user17_mirrored_normalized_keypoints.json\n",
      "Processed features for user17_noise_normalized_keypoints.json\n",
      "Processed features for user17_original_normalized_keypoints.json\n",
      "Processed features for user17_rotate_normalized_keypoints.json\n",
      "Processed features for user19_brightness_normalized_keypoints.json\n",
      "Processed features for user19_mirrored_normalized_keypoints.json\n",
      "Processed features for user19_noise_normalized_keypoints.json\n",
      "Processed features for user19_original_normalized_keypoints.json\n",
      "Processed features for user19_rotate_normalized_keypoints.json\n",
      "Processed features for user1_brightness_normalized_keypoints.json\n",
      "Processed features for user1_mirrored_normalized_keypoints.json\n",
      "Processed features for user1_noise_normalized_keypoints.json\n",
      "Processed features for user1_original_normalized_keypoints.json\n",
      "Processed features for user1_rotate_normalized_keypoints.json\n",
      "Processed features for user20_brightness_normalized_keypoints.json\n",
      "Processed features for user20_mirrored_normalized_keypoints.json\n",
      "Processed features for user20_noise_normalized_keypoints.json\n",
      "Processed features for user20_original_normalized_keypoints.json\n",
      "Processed features for user20_rotate_normalized_keypoints.json\n",
      "Processed features for user21_brightness_normalized_keypoints.json\n",
      "Processed features for user21_mirrored_normalized_keypoints.json\n",
      "Processed features for user21_noise_normalized_keypoints.json\n",
      "Processed features for user21_original_normalized_keypoints.json\n",
      "Processed features for user21_rotate_normalized_keypoints.json\n",
      "Processed features for user22_brightness_normalized_keypoints.json\n",
      "Processed features for user22_mirrored_normalized_keypoints.json\n",
      "Processed features for user22_noise_normalized_keypoints.json\n",
      "Processed features for user22_original_normalized_keypoints.json\n",
      "Processed features for user22_rotate_normalized_keypoints.json\n",
      "Processed features for user2_brightness_normalized_keypoints.json\n",
      "Processed features for user2_mirrored_normalized_keypoints.json\n",
      "Processed features for user2_noise_normalized_keypoints.json\n",
      "Processed features for user2_original_normalized_keypoints.json\n",
      "Processed features for user2_rotate_normalized_keypoints.json\n",
      "Processed features for user3_brightness_normalized_keypoints.json\n",
      "Processed features for user3_mirrored_normalized_keypoints.json\n",
      "Processed features for user3_noise_normalized_keypoints.json\n",
      "Processed features for user3_original_normalized_keypoints.json\n",
      "Processed features for user3_rotate_normalized_keypoints.json\n",
      "Processed features for user4_brightness_normalized_keypoints.json\n",
      "Processed features for user4_mirrored_normalized_keypoints.json\n",
      "Processed features for user4_noise_normalized_keypoints.json\n",
      "Processed features for user4_original_normalized_keypoints.json\n",
      "Processed features for user4_rotate_normalized_keypoints.json\n",
      "Processed features for user5_brightness_normalized_keypoints.json\n",
      "Processed features for user5_mirrored_normalized_keypoints.json\n",
      "Processed features for user5_noise_normalized_keypoints.json\n",
      "Processed features for user5_original_normalized_keypoints.json\n",
      "Processed features for user5_rotate_normalized_keypoints.json\n",
      "Processed features for user6_brightness_normalized_keypoints.json\n",
      "Processed features for user6_mirrored_normalized_keypoints.json\n",
      "Processed features for user6_noise_normalized_keypoints.json\n",
      "Processed features for user6_original_normalized_keypoints.json\n",
      "Processed features for user6_rotate_normalized_keypoints.json\n",
      "Processed features for user7_brightness_normalized_keypoints.json\n",
      "Processed features for user7_mirrored_normalized_keypoints.json\n",
      "Processed features for user7_noise_normalized_keypoints.json\n",
      "Processed features for user7_original_normalized_keypoints.json\n",
      "Processed features for user7_rotate_normalized_keypoints.json\n",
      "Processed features for user8_brightness_normalized_keypoints.json\n",
      "Processed features for user8_mirrored_normalized_keypoints.json\n",
      "Processed features for user8_noise_normalized_keypoints.json\n",
      "Processed features for user8_original_normalized_keypoints.json\n",
      "Processed features for user8_rotate_normalized_keypoints.json\n",
      "Processed features for user9_brightness_normalized_keypoints.json\n",
      "Processed features for user9_mirrored_normalized_keypoints.json\n",
      "Processed features for user9_noise_normalized_keypoints.json\n",
      "Processed features for user9_original_normalized_keypoints.json\n",
      "Processed features for user9_rotate_normalized_keypoints.json\n",
      "Feature extraction with normalization completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "keypoints_dir = \"stage3-keypoints\"  # Directory with keypoints JSON files\n",
    "features_dir = \"stage3-features\"  # Directory to save extracted features\n",
    "os.makedirs(features_dir, exist_ok=True)\n",
    "\n",
    "def compute_reference_length(keypoints):\n",
    "    \"\"\"\n",
    "    Compute the reference length (e.g., distance between shoulders) for normalization.\n",
    "    \"\"\"\n",
    "    left_shoulder = keypoints[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "    right_shoulder = keypoints[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
    "    reference_length = np.sqrt(\n",
    "        (left_shoulder[\"x\"] - right_shoulder[\"x\"]) ** 2 +\n",
    "        (left_shoulder[\"y\"] - right_shoulder[\"y\"]) ** 2\n",
    "    )\n",
    "    return reference_length if reference_length > 0 else 1  # Avoid division by zero\n",
    "\n",
    "def normalize_keypoints(keypoints, reference_length):\n",
    "    \"\"\"\n",
    "    Normalize keypoints using a reference length.\n",
    "    \"\"\"\n",
    "    normalized_keypoints = [\n",
    "        {\n",
    "            \"x\": kp[\"x\"] / reference_length,\n",
    "            \"y\": kp[\"y\"] / reference_length,\n",
    "            \"z\": kp[\"z\"] / reference_length,\n",
    "            \"visibility\": kp[\"visibility\"],  # Visibility is not normalized\n",
    "        }\n",
    "        for kp in keypoints\n",
    "    ]\n",
    "    return normalized_keypoints\n",
    "\n",
    "def compute_features(keypoints_sequence):\n",
    "    \"\"\"\n",
    "    Compute velocity and acceleration features from normalized keypoints.\n",
    "\n",
    "    Args:\n",
    "        keypoints_sequence (list): List of keypoints for consecutive frames.\n",
    "\n",
    "    Returns:\n",
    "        features: Array of features for each frame (velocity, acceleration, etc.).\n",
    "    \"\"\"\n",
    "    normalized_sequences = []\n",
    "    velocities = []\n",
    "    accelerations = []\n",
    "\n",
    "    # Normalize keypoints for each frame\n",
    "    for frame_data in keypoints_sequence:\n",
    "        keypoints = frame_data[\"keypoints\"]\n",
    "        reference_length = compute_reference_length(keypoints)\n",
    "        normalized_keypoints = normalize_keypoints(keypoints, reference_length)\n",
    "        normalized_sequences.append(normalized_keypoints)\n",
    "\n",
    "    # Compute velocity and acceleration\n",
    "    for i in range(1, len(normalized_sequences)):\n",
    "        prev_frame = np.array([[kp[\"x\"], kp[\"y\"]] for kp in normalized_sequences[i - 1]])\n",
    "        curr_frame = np.array([[kp[\"x\"], kp[\"y\"]] for kp in normalized_sequences[i]])\n",
    "\n",
    "        # Compute velocity (change in position)\n",
    "        velocity = curr_frame - prev_frame\n",
    "        velocities.append(velocity)\n",
    "\n",
    "        if i > 1:\n",
    "            # Compute acceleration (change in velocity)\n",
    "            prev_velocity = np.array(velocities[-2])\n",
    "            acceleration = velocity - prev_velocity\n",
    "            accelerations.append(acceleration)\n",
    "\n",
    "    # Pad initial frames with zeros (no velocity/acceleration for the first frame)\n",
    "    velocities = [np.zeros_like(velocities[0])] + velocities\n",
    "    accelerations = [np.zeros_like(accelerations[0])] * 2 + accelerations\n",
    "\n",
    "    return np.array(velocities), np.array(accelerations)\n",
    "\n",
    "def process_keypoints_file(file_path, output_path):\n",
    "    \"\"\"\n",
    "    Process a single keypoints JSON file to compute features.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file with keypoints.\n",
    "        output_path (str): Path to save the computed features.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        keypoints_sequence = json.load(f)\n",
    "\n",
    "    velocities, accelerations = compute_features(keypoints_sequence)\n",
    "\n",
    "    # Combine features\n",
    "    features = {\n",
    "        \"velocities\": velocities.tolist(),\n",
    "        \"accelerations\": accelerations.tolist()\n",
    "    }\n",
    "\n",
    "    # Save features as JSON\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(features, f, indent=4)\n",
    "\n",
    "# Process all keypoints JSON files\n",
    "for keypoints_file in os.listdir(keypoints_dir):\n",
    "    if keypoints_file.endswith(\".json\"):\n",
    "        input_path = os.path.join(keypoints_dir, keypoints_file)\n",
    "        output_path = os.path.join(features_dir, keypoints_file)\n",
    "        process_keypoints_file(input_path, output_path)\n",
    "        print(f\"Processed features for {keypoints_file}\")\n",
    "\n",
    "print(\"Feature extraction with normalization completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Paths\n",
    "keypoints_dir = \"stage3-keypoints\"  # Directory with keypoints JSON files\n",
    "features_dir = \"stage3-features\"  # Directory with features JSON files\n",
    "output_keypoints_dir = \"padded-keypoints\"  # Directory to save padded keypoints\n",
    "output_features_dir = \"padded-features\"  # Directory to save padded features\n",
    "os.makedirs(output_keypoints_dir, exist_ok=True)\n",
    "os.makedirs(output_features_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def pad_keyframes(keypoints_sequence, max_length, num_keypoints):\n",
    "    \"\"\"\n",
    "    Pad keyframes to ensure consistent sequence length.\n",
    "    \"\"\"\n",
    "    padding_frame = [{\"x\": 0.0, \"y\": 0.0, \"z\": 0.0, \"visibility\": 0.0}] * num_keypoints\n",
    "    while len(keypoints_sequence) < max_length:\n",
    "        keypoints_sequence.append({\"frame\": len(keypoints_sequence), \"keypoints\": padding_frame})\n",
    "    return keypoints_sequence\n",
    "\n",
    "\n",
    "def pad_features(features, max_length, num_keypoints):\n",
    "    \"\"\"\n",
    "    Pad velocities and accelerations to ensure consistent sequence length.\n",
    "    \"\"\"\n",
    "    zero_velocity = [[0.0, 0.0]] * num_keypoints\n",
    "    zero_acceleration = [[0.0, 0.0]] * num_keypoints\n",
    "\n",
    "    while len(features[\"velocities\"]) < max_length:\n",
    "        features[\"velocities\"].append(zero_velocity)\n",
    "    while len(features[\"accelerations\"]) < max_length:\n",
    "        features[\"accelerations\"].append(zero_acceleration)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_max_length(keypoints_dir):\n",
    "    \"\"\"\n",
    "    Determine the maximum sequence length across all keypoints files.\n",
    "    \"\"\"\n",
    "    max_length = 0\n",
    "    for file in os.listdir(keypoints_dir):\n",
    "        if file.endswith(\".json\"):\n",
    "            with open(os.path.join(keypoints_dir, file), \"r\") as f:\n",
    "                keypoints_sequence = json.load(f)\n",
    "                max_length = max(max_length, len(keypoints_sequence))\n",
    "    return max_length\n",
    "\n",
    "\n",
    "# Compute the maximum sequence length\n",
    "max_length = get_max_length(keypoints_dir)\n",
    "\n",
    "# Process all keypoints and features files\n",
    "for file in os.listdir(keypoints_dir):\n",
    "    if file.endswith(\".json\"):\n",
    "        keypoints_path = os.path.join(keypoints_dir, file)\n",
    "        features_path = os.path.join(features_dir, file)\n",
    "\n",
    "        with open(keypoints_path, \"r\") as kf, open(features_path, \"r\") as ff:\n",
    "            keypoints_sequence = json.load(kf)\n",
    "            features = json.load(ff)\n",
    "\n",
    "            # Get the number of keypoints from the first frame\n",
    "            num_keypoints = len(keypoints_sequence[0][\"keypoints\"]) if keypoints_sequence else 0\n",
    "\n",
    "            # Pad both keypoints and features\n",
    "            padded_keypoints = pad_keyframes(keypoints_sequence, max_length, num_keypoints)\n",
    "            padded_features = pad_features(features, max_length, num_keypoints)\n",
    "\n",
    "        # Save padded results\n",
    "        padded_keypoints_path = os.path.join(output_keypoints_dir, file)\n",
    "        padded_features_path = os.path.join(output_features_dir, file)\n",
    "        with open(padded_keypoints_path, \"w\") as kf, open(padded_features_path, \"w\") as ff:\n",
    "            json.dump(padded_keypoints, kf, indent=4)\n",
    "            json.dump(padded_features, ff, indent=4)\n",
    "\n",
    "print(\"Padding completed for both keypoints and features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded X shape: (110, 61, 33, 4)\n",
      "Train set: (77, 61, 33, 4), Validation set: (33, 61, 33, 4)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths\n",
    "padded_features_dir = \"padded-features\"\n",
    "labels_file = \"stage3-dataset.csv\"\n",
    "\n",
    "# Load labels\n",
    "labels_df = pd.read_csv(labels_file)\n",
    "label_mapping = dict(zip(labels_df['user'], labels_df['label']))\n",
    "\n",
    "# Load and prepare dataset\n",
    "def load_dataset(features_dir, label_mapping):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "\n",
    "    for file in os.listdir(features_dir):\n",
    "        if file.endswith(\".json\"):\n",
    "            user_id = os.path.splitext(file)[0]\n",
    "            \n",
    "            # Skip if the user_id doesn't have a label\n",
    "            if user_id not in label_mapping:\n",
    "                print(f\"No label for {user_id}. Skipping...\")\n",
    "                continue\n",
    "            \n",
    "            label = label_mapping[user_id]\n",
    "            file_path = os.path.join(features_dir, file)\n",
    "            \n",
    "            # Load features\n",
    "            with open(file_path, \"r\") as f:\n",
    "                features = json.load(f)\n",
    "            \n",
    "            # Combine velocities and accelerations into a single array\n",
    "            velocities = np.array(features[\"velocities\"])\n",
    "            accelerations = np.array(features[\"accelerations\"])\n",
    "            combined_features = np.concatenate([velocities, accelerations], axis=-1)\n",
    "\n",
    "            # Append to dataset\n",
    "            sequences.append(combined_features)\n",
    "            labels.append(label)\n",
    "\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "# Load the dataset\n",
    "X, y = load_dataset(padded_features_dir, label_mapping)\n",
    "\n",
    "# Determine the maximum sequence length\n",
    "sequence_length = max(seq.shape[0] for seq in X)\n",
    "\n",
    "# Pad sequences to ensure consistent length\n",
    "padded_X = []\n",
    "for i, seq in enumerate(X):\n",
    "    try:\n",
    "        # Get the number of features (considering the third dimension)\n",
    "        num_features = seq.shape[1]\n",
    "        extra_dimension = seq.shape[2]\n",
    "\n",
    "        # Pad the sequence\n",
    "        padded_seq = np.pad(\n",
    "            seq,\n",
    "            ((0, sequence_length - seq.shape[0]), (0, 0), (0, 0)),  # Pad along the first axis only\n",
    "            mode='constant',\n",
    "            constant_values=0\n",
    "        )\n",
    "        padded_X.append(padded_seq)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at sequence {i} with shape {seq.shape}: {e}\")\n",
    "        continue  # Skip problematic sequences\n",
    "\n",
    "# Convert to numpy array\n",
    "X = np.array(padded_X)\n",
    "\n",
    "# Validate dimensions after padding\n",
    "print(f\"Padded X shape: {X.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Train set: {X_train.shape}, Validation set: {X_val.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Train set: (77, 61, 132), Validation set: (33, 61, 132)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the data\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], -1)  # (batch_size, sequence_length, feature_dim)\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], -1)          # (batch_size, sequence_length, feature_dim)\n",
    "\n",
    "print(f\"Reshaped Train set: {X_train.shape}, Validation set: {X_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.7857142857142857, 1: 1.375}\n",
      "Epoch 1/200\n",
      "5/5 [==============================] - 2s 146ms/step - loss: 0.7715 - mae: 0.4961 - val_loss: 0.6644 - val_mae: 0.4744\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6715 - mae: 0.4695 - val_loss: 0.6573 - val_mae: 0.4757\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6053 - mae: 0.4212 - val_loss: 0.6886 - val_mae: 0.4889\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.5668 - mae: 0.4042 - val_loss: 0.7025 - val_mae: 0.4889\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.5385 - mae: 0.4000 - val_loss: 0.7118 - val_mae: 0.4875\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.5356 - mae: 0.3888 - val_loss: 0.6710 - val_mae: 0.4597\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.5353 - mae: 0.3640 - val_loss: 0.6187 - val_mae: 0.4310\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.4943 - mae: 0.3570 - val_loss: 0.6176 - val_mae: 0.4342\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3989 - mae: 0.3085 - val_loss: 0.5465 - val_mae: 0.3952\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.3598 - mae: 0.2692 - val_loss: 0.5872 - val_mae: 0.3817\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3517 - mae: 0.2545 - val_loss: 0.5293 - val_mae: 0.3763\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.3257 - mae: 0.2461 - val_loss: 0.5098 - val_mae: 0.3546\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2755 - mae: 0.2080 - val_loss: 0.5651 - val_mae: 0.3734\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2598 - mae: 0.2008 - val_loss: 0.4514 - val_mae: 0.3132\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.1956 - mae: 0.1514 - val_loss: 0.4738 - val_mae: 0.3051\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.1175 - mae: 0.0983 - val_loss: 0.4458 - val_mae: 0.2939\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1489 - mae: 0.1180 - val_loss: 0.4844 - val_mae: 0.2766\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.1614 - mae: 0.1209 - val_loss: 0.3954 - val_mae: 0.2543\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.1832 - mae: 0.1128 - val_loss: 0.6302 - val_mae: 0.2589\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.1117 - mae: 0.0830 - val_loss: 0.4553 - val_mae: 0.2762\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.1520 - mae: 0.1059 - val_loss: 0.4339 - val_mae: 0.2333\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.0896 - mae: 0.0712 - val_loss: 0.5127 - val_mae: 0.2530\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0616 - mae: 0.0461 - val_loss: 0.3933 - val_mae: 0.2253\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0506 - mae: 0.0504 - val_loss: 0.3752 - val_mae: 0.2107\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0259 - mae: 0.0260 - val_loss: 0.4526 - val_mae: 0.1926\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.0242 - mae: 0.0208 - val_loss: 0.4518 - val_mae: 0.1755\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0153 - mae: 0.0148 - val_loss: 0.3783 - val_mae: 0.1628\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0114 - mae: 0.0122 - val_loss: 0.3918 - val_mae: 0.1562\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0111 - mae: 0.0099 - val_loss: 0.5143 - val_mae: 0.1704\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0063 - mae: 0.0060 - val_loss: 0.5005 - val_mae: 0.1630\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0080 - mae: 0.0080 - val_loss: 0.4571 - val_mae: 0.1508\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0055 - mae: 0.0051 - val_loss: 0.4170 - val_mae: 0.1417\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.0065 - mae: 0.0066 - val_loss: 0.4302 - val_mae: 0.1411\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.0038 - mae: 0.0037 - val_loss: 0.4410 - val_mae: 0.1410\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.0033 - mae: 0.0034 - val_loss: 0.4417 - val_mae: 0.1404\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0026 - mae: 0.0027 - val_loss: 0.4504 - val_mae: 0.1411\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0063 - mae: 0.0058 - val_loss: 0.4979 - val_mae: 0.1504\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0035 - mae: 0.0033 - val_loss: 0.4653 - val_mae: 0.1447\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.0024 - mae: 0.0023 - val_loss: 0.4276 - val_mae: 0.1373\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.0017 - mae: 0.0016 - val_loss: 0.4091 - val_mae: 0.1335\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.0027 - mae: 0.0023 - val_loss: 0.3843 - val_mae: 0.1303\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.0025 - mae: 0.0025 - val_loss: 0.3829 - val_mae: 0.1314\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0035 - mae: 0.0037 - val_loss: 0.4134 - val_mae: 0.1352\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0019 - mae: 0.0018 - val_loss: 0.4508 - val_mae: 0.1424\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.0016 - mae: 0.0016 - val_loss: 0.4589 - val_mae: 0.1440\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0026 - mae: 0.0028 - val_loss: 0.4852 - val_mae: 0.1483\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0013 - mae: 0.0012 - val_loss: 0.5032 - val_mae: 0.1501\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0019 - mae: 0.0016 - val_loss: 0.4853 - val_mae: 0.1459\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 0.0010 - mae: 0.0010 - val_loss: 0.4760 - val_mae: 0.1431\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.0016 - mae: 0.0015 - val_loss: 0.4748 - val_mae: 0.1420\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0030 - mae: 0.0033 - val_loss: 0.4981 - val_mae: 0.1460\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0015 - mae: 0.0013 - val_loss: 0.5210 - val_mae: 0.1512\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.0013 - mae: 0.0012 - val_loss: 0.5178 - val_mae: 0.1513\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 9.2778e-04 - mae: 8.6480e-04 - val_loss: 0.4748 - val_mae: 0.1442\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0013 - mae: 0.0012 - val_loss: 0.4476 - val_mae: 0.1389\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0012 - mae: 0.0012 - val_loss: 0.4506 - val_mae: 0.1389\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.0012 - mae: 0.0011 - val_loss: 0.4543 - val_mae: 0.1391\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 9.5812e-04 - mae: 9.0570e-04 - val_loss: 0.4350 - val_mae: 0.1343\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.0011 - mae: 0.0012 - val_loss: 0.4354 - val_mae: 0.1344\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 7.3058e-04 - mae: 7.9441e-04 - val_loss: 0.4450 - val_mae: 0.1358\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 7.8038e-04 - mae: 8.2313e-04 - val_loss: 0.4618 - val_mae: 0.1382\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 9.4899e-04 - mae: 9.8650e-04 - val_loss: 0.4868 - val_mae: 0.1439\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.0032 - mae: 0.0036 - val_loss: 0.6519 - val_mae: 0.1641\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0014 - mae: 0.0012 - val_loss: 0.7070 - val_mae: 0.1662\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 9.0552e-04 - mae: 7.4935e-04 - val_loss: 0.6144 - val_mae: 0.1510\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 5.4840e-04 - mae: 5.1442e-04 - val_loss: 0.5657 - val_mae: 0.1380\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.4506e-04 - mae: 6.3447e-04 - val_loss: 0.5387 - val_mae: 0.1313\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.0011 - mae: 0.0012 - val_loss: 0.5320 - val_mae: 0.1288\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 6.7470e-04 - mae: 5.6408e-04 - val_loss: 0.5402 - val_mae: 0.1298\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.0013 - mae: 0.0012 - val_loss: 0.5539 - val_mae: 0.1336\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 9.9661e-04 - mae: 7.9965e-04 - val_loss: 0.5555 - val_mae: 0.1348\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.0013 - mae: 0.0013 - val_loss: 0.5298 - val_mae: 0.1299\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 8.2454e-04 - mae: 9.5435e-04 - val_loss: 0.5224 - val_mae: 0.1297\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 5.5073e-04 - mae: 5.1171e-04 - val_loss: 0.5242 - val_mae: 0.1308\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 6.2591e-04 - mae: 6.0242e-04 - val_loss: 0.5218 - val_mae: 0.1309\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6.7891e-04 - mae: 6.4961e-04 - val_loss: 0.5224 - val_mae: 0.1314\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 4.4030e-04 - mae: 4.6645e-04 - val_loss: 0.5311 - val_mae: 0.1337\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 8.7286e-04 - mae: 9.1282e-04 - val_loss: 0.5523 - val_mae: 0.1374\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 3.0221e-04 - mae: 3.0727e-04 - val_loss: 0.5683 - val_mae: 0.1400\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 5.9580e-04 - mae: 5.7106e-04 - val_loss: 0.5778 - val_mae: 0.1415\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 4.3662e-04 - mae: 3.9512e-04 - val_loss: 0.5680 - val_mae: 0.1391\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 5.3785e-04 - mae: 4.4914e-04 - val_loss: 0.5409 - val_mae: 0.1333\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 6.8461e-04 - mae: 6.1511e-04 - val_loss: 0.5183 - val_mae: 0.1292\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 4.1131e-04 - mae: 4.4561e-04 - val_loss: 0.5102 - val_mae: 0.1288\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 6.1007e-04 - mae: 6.1278e-04 - val_loss: 0.5087 - val_mae: 0.1288\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 7.8641e-04 - mae: 9.0020e-04 - val_loss: 0.5186 - val_mae: 0.1313\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 3.9911e-04 - mae: 3.9253e-04 - val_loss: 0.5512 - val_mae: 0.1394\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 6.0812e-04 - mae: 5.2253e-04 - val_loss: 0.5653 - val_mae: 0.1432\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 4.5889e-04 - mae: 3.9369e-04 - val_loss: 0.5571 - val_mae: 0.1411\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 3.7751e-04 - mae: 3.7322e-04 - val_loss: 0.5446 - val_mae: 0.1386\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 3.6836e-04 - mae: 3.5371e-04 - val_loss: 0.5371 - val_mae: 0.1375\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 6.7016e-04 - mae: 5.8216e-04 - val_loss: 0.5240 - val_mae: 0.1350\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 2.0721e-04 - mae: 2.0899e-04 - val_loss: 0.5168 - val_mae: 0.1330\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 3.4155e-04 - mae: 3.3476e-04 - val_loss: 0.5133 - val_mae: 0.1319\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 7.9120e-04 - mae: 9.1185e-04 - val_loss: 0.5637 - val_mae: 0.1459\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 5.6162e-04 - mae: 4.4029e-04 - val_loss: 0.6608 - val_mae: 0.1594\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 4.2255e-04 - mae: 3.9551e-04 - val_loss: 0.6307 - val_mae: 0.1560\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 6.5425e-04 - mae: 7.1767e-04 - val_loss: 0.5792 - val_mae: 0.1495\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 2.1639e-04 - mae: 2.2202e-04 - val_loss: 0.5513 - val_mae: 0.1444\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 4.8286e-04 - mae: 5.3451e-04 - val_loss: 0.5387 - val_mae: 0.1413\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 4.1945e-04 - mae: 3.8467e-04 - val_loss: 0.5399 - val_mae: 0.1411\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.9505e-04 - mae: 1.8475e-04 - val_loss: 0.5358 - val_mae: 0.1405\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.8703e-04 - mae: 1.8715e-04 - val_loss: 0.5325 - val_mae: 0.1396\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 2.8761e-04 - mae: 3.0997e-04 - val_loss: 0.5477 - val_mae: 0.1422\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 2.2868e-04 - mae: 2.2528e-04 - val_loss: 0.5581 - val_mae: 0.1438\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 3.8327e-04 - mae: 3.8270e-04 - val_loss: 0.5690 - val_mae: 0.1452\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.6172e-04 - mae: 1.4917e-04 - val_loss: 0.5694 - val_mae: 0.1447\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 2.0709e-04 - mae: 2.0223e-04 - val_loss: 0.5607 - val_mae: 0.1425\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 2.0003e-04 - mae: 1.7697e-04 - val_loss: 0.5422 - val_mae: 0.1378\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 2.7623e-04 - mae: 3.1182e-04 - val_loss: 0.5354 - val_mae: 0.1360\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 3.8806e-04 - mae: 3.4755e-04 - val_loss: 0.5345 - val_mae: 0.1355\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 2.1026e-04 - mae: 2.3545e-04 - val_loss: 0.5362 - val_mae: 0.1356\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.0090e-04 - mae: 9.0491e-05 - val_loss: 0.5383 - val_mae: 0.1357\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 1.6358e-04 - mae: 1.7761e-04 - val_loss: 0.5418 - val_mae: 0.1360\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 2.7850e-04 - mae: 2.9053e-04 - val_loss: 0.5495 - val_mae: 0.1367\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 3.4816e-04 - mae: 3.6136e-04 - val_loss: 0.5600 - val_mae: 0.1372\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 2.7154e-04 - mae: 2.6756e-04 - val_loss: 0.5614 - val_mae: 0.1370\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.4479e-04 - mae: 1.3163e-04 - val_loss: 0.5573 - val_mae: 0.1364\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 3.2940e-04 - mae: 3.2655e-04 - val_loss: 0.5599 - val_mae: 0.1366\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 2.1717e-04 - mae: 1.9810e-04 - val_loss: 0.5599 - val_mae: 0.1365\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 2.4351e-04 - mae: 2.4878e-04 - val_loss: 0.5632 - val_mae: 0.1362\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 2.1556e-04 - mae: 2.3578e-04 - val_loss: 0.5690 - val_mae: 0.1369\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.6883e-04 - mae: 1.8450e-04 - val_loss: 0.5798 - val_mae: 0.1387\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.9267e-04 - mae: 1.9196e-04 - val_loss: 0.5833 - val_mae: 0.1395\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 1.5336e-04 - mae: 1.4803e-04 - val_loss: 0.5898 - val_mae: 0.1406\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.0325e-04 - mae: 9.7382e-05 - val_loss: 0.5861 - val_mae: 0.1400\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 2.7454e-04 - mae: 2.2075e-04 - val_loss: 0.5789 - val_mae: 0.1391\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.4787e-04 - mae: 1.5697e-04 - val_loss: 0.5599 - val_mae: 0.1363\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.5767e-04 - mae: 1.5784e-04 - val_loss: 0.5524 - val_mae: 0.1351\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 2.4793e-04 - mae: 2.6910e-04 - val_loss: 0.5539 - val_mae: 0.1353\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 8.0967e-05 - mae: 7.4786e-05 - val_loss: 0.5594 - val_mae: 0.1363\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 3.7809e-04 - mae: 4.2661e-04 - val_loss: 0.5659 - val_mae: 0.1375\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 1.7682e-04 - mae: 1.6695e-04 - val_loss: 0.5704 - val_mae: 0.1383\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.8062e-04 - mae: 1.6076e-04 - val_loss: 0.5688 - val_mae: 0.1380\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1.2350e-04 - mae: 1.2603e-04 - val_loss: 0.5625 - val_mae: 0.1368\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.5840e-04 - mae: 1.4682e-04 - val_loss: 0.5616 - val_mae: 0.1366\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 8.8599e-05 - mae: 8.5704e-05 - val_loss: 0.5615 - val_mae: 0.1365\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 2.2829e-04 - mae: 1.8762e-04 - val_loss: 0.5565 - val_mae: 0.1356\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 7.5164e-05 - mae: 7.5914e-05 - val_loss: 0.5512 - val_mae: 0.1345\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 8.8743e-05 - mae: 8.6865e-05 - val_loss: 0.5492 - val_mae: 0.1341\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.3993e-04 - mae: 1.5426e-04 - val_loss: 0.5476 - val_mae: 0.1339\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 1.4128e-04 - mae: 1.2229e-04 - val_loss: 0.5475 - val_mae: 0.1339\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 1.2174e-04 - mae: 1.1478e-04 - val_loss: 0.5452 - val_mae: 0.1336\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 8.4946e-05 - mae: 9.3574e-05 - val_loss: 0.5460 - val_mae: 0.1338\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 9.9899e-05 - mae: 9.1018e-05 - val_loss: 0.5434 - val_mae: 0.1335\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 4.1418e-04 - mae: 4.8035e-04 - val_loss: 0.5767 - val_mae: 0.1402\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 4.1527e-04 - mae: 3.2814e-04 - val_loss: 0.5761 - val_mae: 0.1400\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 5.6782e-04 - mae: 6.3765e-04 - val_loss: 0.5563 - val_mae: 0.1358\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1.1809e-04 - mae: 1.1687e-04 - val_loss: 0.5476 - val_mae: 0.1343\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 7.7878e-05 - mae: 8.5047e-05 - val_loss: 0.5465 - val_mae: 0.1344\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 5.7779e-05 - mae: 6.2448e-05 - val_loss: 0.5487 - val_mae: 0.1349\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 1.0371e-04 - mae: 1.1194e-04 - val_loss: 0.5521 - val_mae: 0.1355\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.0126e-04 - mae: 1.0717e-04 - val_loss: 0.5623 - val_mae: 0.1373\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.2028e-04 - mae: 1.1223e-04 - val_loss: 0.5768 - val_mae: 0.1400\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.7529e-04 - mae: 1.5157e-04 - val_loss: 0.5744 - val_mae: 0.1399\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.0494e-04 - mae: 9.4014e-05 - val_loss: 0.5659 - val_mae: 0.1385\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 1.6634e-04 - mae: 1.8112e-04 - val_loss: 0.5635 - val_mae: 0.1380\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 2.6632e-04 - mae: 2.8804e-04 - val_loss: 0.5667 - val_mae: 0.1389\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 2.1486e-04 - mae: 2.6388e-04 - val_loss: 0.5761 - val_mae: 0.1400\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.1160e-04 - mae: 1.2491e-04 - val_loss: 0.5975 - val_mae: 0.1419\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 2.7225e-04 - mae: 2.6840e-04 - val_loss: 0.6172 - val_mae: 0.1427\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 1.2144e-04 - mae: 1.1183e-04 - val_loss: 0.6382 - val_mae: 0.1439\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.4907e-04 - mae: 1.6103e-04 - val_loss: 0.6512 - val_mae: 0.1443\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 4.5833e-05 - mae: 4.5310e-05 - val_loss: 0.6618 - val_mae: 0.1446\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 7.8364e-05 - mae: 8.6528e-05 - val_loss: 0.6711 - val_mae: 0.1450\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 4.9243e-05 - mae: 4.0482e-05 - val_loss: 0.6819 - val_mae: 0.1460\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 7.4780e-05 - mae: 6.7331e-05 - val_loss: 0.6836 - val_mae: 0.1460\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 2.6204e-04 - mae: 2.0042e-04 - val_loss: 0.6562 - val_mae: 0.1430\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.1444e-05 - mae: 7.2885e-05 - val_loss: 0.6431 - val_mae: 0.1418\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.0170e-04 - mae: 9.4438e-05 - val_loss: 0.6353 - val_mae: 0.1415\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 6.6105e-05 - mae: 6.1583e-05 - val_loss: 0.6311 - val_mae: 0.1415\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 9.7155e-05 - mae: 9.7907e-05 - val_loss: 0.6276 - val_mae: 0.1414\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 1.1854e-04 - mae: 1.1874e-04 - val_loss: 0.6346 - val_mae: 0.1416\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 5.9531e-05 - mae: 6.0840e-05 - val_loss: 0.6425 - val_mae: 0.1423\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1.8249e-04 - mae: 2.0950e-04 - val_loss: 0.6662 - val_mae: 0.1434\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 6.0019e-05 - mae: 5.9765e-05 - val_loss: 0.6786 - val_mae: 0.1439\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 7.6608e-05 - mae: 8.0028e-05 - val_loss: 0.6854 - val_mae: 0.1441\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 6.8797e-05 - mae: 7.4342e-05 - val_loss: 0.6907 - val_mae: 0.1443\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 7.5376e-05 - mae: 7.7004e-05 - val_loss: 0.6919 - val_mae: 0.1443\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 5.4592e-05 - mae: 5.2144e-05 - val_loss: 0.6881 - val_mae: 0.1441\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 8.8688e-05 - mae: 8.7558e-05 - val_loss: 0.6875 - val_mae: 0.1442\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 9.1381e-05 - mae: 8.1982e-05 - val_loss: 0.6819 - val_mae: 0.1439\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 8.0406e-05 - mae: 8.3581e-05 - val_loss: 0.6721 - val_mae: 0.1434\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.0933e-04 - mae: 1.0149e-04 - val_loss: 0.6689 - val_mae: 0.1432\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 9.8011e-05 - mae: 9.8701e-05 - val_loss: 0.6663 - val_mae: 0.1430\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 1.1724e-04 - mae: 1.3207e-04 - val_loss: 0.6660 - val_mae: 0.1428\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 8.4110e-05 - mae: 9.0492e-05 - val_loss: 0.6638 - val_mae: 0.1426\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 5.4381e-05 - mae: 5.3249e-05 - val_loss: 0.6634 - val_mae: 0.1425\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 7.1837e-05 - mae: 6.6505e-05 - val_loss: 0.6587 - val_mae: 0.1422\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 1.3307e-04 - mae: 1.5201e-04 - val_loss: 0.6606 - val_mae: 0.1426\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 1.0045e-04 - mae: 8.2802e-05 - val_loss: 0.6575 - val_mae: 0.1424\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 1.0076e-04 - mae: 8.7538e-05 - val_loss: 0.6454 - val_mae: 0.1409\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 1.0614e-04 - mae: 1.2467e-04 - val_loss: 0.6355 - val_mae: 0.1394\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 8.3775e-05 - mae: 7.3422e-05 - val_loss: 0.6240 - val_mae: 0.1378\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 7.8167e-05 - mae: 7.2646e-05 - val_loss: 0.6177 - val_mae: 0.1366\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 1.3686e-04 - mae: 1.3755e-04 - val_loss: 0.6115 - val_mae: 0.1356\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 5.1668e-05 - mae: 4.7232e-05 - val_loss: 0.6097 - val_mae: 0.1352\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 1.5473e-04 - mae: 1.5678e-04 - val_loss: 0.6110 - val_mae: 0.1356\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 1.3042e-04 - mae: 1.3752e-04 - val_loss: 0.6298 - val_mae: 0.1389\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 1.3008e-04 - mae: 1.1403e-04 - val_loss: 0.6553 - val_mae: 0.1432\n",
      "Model training complete and saved as 'stage3-transformer.keras'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Calculate class weights to handle data imbalance\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(f\"Class weights: {class_weights_dict}\")\n",
    "\n",
    "# Transformer Model Definition\n",
    "def create_transformer_model(sequence_length, feature_dim):\n",
    "    inputs = layers.Input(shape=(sequence_length, feature_dim))\n",
    "    x = layers.LayerNormalization()(inputs)\n",
    "\n",
    "    # Transformer Encoder\n",
    "    attention_output = layers.MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
    "    x = layers.Add()([x, attention_output])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    \n",
    "    # Feed-forward layer\n",
    "    ff_output = layers.Dense(64, activation='relu')(x)\n",
    "    ff_output = layers.Dense(feature_dim)(ff_output)  # Match dimensions for residual connection\n",
    "    x = layers.Add()([x, ff_output])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "\n",
    "    # Global Average Pooling\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)  # Binary classification output\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Model Configuration\n",
    "sequence_length = X_train.shape[1]  # Sequence length (e.g., 61)\n",
    "feature_dim = X_train.shape[2]  # Number of features per frame (e.g., 33 * 4)\n",
    "model = create_transformer_model(sequence_length, feature_dim)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['mae'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,  # Adjust based on dataset size\n",
    "    batch_size=16,  # Adjust based on memory constraints\n",
    "    class_weight=class_weights_dict,  # Handle class imbalance\n",
    "   #  callbacks=[early_stopping],  # Early stopping to prevent overfitting\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"stage3-transformer.keras\")\n",
    "print(\"Model training complete and saved as 'stage3-transformer.keras'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 39ms/step\n",
      "Validation results saved to 'validation_results.csv'.\n",
      "   True Label  Predicted Value  Predicted Class\n",
      "0           0     1.277181e-08                0\n",
      "1           0     7.341225e-08                0\n",
      "2           1     8.401749e-01                1\n",
      "3           0     1.791547e-04                0\n",
      "4           0     1.131109e-05                0\n",
      "Accuracy: 0.88\n",
      "Confusion Matrix:\n",
      "[[20  1]\n",
      " [ 3  9]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Correct       0.87      0.95      0.91        21\n",
      "   Incorrect       0.90      0.75      0.82        12\n",
      "\n",
      "    accuracy                           0.88        33\n",
      "   macro avg       0.88      0.85      0.86        33\n",
      "weighted avg       0.88      0.88      0.88        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Define threshold\n",
    "threshold = 0.5  # Predictions above this are classified as 1 (incorrect), below as 0 (correct)\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"stage3-transformer.keras\")\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_val).flatten()  # Flatten predictions for simplicity\n",
    "\n",
    "# Apply threshold to classify\n",
    "y_classified = [1 if pred > threshold else 0 for pred in y_pred]\n",
    "\n",
    "# Convert results to a DataFrame for analysis\n",
    "results_df = pd.DataFrame({\n",
    "    'True Label': y_val,\n",
    "    'Predicted Value': y_pred,\n",
    "    'Predicted Class': y_classified\n",
    "})\n",
    "\n",
    "# Save results to a CSV file for analysis\n",
    "results_df.to_csv(\"validation_results.csv\", index=False)\n",
    "print(\"Validation results saved to 'validation_results.csv'.\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(results_df.head())\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = accuracy_score(y_val, y_classified)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val, y_classified)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification report for detailed metrics\n",
    "class_report = classification_report(y_val, y_classified, target_names=[\"Correct\", \"Incorrect\"])\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 17ms/step\n",
      "[0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a single threshold for classification\n",
    "# threshold = 0.005  # Adjust this value to experiment with different thresholds\n",
    "threshold = 0.5  # Predictions above this are classified as `correct` (0), below as `incorrect` (1)\n",
    "\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = model.predict(X_val).flatten()  # Flatten the predictions for simplicity\n",
    "\n",
    "# Apply threshold\n",
    "# y_classified = [0 if pred > threshold else 1 for pred in y_pred]  # 0 = correct, 1 = incorrect\n",
    "\n",
    "y_classified = []\n",
    "for pred in y_pred:\n",
    "    if pred > threshold:\n",
    "        y_classified.append(1)  # Correct\n",
    "    else:\n",
    "        y_classified.append(0)  # Incorrect\n",
    "print(y_classified)\n",
    "\n",
    "# Classify predictions based on the threshold\n",
    "# y_classified = [0 if pred > threshold else 1 for pred in y_pred]  # `0` = correct, `1` = incorrect\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    # Ensure label order matches the data\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])  # Numerical order: 0 = correct, 1 = incorrect\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap='Blues', xticks_rotation='vertical')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "# Ensure the order of labels matches the confusion matrix\n",
    "true_labels = [\"correct\", \"incorrect\"]  # Match this to 0 = correct, 1 = incorrect\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(y_val, y_classified, labels=true_labels)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(y_val, y_classified)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
