{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737665237.315508 11090681 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1737665237.376650 11090994 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737665237.388010 11090994 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737665237.402132 11091003 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knee lift and arm height analysis complete! JSON files saved in 'keypoints' folder.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to check if the knee is fully lifted and the arm is raised high\n",
    "def is_full_knee_lift_and_arm_high(knee, hip, shoulder, elbow, wrist):\n",
    "    \"\"\"\n",
    "    Determines if the knee is fully lifted and the arm is raised high by analyzing the\n",
    "    relative positions of the knee to the hip and wrist to the shoulder.\n",
    "    \"\"\"\n",
    "    knee_x, knee_y = knee\n",
    "    hip_x, hip_y = hip\n",
    "    shoulder_x, shoulder_y = shoulder\n",
    "    elbow_x, elbow_y = elbow\n",
    "    wrist_x, wrist_y = wrist\n",
    "\n",
    "    # Knee is considered lifted if it's higher than the hip\n",
    "    knee_lifted = knee_y < hip_y\n",
    "\n",
    "    # Arm is considered raised if the wrist is higher than the shoulder and elbow\n",
    "    arm_high = wrist_y < shoulder_y and wrist_y < elbow_y\n",
    "\n",
    "    return knee_lifted and arm_high\n",
    "\n",
    "# Paths for the stage 3 videos and keypoints storage\n",
    "stage_path = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage3/videos\"\n",
    "keypoints_folder = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage3/keypoints\"\n",
    "\n",
    "# Ensure keypoints folder exists\n",
    "os.makedirs(keypoints_folder, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(stage_path):\n",
    "    if file.endswith(\".mp4\"):\n",
    "        video_file_path = os.path.join(stage_path, file)\n",
    "        cap = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "        keypoints_data = []  # Store keypoints for this video\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Convert frame to RGB for MediaPipe processing\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result = pose.process(frame_rgb)\n",
    "\n",
    "            if result.pose_landmarks:\n",
    "                landmarks = result.pose_landmarks.landmark\n",
    "\n",
    "                # Extract relevant keypoints for knee lift and arm height analysis\n",
    "                left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y]\n",
    "                left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_HIP].y]\n",
    "                left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x,\n",
    "                                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y]\n",
    "                left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].y]\n",
    "                left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.LEFT_WRIST].y]\n",
    "\n",
    "                right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y]\n",
    "                right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y]\n",
    "                right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x,\n",
    "                                  landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y]\n",
    "                right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].y]\n",
    "                right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_WRIST].y]\n",
    "\n",
    "                # Check if knee is lifted and arm is high for both sides\n",
    "                left_takeoff = is_full_knee_lift_and_arm_high(left_knee, left_hip, left_shoulder, left_elbow, left_wrist)\n",
    "                right_takeoff = is_full_knee_lift_and_arm_high(right_knee, right_hip, right_shoulder, right_elbow, right_wrist)\n",
    "\n",
    "                # Store data for this frame\n",
    "                keypoints_data.append({\n",
    "                    \"frame\": int(cap.get(cv2.CAP_PROP_POS_FRAMES)),\n",
    "                    \"left_takeoff\": left_takeoff,\n",
    "                    \"right_takeoff\": right_takeoff,\n",
    "                    \"left_knee\": left_knee,\n",
    "                    \"left_hip\": left_hip,\n",
    "                    \"left_shoulder\": left_shoulder,\n",
    "                    \"left_elbow\": left_elbow,\n",
    "                    \"left_wrist\": left_wrist,\n",
    "                    \"right_knee\": right_knee,\n",
    "                    \"right_hip\": right_hip,\n",
    "                    \"right_shoulder\": right_shoulder,\n",
    "                    \"right_elbow\": right_elbow,\n",
    "                    \"right_wrist\": right_wrist\n",
    "                })\n",
    "\n",
    "        # Release the video\n",
    "        cap.release()\n",
    "\n",
    "        # Save keypoints to the keypoints folder\n",
    "        json_filename = os.path.splitext(file)[0] + \"_keypoints.json\"\n",
    "        json_path = os.path.join(keypoints_folder, json_filename)\n",
    "        with open(json_path, \"w\") as json_file:\n",
    "            json.dump(keypoints_data, json_file, indent=4)\n",
    "\n",
    "print(\"Knee lift and arm height analysis complete! JSON files saved in 'keypoints' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 sequences with labels.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Path to the keypoints folder for knee lift and arm height analysis\n",
    "keypoints_folder = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage3/keypoints\"\n",
    "\n",
    "# Lists to store sequences and labels\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "# Process keypoint JSON files\n",
    "for file in os.listdir(keypoints_folder):\n",
    "    if file.endswith(\"_keypoints.json\"):\n",
    "        file_path = os.path.join(keypoints_folder, file)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Extract knee lift and arm high indicators across all frames\n",
    "        knee_arm_data = [\n",
    "            [int(frame[\"left_takeoff\"]), int(frame[\"right_takeoff\"])]\n",
    "            for frame in data\n",
    "        ]\n",
    "        sequences.append(knee_arm_data)\n",
    "\n",
    "        # Extract label from filename (assumes label is the first part of filename)\n",
    "        try:\n",
    "            label = float(file.split(\"_\")[0])  # Modify if filename structure differs\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Unable to extract label from {file}\")\n",
    "            continue\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "# Pad sequences to ensure uniform input shape\n",
    "if sequences:\n",
    "    max_len = max(len(seq) for seq in sequences)\n",
    "    sequences = pad_sequences(sequences, maxlen=max_len, padding='post', dtype='float32')\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    print(f\"Loaded {len(sequences)} sequences with labels.\")\n",
    "else:\n",
    "    print(\"No sequences found in the keypoints folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented dataset size: 75\n"
     ]
    }
   ],
   "source": [
    "def augment_data(sequence):\n",
    "    augmented_sequences = []\n",
    "\n",
    "    # Original\n",
    "    augmented_sequences.append(sequence)\n",
    "\n",
    "    # Mirrored (flip angles horizontally)\n",
    "    mirrored = -sequence\n",
    "    augmented_sequences.append(mirrored)\n",
    "\n",
    "    # Rotation (add a small angle offset)\n",
    "    rotated = sequence + np.random.uniform(-10, 10, size=sequence.shape)\n",
    "    augmented_sequences.append(rotated)\n",
    "\n",
    "    # Noise (add random Gaussian noise)\n",
    "    noisy = sequence + np.random.normal(0, 0.05, size=sequence.shape)\n",
    "    augmented_sequences.append(noisy)\n",
    "\n",
    "    # Scaled (adjust by a small percentage)\n",
    "    scaled = sequence * np.random.uniform(0.9, 1.1)\n",
    "    augmented_sequences.append(scaled)\n",
    "\n",
    "    return augmented_sequences\n",
    "\n",
    "augmented_sequences = []\n",
    "augmented_labels = []\n",
    "\n",
    "for seq, label in zip(sequences, labels):\n",
    "    augmented = augment_data(seq)\n",
    "    augmented_sequences.extend(augmented)\n",
    "    augmented_labels.extend([label] * len(augmented))\n",
    "\n",
    "augmented_sequences = np.array(augmented_sequences)\n",
    "augmented_labels = np.array(augmented_labels)\n",
    "\n",
    "print(f\"Augmented dataset size: {len(augmented_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 57, Validation samples: 18\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    augmented_sequences, augmented_labels, test_size=4/17, random_state=42\n",
    ")\n",
    "\n",
    "# Ensure correct shape for LSTM input (samples, timesteps, features)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 2))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 2))\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define enhanced LSTM model\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(128, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1], 2))),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Bidirectional(LSTM(64, activation='tanh', return_sequences=True)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Bidirectional(LSTM(32, activation='tanh', return_sequences=False)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output: Regression score\n",
    "])\n",
    "\n",
    "# Compile the model with a reduced learning rate for better convergence\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse', metrics=['mae'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.6451 - mae: 0.6562 - val_loss: 0.6373 - val_mae: 0.7206\n",
      "Epoch 2/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.5962 - mae: 0.6921 - val_loss: 0.3611 - val_mae: 0.5693\n",
      "Epoch 3/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.3243 - mae: 0.5233 - val_loss: 0.1585 - val_mae: 0.3292\n",
      "Epoch 4/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.2837 - mae: 0.4572 - val_loss: 0.1840 - val_mae: 0.3953\n",
      "Epoch 5/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.2520 - mae: 0.4644 - val_loss: 0.2079 - val_mae: 0.4369\n",
      "Epoch 6/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.2049 - mae: 0.4312 - val_loss: 0.2055 - val_mae: 0.4394\n",
      "Epoch 7/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.2382 - mae: 0.4592 - val_loss: 0.1719 - val_mae: 0.3613\n",
      "Epoch 8/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.1994 - mae: 0.3828 - val_loss: 0.1760 - val_mae: 0.3709\n",
      "Epoch 9/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.1960 - mae: 0.3767 - val_loss: 0.2139 - val_mae: 0.4506\n",
      "Epoch 10/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.1871 - mae: 0.3910 - val_loss: 0.1672 - val_mae: 0.3670\n",
      "Epoch 11/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.2003 - mae: 0.4072 - val_loss: 0.1532 - val_mae: 0.3543\n",
      "Epoch 12/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.1838 - mae: 0.3936 - val_loss: 0.1450 - val_mae: 0.3050\n",
      "Epoch 13/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1351 - mae: 0.2740 - val_loss: 0.1619 - val_mae: 0.3379\n",
      "Epoch 14/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - loss: 0.1712 - mae: 0.3477 - val_loss: 0.2043 - val_mae: 0.3948\n",
      "Epoch 15/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 0.1533 - mae: 0.3312 - val_loss: 0.1725 - val_mae: 0.3391\n",
      "Epoch 16/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1751 - mae: 0.3340 - val_loss: 0.1626 - val_mae: 0.3492\n",
      "Epoch 17/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.1675 - mae: 0.3570 - val_loss: 0.1611 - val_mae: 0.3571\n",
      "Epoch 18/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.1738 - mae: 0.3568 - val_loss: 0.1442 - val_mae: 0.3151\n",
      "Epoch 19/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1402 - mae: 0.3110 - val_loss: 0.1372 - val_mae: 0.3000\n",
      "Epoch 20/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1552 - mae: 0.3210 - val_loss: 0.1278 - val_mae: 0.2901\n",
      "Epoch 21/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - loss: 0.1780 - mae: 0.3436 - val_loss: 0.1360 - val_mae: 0.3078\n",
      "Epoch 22/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1222 - mae: 0.2898 - val_loss: 0.1454 - val_mae: 0.3250\n",
      "Epoch 23/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.1201 - mae: 0.2819 - val_loss: 0.1331 - val_mae: 0.3219\n",
      "Epoch 24/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1257 - mae: 0.2877 - val_loss: 0.1280 - val_mae: 0.3030\n",
      "Epoch 25/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.1609 - mae: 0.3389 - val_loss: 0.1307 - val_mae: 0.3221\n",
      "Epoch 26/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1247 - mae: 0.2813 - val_loss: 0.1332 - val_mae: 0.3386\n",
      "Epoch 27/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1134 - mae: 0.2808 - val_loss: 0.1425 - val_mae: 0.3398\n",
      "Epoch 28/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1487 - mae: 0.3187 - val_loss: 0.1312 - val_mae: 0.3333\n",
      "Epoch 29/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.1290 - mae: 0.2927 - val_loss: 0.1407 - val_mae: 0.3351\n",
      "Epoch 30/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - loss: 0.1328 - mae: 0.3202 - val_loss: 0.1165 - val_mae: 0.2931\n",
      "Epoch 31/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.1040 - mae: 0.2528 - val_loss: 0.1211 - val_mae: 0.3030\n",
      "Epoch 32/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1405 - mae: 0.3103 - val_loss: 0.1229 - val_mae: 0.2991\n",
      "Epoch 33/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1107 - mae: 0.2681 - val_loss: 0.1216 - val_mae: 0.3013\n",
      "Epoch 34/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.1216 - mae: 0.2914 - val_loss: 0.1150 - val_mae: 0.2983\n",
      "Epoch 35/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1101 - mae: 0.2690 - val_loss: 0.1146 - val_mae: 0.3009\n",
      "Epoch 36/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1271 - mae: 0.2816 - val_loss: 0.1155 - val_mae: 0.2899\n",
      "Epoch 37/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.1121 - mae: 0.2669 - val_loss: 0.1494 - val_mae: 0.3509\n",
      "Epoch 38/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0966 - mae: 0.2567 - val_loss: 0.1310 - val_mae: 0.3047\n",
      "Epoch 39/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0924 - mae: 0.2487 - val_loss: 0.1290 - val_mae: 0.3145\n",
      "Epoch 40/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.1080 - mae: 0.2645 - val_loss: 0.1281 - val_mae: 0.2964\n",
      "Epoch 41/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - loss: 0.0871 - mae: 0.2391 - val_loss: 0.1593 - val_mae: 0.3367\n",
      "Epoch 42/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1041 - mae: 0.2444 - val_loss: 0.1210 - val_mae: 0.2940\n",
      "Epoch 43/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0926 - mae: 0.2337 - val_loss: 0.1105 - val_mae: 0.2795\n",
      "Epoch 44/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.1269 - mae: 0.2758 - val_loss: 0.1625 - val_mae: 0.3161\n",
      "Epoch 45/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.1039 - mae: 0.2404 - val_loss: 0.1384 - val_mae: 0.2985\n",
      "Epoch 46/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.1024 - mae: 0.2436 - val_loss: 0.1013 - val_mae: 0.2783\n",
      "Epoch 47/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0940 - mae: 0.2553 - val_loss: 0.1155 - val_mae: 0.2753\n",
      "Epoch 48/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0805 - mae: 0.2179 - val_loss: 0.1127 - val_mae: 0.2700\n",
      "Epoch 49/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0659 - mae: 0.1997 - val_loss: 0.1234 - val_mae: 0.2723\n",
      "Epoch 50/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0767 - mae: 0.2076 - val_loss: 0.1648 - val_mae: 0.2816\n",
      "Epoch 51/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0734 - mae: 0.2093 - val_loss: 0.1449 - val_mae: 0.2718\n",
      "Epoch 52/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0721 - mae: 0.2076 - val_loss: 0.1351 - val_mae: 0.2488\n",
      "Epoch 53/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0881 - mae: 0.2141 - val_loss: 0.1596 - val_mae: 0.2643\n",
      "Epoch 54/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0504 - mae: 0.1682 - val_loss: 0.1805 - val_mae: 0.2767\n",
      "Epoch 55/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0637 - mae: 0.1680 - val_loss: 0.2001 - val_mae: 0.2896\n",
      "Epoch 56/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0650 - mae: 0.1700 - val_loss: 0.2176 - val_mae: 0.3065\n",
      "Epoch 57/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0465 - mae: 0.1535 - val_loss: 0.1535 - val_mae: 0.2387\n",
      "Epoch 58/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0598 - mae: 0.1574 - val_loss: 0.1108 - val_mae: 0.1973\n",
      "Epoch 59/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0561 - mae: 0.1556 - val_loss: 0.1198 - val_mae: 0.2301\n",
      "Epoch 60/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0857 - mae: 0.1882 - val_loss: 0.1153 - val_mae: 0.1995\n",
      "Epoch 61/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0508 - mae: 0.1489 - val_loss: 0.1121 - val_mae: 0.1953\n",
      "Epoch 62/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0615 - mae: 0.1738 - val_loss: 0.1237 - val_mae: 0.2084\n",
      "Epoch 63/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0361 - mae: 0.1309 - val_loss: 0.1384 - val_mae: 0.2218\n",
      "Epoch 64/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0551 - mae: 0.1566 - val_loss: 0.1457 - val_mae: 0.2455\n",
      "Epoch 65/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0419 - mae: 0.1456 - val_loss: 0.1094 - val_mae: 0.2073\n",
      "Epoch 66/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0377 - mae: 0.1332 - val_loss: 0.1191 - val_mae: 0.2000\n",
      "Epoch 67/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0928 - mae: 0.1744 - val_loss: 0.1163 - val_mae: 0.2027\n",
      "Epoch 68/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0656 - mae: 0.1539 - val_loss: 0.1514 - val_mae: 0.2477\n",
      "Epoch 69/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0296 - mae: 0.1229 - val_loss: 0.1488 - val_mae: 0.2447\n",
      "Epoch 70/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0454 - mae: 0.1555 - val_loss: 0.1571 - val_mae: 0.2438\n",
      "Epoch 71/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0275 - mae: 0.1245 - val_loss: 0.1860 - val_mae: 0.2936\n",
      "Epoch 72/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0300 - mae: 0.1202 - val_loss: 0.1883 - val_mae: 0.2681\n",
      "Epoch 73/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0401 - mae: 0.1513 - val_loss: 0.1890 - val_mae: 0.2775\n",
      "Epoch 74/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0353 - mae: 0.1347 - val_loss: 0.2129 - val_mae: 0.2834\n",
      "Epoch 75/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0220 - mae: 0.1085 - val_loss: 0.1529 - val_mae: 0.2385\n",
      "Epoch 76/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0321 - mae: 0.1306 - val_loss: 0.1001 - val_mae: 0.1728\n",
      "Epoch 77/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0361 - mae: 0.1113 - val_loss: 0.1006 - val_mae: 0.1708\n",
      "Epoch 78/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0248 - mae: 0.1074 - val_loss: 0.1095 - val_mae: 0.1995\n",
      "Epoch 79/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0229 - mae: 0.1076 - val_loss: 0.1180 - val_mae: 0.2106\n",
      "Epoch 80/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0157 - mae: 0.0791 - val_loss: 0.1125 - val_mae: 0.1865\n",
      "Epoch 81/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0504 - mae: 0.1357 - val_loss: 0.1292 - val_mae: 0.2322\n",
      "Epoch 82/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0378 - mae: 0.1196 - val_loss: 0.1557 - val_mae: 0.2560\n",
      "Epoch 83/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0195 - mae: 0.0943 - val_loss: 0.1343 - val_mae: 0.2245\n",
      "Epoch 84/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0375 - mae: 0.1060 - val_loss: 0.1333 - val_mae: 0.2223\n",
      "Epoch 85/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0480 - mae: 0.1318 - val_loss: 0.1723 - val_mae: 0.2592\n",
      "Epoch 86/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0193 - mae: 0.0909 - val_loss: 0.1501 - val_mae: 0.2426\n",
      "Epoch 87/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0194 - mae: 0.0914 - val_loss: 0.1272 - val_mae: 0.2056\n",
      "Epoch 88/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0181 - mae: 0.0960 - val_loss: 0.1257 - val_mae: 0.2071\n",
      "Epoch 89/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0165 - mae: 0.0931 - val_loss: 0.1156 - val_mae: 0.2029\n",
      "Epoch 90/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0378 - mae: 0.1284 - val_loss: 0.1181 - val_mae: 0.2125\n",
      "Epoch 91/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0140 - mae: 0.0858 - val_loss: 0.1380 - val_mae: 0.2606\n",
      "Epoch 92/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0185 - mae: 0.0951 - val_loss: 0.1285 - val_mae: 0.2140\n",
      "Epoch 93/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0249 - mae: 0.0957 - val_loss: 0.1184 - val_mae: 0.2034\n",
      "Epoch 94/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0205 - mae: 0.0870 - val_loss: 0.1335 - val_mae: 0.2339\n",
      "Epoch 95/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0178 - mae: 0.0980 - val_loss: 0.1254 - val_mae: 0.2155\n",
      "Epoch 96/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0182 - mae: 0.0943 - val_loss: 0.1135 - val_mae: 0.1909\n",
      "Epoch 97/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0223 - mae: 0.1074 - val_loss: 0.1190 - val_mae: 0.1925\n",
      "Epoch 98/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0220 - mae: 0.0780 - val_loss: 0.1333 - val_mae: 0.2061\n",
      "Epoch 99/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0205 - mae: 0.1033 - val_loss: 0.1300 - val_mae: 0.2092\n",
      "Epoch 100/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0130 - mae: 0.0754 - val_loss: 0.1299 - val_mae: 0.2088\n",
      "Epoch 101/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0137 - mae: 0.0758 - val_loss: 0.1283 - val_mae: 0.2188\n",
      "Epoch 102/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0250 - mae: 0.1022 - val_loss: 0.1109 - val_mae: 0.2008\n",
      "Epoch 103/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0318 - mae: 0.0950 - val_loss: 0.1041 - val_mae: 0.1877\n",
      "Epoch 104/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0144 - mae: 0.0814 - val_loss: 0.1007 - val_mae: 0.1777\n",
      "Epoch 105/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0437 - mae: 0.1084 - val_loss: 0.1005 - val_mae: 0.1859\n",
      "Epoch 106/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0166 - mae: 0.0868 - val_loss: 0.0978 - val_mae: 0.1699\n",
      "Epoch 107/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0257 - mae: 0.0998 - val_loss: 0.0986 - val_mae: 0.1820\n",
      "Epoch 108/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0174 - mae: 0.0874 - val_loss: 0.1254 - val_mae: 0.2390\n",
      "Epoch 109/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0261 - mae: 0.1087 - val_loss: 0.1137 - val_mae: 0.2237\n",
      "Epoch 110/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0431 - mae: 0.1112 - val_loss: 0.1032 - val_mae: 0.1794\n",
      "Epoch 111/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - loss: 0.0328 - mae: 0.1203 - val_loss: 0.1023 - val_mae: 0.1759\n",
      "Epoch 112/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0397 - mae: 0.1208 - val_loss: 0.1543 - val_mae: 0.2571\n",
      "Epoch 113/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0581 - mae: 0.1393 - val_loss: 0.1418 - val_mae: 0.2351\n",
      "Epoch 114/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0426 - mae: 0.1413 - val_loss: 0.1096 - val_mae: 0.2074\n",
      "Epoch 115/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0349 - mae: 0.1228 - val_loss: 0.1185 - val_mae: 0.2325\n",
      "Epoch 116/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - loss: 0.0372 - mae: 0.1165 - val_loss: 0.1098 - val_mae: 0.2214\n",
      "Epoch 117/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 0.0306 - mae: 0.1073 - val_loss: 0.1295 - val_mae: 0.2541\n",
      "Epoch 118/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0380 - mae: 0.1324 - val_loss: 0.1211 - val_mae: 0.2127\n",
      "Epoch 119/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0594 - mae: 0.1519 - val_loss: 0.1394 - val_mae: 0.2425\n",
      "Epoch 120/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0364 - mae: 0.1305 - val_loss: 0.1696 - val_mae: 0.2834\n",
      "Epoch 121/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0400 - mae: 0.1248 - val_loss: 0.1096 - val_mae: 0.2220\n",
      "Epoch 122/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0297 - mae: 0.0994 - val_loss: 0.1032 - val_mae: 0.1914\n",
      "Epoch 123/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0600 - mae: 0.1381 - val_loss: 0.0967 - val_mae: 0.1724\n",
      "Epoch 124/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0344 - mae: 0.1054 - val_loss: 0.1028 - val_mae: 0.1992\n",
      "Epoch 125/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0337 - mae: 0.1052 - val_loss: 0.0985 - val_mae: 0.1971\n",
      "Epoch 126/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0306 - mae: 0.0951 - val_loss: 0.0893 - val_mae: 0.1616\n",
      "Epoch 127/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0732 - mae: 0.1520 - val_loss: 0.2324 - val_mae: 0.3013\n",
      "Epoch 128/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0482 - mae: 0.1269 - val_loss: 0.2058 - val_mae: 0.2801\n",
      "Epoch 129/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 0.0344 - mae: 0.1049 - val_loss: 0.0920 - val_mae: 0.1621\n",
      "Epoch 130/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0286 - mae: 0.1035 - val_loss: 0.0973 - val_mae: 0.1798\n",
      "Epoch 131/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - loss: 0.0214 - mae: 0.0999 - val_loss: 0.0945 - val_mae: 0.1922\n",
      "Epoch 132/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - loss: 0.0508 - mae: 0.1274 - val_loss: 0.0813 - val_mae: 0.2031\n",
      "Epoch 133/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - loss: 0.0356 - mae: 0.1317 - val_loss: 0.0897 - val_mae: 0.1945\n",
      "Epoch 134/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0352 - mae: 0.1101 - val_loss: 0.0976 - val_mae: 0.1932\n",
      "Epoch 135/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0616 - mae: 0.1252 - val_loss: 0.0914 - val_mae: 0.1834\n",
      "Epoch 136/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0600 - mae: 0.1367 - val_loss: 0.0893 - val_mae: 0.1642\n",
      "Epoch 137/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0261 - mae: 0.0914 - val_loss: 0.0953 - val_mae: 0.1982\n",
      "Epoch 138/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0347 - mae: 0.1046 - val_loss: 0.0875 - val_mae: 0.1968\n",
      "Epoch 139/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0494 - mae: 0.1350 - val_loss: 0.0802 - val_mae: 0.1693\n",
      "Epoch 140/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0443 - mae: 0.1345 - val_loss: 0.0816 - val_mae: 0.1681\n",
      "Epoch 141/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - loss: 0.0416 - mae: 0.1145 - val_loss: 0.0833 - val_mae: 0.1814\n",
      "Epoch 142/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0292 - mae: 0.0985 - val_loss: 0.0855 - val_mae: 0.1914\n",
      "Epoch 143/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0333 - mae: 0.1049 - val_loss: 0.0805 - val_mae: 0.1741\n",
      "Epoch 144/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0455 - mae: 0.1199 - val_loss: 0.0841 - val_mae: 0.1917\n",
      "Epoch 145/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0350 - mae: 0.1132 - val_loss: 0.0861 - val_mae: 0.1914\n",
      "Epoch 146/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0364 - mae: 0.1071 - val_loss: 0.0865 - val_mae: 0.1820\n",
      "Epoch 147/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.0272 - mae: 0.1045 - val_loss: 0.0848 - val_mae: 0.1595\n",
      "Epoch 148/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0249 - mae: 0.0980 - val_loss: 0.0828 - val_mae: 0.1645\n",
      "Epoch 149/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.0487 - mae: 0.1173 - val_loss: 0.0836 - val_mae: 0.1866\n",
      "Epoch 150/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0365 - mae: 0.1001 - val_loss: 0.0873 - val_mae: 0.2023\n",
      "Epoch 151/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0332 - mae: 0.1074 - val_loss: 0.0787 - val_mae: 0.1667\n",
      "Epoch 152/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0277 - mae: 0.1015 - val_loss: 0.0790 - val_mae: 0.1612\n",
      "Epoch 153/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0375 - mae: 0.1089 - val_loss: 0.0844 - val_mae: 0.1959\n",
      "Epoch 154/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0176 - mae: 0.0847 - val_loss: 0.0807 - val_mae: 0.1715\n",
      "Epoch 155/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.0194 - mae: 0.0871 - val_loss: 0.0828 - val_mae: 0.1793\n",
      "Epoch 156/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0228 - mae: 0.1061 - val_loss: 0.0869 - val_mae: 0.1944\n",
      "Epoch 157/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0316 - mae: 0.1039 - val_loss: 0.0896 - val_mae: 0.2113\n",
      "Epoch 158/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0348 - mae: 0.1103 - val_loss: 0.0821 - val_mae: 0.1797\n",
      "Epoch 159/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0335 - mae: 0.1091 - val_loss: 0.0809 - val_mae: 0.1779\n",
      "Epoch 160/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0270 - mae: 0.0973 - val_loss: 0.0846 - val_mae: 0.1868\n",
      "Epoch 161/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0383 - mae: 0.1121 - val_loss: 0.0820 - val_mae: 0.1832\n",
      "Epoch 162/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0219 - mae: 0.1073 - val_loss: 0.0797 - val_mae: 0.1646\n",
      "Epoch 163/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0254 - mae: 0.0968 - val_loss: 0.0811 - val_mae: 0.1663\n",
      "Epoch 164/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0482 - mae: 0.1198 - val_loss: 0.0803 - val_mae: 0.1824\n",
      "Epoch 165/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0338 - mae: 0.1024 - val_loss: 0.0830 - val_mae: 0.1984\n",
      "Epoch 166/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0417 - mae: 0.1190 - val_loss: 0.0728 - val_mae: 0.1865\n",
      "Epoch 167/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0335 - mae: 0.0996 - val_loss: 0.1181 - val_mae: 0.1960\n",
      "Epoch 168/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0285 - mae: 0.0897 - val_loss: 0.1170 - val_mae: 0.2046\n",
      "Epoch 169/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0475 - mae: 0.1126 - val_loss: 0.0927 - val_mae: 0.1892\n",
      "Epoch 170/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.0351 - mae: 0.1102 - val_loss: 0.0890 - val_mae: 0.1792\n",
      "Epoch 171/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0299 - mae: 0.1083 - val_loss: 0.0890 - val_mae: 0.1841\n",
      "Epoch 172/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0262 - mae: 0.0920 - val_loss: 0.0852 - val_mae: 0.1824\n",
      "Epoch 173/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0287 - mae: 0.0960 - val_loss: 0.0832 - val_mae: 0.1770\n",
      "Epoch 174/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0357 - mae: 0.1100 - val_loss: 0.0871 - val_mae: 0.1737\n",
      "Epoch 175/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0238 - mae: 0.0866 - val_loss: 0.0899 - val_mae: 0.1942\n",
      "Epoch 176/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0202 - mae: 0.0876 - val_loss: 0.0888 - val_mae: 0.2024\n",
      "Epoch 177/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0245 - mae: 0.0968 - val_loss: 0.0817 - val_mae: 0.1914\n",
      "Epoch 178/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0266 - mae: 0.0923 - val_loss: 0.0829 - val_mae: 0.2018\n",
      "Epoch 179/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0306 - mae: 0.1004 - val_loss: 0.0848 - val_mae: 0.1943\n",
      "Epoch 180/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0297 - mae: 0.1061 - val_loss: 0.0915 - val_mae: 0.1962\n",
      "Epoch 181/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0359 - mae: 0.1048 - val_loss: 0.1023 - val_mae: 0.2229\n",
      "Epoch 182/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0544 - mae: 0.1274 - val_loss: 0.1037 - val_mae: 0.2114\n",
      "Epoch 183/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0429 - mae: 0.1124 - val_loss: 0.0842 - val_mae: 0.1634\n",
      "Epoch 184/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0249 - mae: 0.0966 - val_loss: 0.0911 - val_mae: 0.2041\n",
      "Epoch 185/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0557 - mae: 0.1329 - val_loss: 0.0832 - val_mae: 0.2077\n",
      "Epoch 186/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0331 - mae: 0.1155 - val_loss: 0.0812 - val_mae: 0.1985\n",
      "Epoch 187/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.0278 - mae: 0.1075 - val_loss: 0.0762 - val_mae: 0.1879\n",
      "Epoch 188/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0345 - mae: 0.1145 - val_loss: 0.0779 - val_mae: 0.1895\n",
      "Epoch 189/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0265 - mae: 0.0917 - val_loss: 0.0825 - val_mae: 0.2002\n",
      "Epoch 190/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0308 - mae: 0.1171 - val_loss: 0.0782 - val_mae: 0.1733\n",
      "Epoch 191/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0251 - mae: 0.0930 - val_loss: 0.0903 - val_mae: 0.2157\n",
      "Epoch 192/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.0338 - mae: 0.0988 - val_loss: 0.0792 - val_mae: 0.1906\n",
      "Epoch 193/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0377 - mae: 0.1031 - val_loss: 0.0726 - val_mae: 0.1852\n",
      "Epoch 194/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0341 - mae: 0.1095 - val_loss: 0.0846 - val_mae: 0.1961\n",
      "Epoch 195/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.0373 - mae: 0.1140 - val_loss: 0.0782 - val_mae: 0.1791\n",
      "Epoch 196/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0295 - mae: 0.0977 - val_loss: 0.0828 - val_mae: 0.1813\n",
      "Epoch 197/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0444 - mae: 0.1145 - val_loss: 0.0842 - val_mae: 0.2111\n",
      "Epoch 198/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0290 - mae: 0.1102 - val_loss: 0.0867 - val_mae: 0.1900\n",
      "Epoch 199/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 0.0175 - mae: 0.0745 - val_loss: 0.0843 - val_mae: 0.1777\n",
      "Epoch 200/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0179 - mae: 0.0869 - val_loss: 0.0686 - val_mae: 0.1481\n",
      "Epoch 201/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0210 - mae: 0.0960 - val_loss: 0.0754 - val_mae: 0.1851\n",
      "Epoch 202/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0252 - mae: 0.0941 - val_loss: 0.1008 - val_mae: 0.2183\n",
      "Epoch 203/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0263 - mae: 0.0936 - val_loss: 0.0896 - val_mae: 0.2028\n",
      "Epoch 204/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0296 - mae: 0.1060 - val_loss: 0.0870 - val_mae: 0.2055\n",
      "Epoch 205/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0202 - mae: 0.0754 - val_loss: 0.0785 - val_mae: 0.1998\n",
      "Epoch 206/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0271 - mae: 0.1053 - val_loss: 0.0681 - val_mae: 0.1533\n",
      "Epoch 207/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0298 - mae: 0.1069 - val_loss: 0.0713 - val_mae: 0.1456\n",
      "Epoch 208/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0469 - mae: 0.1226 - val_loss: 0.1047 - val_mae: 0.2170\n",
      "Epoch 209/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0157 - mae: 0.0756 - val_loss: 0.0894 - val_mae: 0.1689\n",
      "Epoch 210/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0347 - mae: 0.1253 - val_loss: 0.0519 - val_mae: 0.1400\n",
      "Epoch 211/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.0442 - mae: 0.1416 - val_loss: 0.0934 - val_mae: 0.1806\n",
      "Epoch 212/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0536 - mae: 0.1313 - val_loss: 0.0774 - val_mae: 0.1680\n",
      "Epoch 213/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0574 - mae: 0.1391 - val_loss: 0.0805 - val_mae: 0.1647\n",
      "Epoch 214/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.0270 - mae: 0.1034 - val_loss: 0.0837 - val_mae: 0.1713\n",
      "Epoch 215/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0426 - mae: 0.1177 - val_loss: 0.1164 - val_mae: 0.1907\n",
      "Epoch 216/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0315 - mae: 0.0970 - val_loss: 0.1231 - val_mae: 0.2477\n",
      "Epoch 217/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.1343 - mae: 0.2109 - val_loss: 0.1755 - val_mae: 0.3596\n",
      "Epoch 218/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 0.1689 - mae: 0.2981 - val_loss: 0.1963 - val_mae: 0.4329\n",
      "Epoch 219/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.1873 - mae: 0.3812 - val_loss: 0.1696 - val_mae: 0.3715\n",
      "Epoch 220/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.1505 - mae: 0.2879 - val_loss: 0.1806 - val_mae: 0.4103\n",
      "Epoch 221/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.1783 - mae: 0.3744 - val_loss: 0.1417 - val_mae: 0.3530\n",
      "Epoch 222/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.1874 - mae: 0.3259 - val_loss: 0.2527 - val_mae: 0.4164\n",
      "Epoch 223/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.1530 - mae: 0.2993 - val_loss: 0.1093 - val_mae: 0.2975\n",
      "Epoch 224/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.1353 - mae: 0.2934 - val_loss: 0.1242 - val_mae: 0.3094\n",
      "Epoch 225/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.1548 - mae: 0.2823 - val_loss: 0.1719 - val_mae: 0.3906\n",
      "Epoch 226/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.1406 - mae: 0.3211 - val_loss: 0.1136 - val_mae: 0.3196\n",
      "Epoch 227/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.1076 - mae: 0.2513 - val_loss: 0.1746 - val_mae: 0.3672\n",
      "Epoch 228/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1495 - mae: 0.3003 - val_loss: 0.1401 - val_mae: 0.3204\n",
      "Epoch 229/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.1524 - mae: 0.3369 - val_loss: 0.1689 - val_mae: 0.3864\n",
      "Epoch 230/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.1257 - mae: 0.2958 - val_loss: 0.1336 - val_mae: 0.2790\n",
      "Epoch 231/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.1319 - mae: 0.2657 - val_loss: 0.1321 - val_mae: 0.3132\n",
      "Epoch 232/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.1082 - mae: 0.2524 - val_loss: 0.1649 - val_mae: 0.3509\n",
      "Epoch 233/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.1449 - mae: 0.2956 - val_loss: 0.3129 - val_mae: 0.4492\n",
      "Epoch 234/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - loss: 0.1990 - mae: 0.3365 - val_loss: 0.1394 - val_mae: 0.3016\n",
      "Epoch 235/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.1083 - mae: 0.2387 - val_loss: 0.1298 - val_mae: 0.3183\n",
      "Epoch 236/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.1300 - mae: 0.2863 - val_loss: 0.2529 - val_mae: 0.4837\n",
      "Epoch 237/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.1507 - mae: 0.3257 - val_loss: 0.1969 - val_mae: 0.3897\n",
      "Epoch 238/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.1403 - mae: 0.2853 - val_loss: 0.2252 - val_mae: 0.4306\n",
      "Epoch 239/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1354 - mae: 0.2892 - val_loss: 0.2226 - val_mae: 0.3988\n",
      "Epoch 240/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 0.1162 - mae: 0.2696 - val_loss: 0.2234 - val_mae: 0.4049\n",
      "Epoch 241/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.1546 - mae: 0.3322 - val_loss: 0.2420 - val_mae: 0.4529\n",
      "Epoch 242/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.1606 - mae: 0.3372 - val_loss: 0.2204 - val_mae: 0.4055\n",
      "Epoch 243/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.1266 - mae: 0.2707 - val_loss: 0.2142 - val_mae: 0.4125\n",
      "Epoch 244/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.1647 - mae: 0.3264 - val_loss: 0.1922 - val_mae: 0.3858\n",
      "Epoch 245/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.1000 - mae: 0.2426 - val_loss: 0.1802 - val_mae: 0.3537\n",
      "Epoch 246/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - loss: 0.1170 - mae: 0.2788 - val_loss: 0.1609 - val_mae: 0.3384\n",
      "Epoch 247/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.0867 - mae: 0.2142 - val_loss: 0.1710 - val_mae: 0.3466\n",
      "Epoch 248/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.1025 - mae: 0.2426 - val_loss: 0.1680 - val_mae: 0.3442\n",
      "Epoch 249/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.1075 - mae: 0.2538 - val_loss: 0.1749 - val_mae: 0.3560\n",
      "Epoch 250/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 0.1165 - mae: 0.2547 - val_loss: 0.1695 - val_mae: 0.3312\n",
      "Epoch 251/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0966 - mae: 0.2292 - val_loss: 0.1539 - val_mae: 0.3328\n",
      "Epoch 252/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0916 - mae: 0.2324 - val_loss: 0.1699 - val_mae: 0.3237\n",
      "Epoch 253/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0599 - mae: 0.1690 - val_loss: 0.1105 - val_mae: 0.2631\n",
      "Epoch 254/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.2049 - mae: 0.3202 - val_loss: 0.1932 - val_mae: 0.4269\n",
      "Epoch 255/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 0.2174 - mae: 0.4376 - val_loss: 0.2304 - val_mae: 0.4742\n",
      "Epoch 256/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.2394 - mae: 0.4370 - val_loss: 0.1681 - val_mae: 0.3642\n",
      "Epoch 257/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.2162 - mae: 0.3999 - val_loss: 0.1793 - val_mae: 0.4057\n",
      "Epoch 258/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - loss: 0.2225 - mae: 0.4157 - val_loss: 0.1880 - val_mae: 0.4207\n",
      "Epoch 259/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.2090 - mae: 0.4143 - val_loss: 0.1812 - val_mae: 0.4095\n",
      "Epoch 260/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 0.2244 - mae: 0.4297 - val_loss: 0.1739 - val_mae: 0.4019\n",
      "Epoch 261/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.1833 - mae: 0.3986 - val_loss: 0.2161 - val_mae: 0.4570\n",
      "Epoch 262/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.2234 - mae: 0.4461 - val_loss: 0.1692 - val_mae: 0.3906\n",
      "Epoch 263/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.2058 - mae: 0.3864 - val_loss: 0.1492 - val_mae: 0.3505\n",
      "Epoch 264/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.1969 - mae: 0.3729 - val_loss: 0.1444 - val_mae: 0.3529\n",
      "Epoch 265/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.1665 - mae: 0.3514 - val_loss: 0.2228 - val_mae: 0.4323\n",
      "Epoch 266/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.1347 - mae: 0.3123 - val_loss: 0.3334 - val_mae: 0.4645\n",
      "Epoch 267/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.2029 - mae: 0.3748 - val_loss: 0.3536 - val_mae: 0.5668\n",
      "Epoch 268/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.1909 - mae: 0.4067 - val_loss: 0.2790 - val_mae: 0.4883\n",
      "Epoch 269/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.1397 - mae: 0.2749 - val_loss: 0.2539 - val_mae: 0.4281\n",
      "Epoch 270/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.2125 - mae: 0.3677 - val_loss: 0.2900 - val_mae: 0.5008\n",
      "Epoch 271/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.1098 - mae: 0.2741 - val_loss: 0.2751 - val_mae: 0.4734\n",
      "Epoch 272/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.1502 - mae: 0.3020 - val_loss: 0.2439 - val_mae: 0.3979\n",
      "Epoch 273/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.1744 - mae: 0.2906 - val_loss: 0.1937 - val_mae: 0.4073\n",
      "Epoch 274/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.1673 - mae: 0.3477 - val_loss: 0.2307 - val_mae: 0.4683\n",
      "Epoch 275/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.1614 - mae: 0.3500 - val_loss: 0.2297 - val_mae: 0.4497\n",
      "Epoch 276/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.1646 - mae: 0.3384 - val_loss: 0.2252 - val_mae: 0.4329\n",
      "Epoch 277/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.1566 - mae: 0.3133 - val_loss: 0.2155 - val_mae: 0.4008\n",
      "Epoch 278/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 0.1635 - mae: 0.3147 - val_loss: 0.2268 - val_mae: 0.4381\n",
      "Epoch 279/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.1568 - mae: 0.3213 - val_loss: 0.2149 - val_mae: 0.4167\n",
      "Epoch 280/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.1505 - mae: 0.3051 - val_loss: 0.2123 - val_mae: 0.4121\n",
      "Epoch 281/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.1168 - mae: 0.2576 - val_loss: 0.2200 - val_mae: 0.4323\n",
      "Epoch 282/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.1184 - mae: 0.2865 - val_loss: 0.2330 - val_mae: 0.4537\n",
      "Epoch 283/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.1383 - mae: 0.3099 - val_loss: 0.2361 - val_mae: 0.4596\n",
      "Epoch 284/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.1552 - mae: 0.3384 - val_loss: 0.2824 - val_mae: 0.5070\n",
      "Epoch 285/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.1836 - mae: 0.3850 - val_loss: 0.2117 - val_mae: 0.4224\n",
      "Epoch 286/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.1600 - mae: 0.3201 - val_loss: 0.2074 - val_mae: 0.4219\n",
      "Epoch 287/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.1571 - mae: 0.3302 - val_loss: 0.2140 - val_mae: 0.4298\n",
      "Epoch 288/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.1433 - mae: 0.3139 - val_loss: 0.1986 - val_mae: 0.4068\n",
      "Epoch 289/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.1360 - mae: 0.3056 - val_loss: 0.1880 - val_mae: 0.3741\n",
      "Epoch 290/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.1379 - mae: 0.2659 - val_loss: 0.1971 - val_mae: 0.3950\n",
      "Epoch 291/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.1746 - mae: 0.3599 - val_loss: 0.2592 - val_mae: 0.4826\n",
      "Epoch 292/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.1418 - mae: 0.3201 - val_loss: 0.2373 - val_mae: 0.4554\n",
      "Epoch 293/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.1259 - mae: 0.2893 - val_loss: 0.2195 - val_mae: 0.4248\n",
      "Epoch 294/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.1398 - mae: 0.3109 - val_loss: 0.2270 - val_mae: 0.4395\n",
      "Epoch 295/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.1249 - mae: 0.2697 - val_loss: 0.2119 - val_mae: 0.3935\n",
      "Epoch 296/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.1276 - mae: 0.2576 - val_loss: 0.2293 - val_mae: 0.4406\n",
      "Epoch 297/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.1238 - mae: 0.2869 - val_loss: 0.2195 - val_mae: 0.4094\n",
      "Epoch 298/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.1165 - mae: 0.2551 - val_loss: 0.2468 - val_mae: 0.4609\n",
      "Epoch 299/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.1100 - mae: 0.2669 - val_loss: 0.2150 - val_mae: 0.4066\n",
      "Epoch 300/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.1333 - mae: 0.2955 - val_loss: 0.2134 - val_mae: 0.4076\n",
      "Epoch 301/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.1117 - mae: 0.2386 - val_loss: 0.2111 - val_mae: 0.4011\n",
      "Epoch 302/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.1175 - mae: 0.2824 - val_loss: 0.2126 - val_mae: 0.4087\n",
      "Epoch 303/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.1276 - mae: 0.2833 - val_loss: 0.1747 - val_mae: 0.3716\n",
      "Epoch 304/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0963 - mae: 0.2482 - val_loss: 0.1716 - val_mae: 0.3724\n",
      "Epoch 305/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.1017 - mae: 0.2507 - val_loss: 0.2090 - val_mae: 0.3847\n",
      "Epoch 306/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0934 - mae: 0.2189 - val_loss: 0.1835 - val_mae: 0.3676\n",
      "Epoch 307/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.1587 - mae: 0.3241 - val_loss: 0.1958 - val_mae: 0.3205\n",
      "Epoch 308/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.1569 - mae: 0.2752 - val_loss: 0.1762 - val_mae: 0.3781\n",
      "Epoch 309/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.1359 - mae: 0.3048 - val_loss: 0.1303 - val_mae: 0.2989\n",
      "Epoch 310/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.1344 - mae: 0.2725 - val_loss: 0.1124 - val_mae: 0.2786\n",
      "Epoch 311/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0826 - mae: 0.2098 - val_loss: 0.1229 - val_mae: 0.3133\n",
      "Epoch 312/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0814 - mae: 0.2186 - val_loss: 0.1134 - val_mae: 0.2848\n",
      "Epoch 313/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0895 - mae: 0.1984 - val_loss: 0.0988 - val_mae: 0.2495\n",
      "Epoch 314/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0995 - mae: 0.2171 - val_loss: 0.1761 - val_mae: 0.3285\n",
      "Epoch 315/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.2067 - mae: 0.3449 - val_loss: 0.1637 - val_mae: 0.3257\n",
      "Epoch 316/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.1432 - mae: 0.2639 - val_loss: 0.1696 - val_mae: 0.3477\n",
      "Epoch 317/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0895 - mae: 0.2412 - val_loss: 0.1037 - val_mae: 0.2669\n",
      "Epoch 318/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0844 - mae: 0.2097 - val_loss: 0.1567 - val_mae: 0.3000\n",
      "Epoch 319/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0588 - mae: 0.1704 - val_loss: 0.0683 - val_mae: 0.2174\n",
      "Epoch 320/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0554 - mae: 0.1575 - val_loss: 0.0367 - val_mae: 0.1533\n",
      "Epoch 321/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0366 - mae: 0.1269 - val_loss: 0.1382 - val_mae: 0.2864\n",
      "Epoch 322/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0844 - mae: 0.2107 - val_loss: 0.0977 - val_mae: 0.2409\n",
      "Epoch 323/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0448 - mae: 0.1551 - val_loss: 0.0829 - val_mae: 0.1716\n",
      "Epoch 324/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 0.0305 - mae: 0.1260 - val_loss: 0.0611 - val_mae: 0.1456\n",
      "Epoch 325/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0340 - mae: 0.1358 - val_loss: 0.1025 - val_mae: 0.1738\n",
      "Epoch 326/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0699 - mae: 0.1651 - val_loss: 0.0826 - val_mae: 0.1826\n",
      "Epoch 327/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0442 - mae: 0.1360 - val_loss: 0.0707 - val_mae: 0.1668\n",
      "Epoch 328/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0185 - mae: 0.1004 - val_loss: 0.0419 - val_mae: 0.1291\n",
      "Epoch 329/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0358 - mae: 0.1201 - val_loss: 0.0896 - val_mae: 0.1759\n",
      "Epoch 330/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0338 - mae: 0.1258 - val_loss: 0.0751 - val_mae: 0.1444\n",
      "Epoch 331/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0143 - mae: 0.0918 - val_loss: 0.0230 - val_mae: 0.0861\n",
      "Epoch 332/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0640 - mae: 0.1506 - val_loss: 0.0424 - val_mae: 0.1342\n",
      "Epoch 333/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0632 - mae: 0.1511 - val_loss: 0.0304 - val_mae: 0.1563\n",
      "Epoch 334/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0638 - mae: 0.1727 - val_loss: 0.0940 - val_mae: 0.2115\n",
      "Epoch 335/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0337 - mae: 0.1395 - val_loss: 0.0257 - val_mae: 0.0913\n",
      "Epoch 336/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0407 - mae: 0.1344 - val_loss: 0.0288 - val_mae: 0.1048\n",
      "Epoch 337/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0295 - mae: 0.1215 - val_loss: 0.0844 - val_mae: 0.1308\n",
      "Epoch 338/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0285 - mae: 0.1031 - val_loss: 0.0897 - val_mae: 0.1466\n",
      "Epoch 339/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0360 - mae: 0.1219 - val_loss: 0.0659 - val_mae: 0.1391\n",
      "Epoch 340/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0170 - mae: 0.0898 - val_loss: 0.0794 - val_mae: 0.1464\n",
      "Epoch 341/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0282 - mae: 0.0949 - val_loss: 0.0915 - val_mae: 0.1478\n",
      "Epoch 342/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0493 - mae: 0.1161 - val_loss: 0.1120 - val_mae: 0.1501\n",
      "Epoch 343/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0332 - mae: 0.0989 - val_loss: 0.0764 - val_mae: 0.1302\n",
      "Epoch 344/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0226 - mae: 0.1066 - val_loss: 0.0779 - val_mae: 0.1411\n",
      "Epoch 345/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0222 - mae: 0.0949 - val_loss: 0.0823 - val_mae: 0.1571\n",
      "Epoch 346/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0235 - mae: 0.0978 - val_loss: 0.0916 - val_mae: 0.1709\n",
      "Epoch 347/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0243 - mae: 0.0971 - val_loss: 0.0995 - val_mae: 0.1607\n",
      "Epoch 348/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0277 - mae: 0.1000 - val_loss: 0.1358 - val_mae: 0.2059\n",
      "Epoch 349/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0502 - mae: 0.1195 - val_loss: 0.1736 - val_mae: 0.2686\n",
      "Epoch 350/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0656 - mae: 0.1641 - val_loss: 0.1055 - val_mae: 0.1469\n",
      "Epoch 351/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0358 - mae: 0.1134 - val_loss: 0.0888 - val_mae: 0.1463\n",
      "Epoch 352/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0261 - mae: 0.1094 - val_loss: 0.0257 - val_mae: 0.1085\n",
      "Epoch 353/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0392 - mae: 0.1359 - val_loss: 0.0639 - val_mae: 0.1767\n",
      "Epoch 354/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0318 - mae: 0.1162 - val_loss: 0.0807 - val_mae: 0.1798\n",
      "Epoch 355/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0372 - mae: 0.1092 - val_loss: 0.0777 - val_mae: 0.1710\n",
      "Epoch 356/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0236 - mae: 0.1001 - val_loss: 0.0908 - val_mae: 0.1745\n",
      "Epoch 357/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0355 - mae: 0.1188 - val_loss: 0.0974 - val_mae: 0.1813\n",
      "Epoch 358/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0231 - mae: 0.0913 - val_loss: 0.0752 - val_mae: 0.1476\n",
      "Epoch 359/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0329 - mae: 0.1244 - val_loss: 0.0886 - val_mae: 0.1847\n",
      "Epoch 360/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0401 - mae: 0.1284 - val_loss: 0.1243 - val_mae: 0.1904\n",
      "Epoch 361/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0342 - mae: 0.1109 - val_loss: 0.1300 - val_mae: 0.2183\n",
      "Epoch 362/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0469 - mae: 0.1323 - val_loss: 0.0868 - val_mae: 0.1711\n",
      "Epoch 363/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0126 - mae: 0.0764 - val_loss: 0.0711 - val_mae: 0.1535\n",
      "Epoch 364/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0257 - mae: 0.1065 - val_loss: 0.0433 - val_mae: 0.1300\n",
      "Epoch 365/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0216 - mae: 0.0994 - val_loss: 0.0971 - val_mae: 0.1699\n",
      "Epoch 366/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0232 - mae: 0.0958 - val_loss: 0.1057 - val_mae: 0.1726\n",
      "Epoch 367/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0381 - mae: 0.1011 - val_loss: 0.0827 - val_mae: 0.1605\n",
      "Epoch 368/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0185 - mae: 0.0814 - val_loss: 0.0888 - val_mae: 0.1775\n",
      "Epoch 369/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0169 - mae: 0.0835 - val_loss: 0.0824 - val_mae: 0.1667\n",
      "Epoch 370/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0195 - mae: 0.0736 - val_loss: 0.0773 - val_mae: 0.1568\n",
      "Epoch 371/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0146 - mae: 0.0759 - val_loss: 0.0887 - val_mae: 0.1779\n",
      "Epoch 372/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0302 - mae: 0.0945 - val_loss: 0.0943 - val_mae: 0.1883\n",
      "Epoch 373/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0165 - mae: 0.0728 - val_loss: 0.0968 - val_mae: 0.1865\n",
      "Epoch 374/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0140 - mae: 0.0749 - val_loss: 0.1034 - val_mae: 0.1890\n",
      "Epoch 375/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0273 - mae: 0.0904 - val_loss: 0.0936 - val_mae: 0.1764\n",
      "Epoch 376/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0172 - mae: 0.0799 - val_loss: 0.1088 - val_mae: 0.1897\n",
      "Epoch 377/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0100 - mae: 0.0721 - val_loss: 0.1003 - val_mae: 0.1736\n",
      "Epoch 378/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0226 - mae: 0.0902 - val_loss: 0.0573 - val_mae: 0.1583\n",
      "Epoch 379/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0305 - mae: 0.1106 - val_loss: 0.0657 - val_mae: 0.1914\n",
      "Epoch 380/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0295 - mae: 0.1079 - val_loss: 0.0704 - val_mae: 0.1894\n",
      "Epoch 381/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0205 - mae: 0.0915 - val_loss: 0.0697 - val_mae: 0.1742\n",
      "Epoch 382/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0133 - mae: 0.0723 - val_loss: 0.0753 - val_mae: 0.1540\n",
      "Epoch 383/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0186 - mae: 0.0812 - val_loss: 0.0769 - val_mae: 0.1433\n",
      "Epoch 384/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0193 - mae: 0.0949 - val_loss: 0.0852 - val_mae: 0.1608\n",
      "Epoch 385/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0190 - mae: 0.0809 - val_loss: 0.0741 - val_mae: 0.1556\n",
      "Epoch 386/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0270 - mae: 0.0968 - val_loss: 0.0705 - val_mae: 0.1427\n",
      "Epoch 387/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0155 - mae: 0.0833 - val_loss: 0.0771 - val_mae: 0.1515\n",
      "Epoch 388/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0248 - mae: 0.0836 - val_loss: 0.0734 - val_mae: 0.1504\n",
      "Epoch 389/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0155 - mae: 0.0761 - val_loss: 0.0795 - val_mae: 0.1447\n",
      "Epoch 390/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0102 - mae: 0.0602 - val_loss: 0.0839 - val_mae: 0.1474\n",
      "Epoch 391/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0335 - mae: 0.0980 - val_loss: 0.0849 - val_mae: 0.1562\n",
      "Epoch 392/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0154 - mae: 0.0779 - val_loss: 0.0965 - val_mae: 0.1927\n",
      "Epoch 393/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0140 - mae: 0.0818 - val_loss: 0.0936 - val_mae: 0.1865\n",
      "Epoch 394/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0208 - mae: 0.0980 - val_loss: 0.0794 - val_mae: 0.1646\n",
      "Epoch 395/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0202 - mae: 0.0811 - val_loss: 0.0795 - val_mae: 0.1404\n",
      "Epoch 396/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0157 - mae: 0.0821 - val_loss: 0.0968 - val_mae: 0.1598\n",
      "Epoch 397/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0116 - mae: 0.0647 - val_loss: 0.1138 - val_mae: 0.1940\n",
      "Epoch 398/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0207 - mae: 0.0896 - val_loss: 0.0831 - val_mae: 0.1634\n",
      "Epoch 399/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0280 - mae: 0.0953 - val_loss: 0.0698 - val_mae: 0.1334\n",
      "Epoch 400/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0156 - mae: 0.0739 - val_loss: 0.0730 - val_mae: 0.1307\n",
      "Epoch 401/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0284 - mae: 0.1151 - val_loss: 0.0962 - val_mae: 0.1566\n",
      "Epoch 402/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0245 - mae: 0.0923 - val_loss: 0.0821 - val_mae: 0.1532\n",
      "Epoch 403/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0157 - mae: 0.0895 - val_loss: 0.1279 - val_mae: 0.1901\n",
      "Epoch 404/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0141 - mae: 0.0816 - val_loss: 0.1179 - val_mae: 0.1895\n",
      "Epoch 405/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0252 - mae: 0.0899 - val_loss: 0.0663 - val_mae: 0.1486\n",
      "Epoch 406/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0273 - mae: 0.1063 - val_loss: 0.1443 - val_mae: 0.2000\n",
      "Epoch 407/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0449 - mae: 0.1121 - val_loss: 0.0831 - val_mae: 0.1612\n",
      "Epoch 408/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0300 - mae: 0.1113 - val_loss: 0.0786 - val_mae: 0.1670\n",
      "Epoch 409/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0237 - mae: 0.0920 - val_loss: 0.1256 - val_mae: 0.1935\n",
      "Epoch 410/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0365 - mae: 0.0950 - val_loss: 0.1153 - val_mae: 0.1823\n",
      "Epoch 411/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0212 - mae: 0.0846 - val_loss: 0.1139 - val_mae: 0.1737\n",
      "Epoch 412/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0325 - mae: 0.0823 - val_loss: 0.1165 - val_mae: 0.1745\n",
      "Epoch 413/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0414 - mae: 0.1083 - val_loss: 0.0762 - val_mae: 0.1523\n",
      "Epoch 414/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0263 - mae: 0.0955 - val_loss: 0.0653 - val_mae: 0.1592\n",
      "Epoch 415/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0147 - mae: 0.0801 - val_loss: 0.0692 - val_mae: 0.1646\n",
      "Epoch 416/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0161 - mae: 0.0763 - val_loss: 0.0767 - val_mae: 0.1477\n",
      "Epoch 417/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0273 - mae: 0.0962 - val_loss: 0.0795 - val_mae: 0.1430\n",
      "Epoch 418/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0128 - mae: 0.0738 - val_loss: 0.0065 - val_mae: 0.0642\n",
      "Epoch 419/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.1132 - mae: 0.1746 - val_loss: 0.2545 - val_mae: 0.3679\n",
      "Epoch 420/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0795 - mae: 0.1813 - val_loss: 0.2200 - val_mae: 0.3662\n",
      "Epoch 421/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0827 - mae: 0.1952 - val_loss: 0.1492 - val_mae: 0.2554\n",
      "Epoch 422/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0726 - mae: 0.1603 - val_loss: 0.0923 - val_mae: 0.1776\n",
      "Epoch 423/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0716 - mae: 0.1610 - val_loss: 0.1330 - val_mae: 0.2225\n",
      "Epoch 424/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0847 - mae: 0.1845 - val_loss: 0.1396 - val_mae: 0.2362\n",
      "Epoch 425/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0709 - mae: 0.1892 - val_loss: 0.1055 - val_mae: 0.1813\n",
      "Epoch 426/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0485 - mae: 0.1341 - val_loss: 0.0886 - val_mae: 0.1792\n",
      "Epoch 427/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0540 - mae: 0.1482 - val_loss: 0.1764 - val_mae: 0.2513\n",
      "Epoch 428/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0595 - mae: 0.1433 - val_loss: 0.2132 - val_mae: 0.2704\n",
      "Epoch 429/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0324 - mae: 0.1049 - val_loss: 0.2087 - val_mae: 0.2522\n",
      "Epoch 430/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0365 - mae: 0.1062 - val_loss: 0.1807 - val_mae: 0.2666\n",
      "Epoch 431/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0242 - mae: 0.1134 - val_loss: 0.1068 - val_mae: 0.1820\n",
      "Epoch 432/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0534 - mae: 0.1268 - val_loss: 0.1588 - val_mae: 0.2372\n",
      "Epoch 433/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0689 - mae: 0.1758 - val_loss: 0.1285 - val_mae: 0.2340\n",
      "Epoch 434/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0522 - mae: 0.1472 - val_loss: 0.1861 - val_mae: 0.2706\n",
      "Epoch 435/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0251 - mae: 0.0924 - val_loss: 0.2315 - val_mae: 0.2697\n",
      "Epoch 436/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0449 - mae: 0.1269 - val_loss: 0.2358 - val_mae: 0.2713\n",
      "Epoch 437/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0189 - mae: 0.0902 - val_loss: 0.2379 - val_mae: 0.2878\n",
      "Epoch 438/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0327 - mae: 0.1052 - val_loss: 0.2303 - val_mae: 0.2719\n",
      "Epoch 439/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0172 - mae: 0.0915 - val_loss: 0.1816 - val_mae: 0.2235\n",
      "Epoch 440/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0150 - mae: 0.0782 - val_loss: 0.2211 - val_mae: 0.2628\n",
      "Epoch 441/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0184 - mae: 0.0941 - val_loss: 0.2162 - val_mae: 0.2657\n",
      "Epoch 442/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0367 - mae: 0.1032 - val_loss: 0.2077 - val_mae: 0.2680\n",
      "Epoch 443/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0315 - mae: 0.1032 - val_loss: 0.2058 - val_mae: 0.2564\n",
      "Epoch 444/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0313 - mae: 0.1030 - val_loss: 0.1741 - val_mae: 0.2354\n",
      "Epoch 445/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0217 - mae: 0.0765 - val_loss: 0.1751 - val_mae: 0.2344\n",
      "Epoch 446/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0222 - mae: 0.0762 - val_loss: 0.1431 - val_mae: 0.2088\n",
      "Epoch 447/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0138 - mae: 0.0748 - val_loss: 0.1551 - val_mae: 0.2182\n",
      "Epoch 448/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0273 - mae: 0.0985 - val_loss: 0.1771 - val_mae: 0.2483\n",
      "Epoch 449/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0126 - mae: 0.0639 - val_loss: 0.2319 - val_mae: 0.2841\n",
      "Epoch 450/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0127 - mae: 0.0598 - val_loss: 0.2181 - val_mae: 0.2838\n",
      "Epoch 451/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0405 - mae: 0.1019 - val_loss: 0.2070 - val_mae: 0.2749\n",
      "Epoch 452/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0125 - mae: 0.0708 - val_loss: 0.2136 - val_mae: 0.2703\n",
      "Epoch 453/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0141 - mae: 0.0642 - val_loss: 0.1658 - val_mae: 0.2342\n",
      "Epoch 454/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0293 - mae: 0.0957 - val_loss: 0.1879 - val_mae: 0.2542\n",
      "Epoch 455/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0126 - mae: 0.0762 - val_loss: 0.1778 - val_mae: 0.2516\n",
      "Epoch 456/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0268 - mae: 0.0987 - val_loss: 0.1960 - val_mae: 0.2666\n",
      "Epoch 457/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0171 - mae: 0.0730 - val_loss: 0.2046 - val_mae: 0.2615\n",
      "Epoch 458/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0172 - mae: 0.0696 - val_loss: 0.2105 - val_mae: 0.2653\n",
      "Epoch 459/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.0148 - mae: 0.0677 - val_loss: 0.2058 - val_mae: 0.2697\n",
      "Epoch 460/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0221 - mae: 0.0879 - val_loss: 0.2094 - val_mae: 0.2717\n",
      "Epoch 461/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0144 - mae: 0.0742 - val_loss: 0.1668 - val_mae: 0.2348\n",
      "Epoch 462/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0376 - mae: 0.1060 - val_loss: 0.1778 - val_mae: 0.2473\n",
      "Epoch 463/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0295 - mae: 0.1003 - val_loss: 0.1791 - val_mae: 0.2563\n",
      "Epoch 464/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0170 - mae: 0.0786 - val_loss: 0.1737 - val_mae: 0.2397\n",
      "Epoch 465/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0303 - mae: 0.0857 - val_loss: 0.1930 - val_mae: 0.2502\n",
      "Epoch 466/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0187 - mae: 0.0738 - val_loss: 0.1935 - val_mae: 0.2459\n",
      "Epoch 467/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0286 - mae: 0.0861 - val_loss: 0.2259 - val_mae: 0.2836\n",
      "Epoch 468/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0134 - mae: 0.0719 - val_loss: 0.1776 - val_mae: 0.2434\n",
      "Epoch 469/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0227 - mae: 0.0738 - val_loss: 0.1777 - val_mae: 0.2352\n",
      "Epoch 470/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0101 - mae: 0.0631 - val_loss: 0.1780 - val_mae: 0.2261\n",
      "Epoch 471/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0294 - mae: 0.0813 - val_loss: 0.1780 - val_mae: 0.2303\n",
      "Epoch 472/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0225 - mae: 0.0710 - val_loss: 0.1919 - val_mae: 0.2463\n",
      "Epoch 473/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0278 - mae: 0.0815 - val_loss: 0.1871 - val_mae: 0.2395\n",
      "Epoch 474/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0093 - mae: 0.0625 - val_loss: 0.1834 - val_mae: 0.2387\n",
      "Epoch 475/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0141 - mae: 0.0664 - val_loss: 0.1739 - val_mae: 0.2282\n",
      "Epoch 476/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0202 - mae: 0.0817 - val_loss: 0.1734 - val_mae: 0.2296\n",
      "Epoch 477/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0126 - mae: 0.0635 - val_loss: 0.1726 - val_mae: 0.2406\n",
      "Epoch 478/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0157 - mae: 0.0784 - val_loss: 0.1633 - val_mae: 0.2310\n",
      "Epoch 479/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0199 - mae: 0.0718 - val_loss: 0.1824 - val_mae: 0.2428\n",
      "Epoch 480/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0225 - mae: 0.0836 - val_loss: 0.1804 - val_mae: 0.2509\n",
      "Epoch 481/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0109 - mae: 0.0654 - val_loss: 0.2046 - val_mae: 0.2723\n",
      "Epoch 482/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0202 - mae: 0.0714 - val_loss: 0.1945 - val_mae: 0.2641\n",
      "Epoch 483/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0112 - mae: 0.0646 - val_loss: 0.2015 - val_mae: 0.2694\n",
      "Epoch 484/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0155 - mae: 0.0721 - val_loss: 0.1903 - val_mae: 0.2544\n",
      "Epoch 485/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0170 - mae: 0.0800 - val_loss: 0.2108 - val_mae: 0.2743\n",
      "Epoch 486/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0084 - mae: 0.0559 - val_loss: 0.2164 - val_mae: 0.2856\n",
      "Epoch 487/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0257 - mae: 0.0813 - val_loss: 0.2198 - val_mae: 0.2709\n",
      "Epoch 488/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0103 - mae: 0.0678 - val_loss: 0.2182 - val_mae: 0.2679\n",
      "Epoch 489/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - loss: 0.0126 - mae: 0.0622 - val_loss: 0.2091 - val_mae: 0.2721\n",
      "Epoch 490/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0143 - mae: 0.0730 - val_loss: 0.1936 - val_mae: 0.2715\n",
      "Epoch 491/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0188 - mae: 0.0648 - val_loss: 0.1830 - val_mae: 0.2543\n",
      "Epoch 492/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0133 - mae: 0.0628 - val_loss: 0.1884 - val_mae: 0.2601\n",
      "Epoch 493/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0232 - mae: 0.0850 - val_loss: 0.1786 - val_mae: 0.2499\n",
      "Epoch 494/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0100 - mae: 0.0598 - val_loss: 0.1768 - val_mae: 0.2430\n",
      "Epoch 495/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0153 - mae: 0.0599 - val_loss: 0.1732 - val_mae: 0.2349\n",
      "Epoch 496/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0141 - mae: 0.0655 - val_loss: 0.1891 - val_mae: 0.2498\n",
      "Epoch 497/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0176 - mae: 0.0648 - val_loss: 0.1881 - val_mae: 0.2502\n",
      "Epoch 498/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0129 - mae: 0.0620 - val_loss: 0.1811 - val_mae: 0.2394\n",
      "Epoch 499/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0250 - mae: 0.0738 - val_loss: 0.1764 - val_mae: 0.2360\n",
      "Epoch 500/500\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0094 - mae: 0.0543 - val_loss: 0.1832 - val_mae: 0.2426\n"
     ]
    }
   ],
   "source": [
    "# Train the LSTM model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=500,  # You can adjust based on convergence\n",
    "    batch_size=16,  # Smaller batch size for augmented data\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1832, Validation MAE: 0.2426\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_mae = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation MAE: {val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
      "Predicted: -0.00, Actual: 0.00\n",
      "Predicted: 0.91, Actual: 1.00\n",
      "Predicted: 0.94, Actual: 1.00\n",
      "Predicted: -0.01, Actual: 0.00\n",
      "Predicted: 0.93, Actual: 1.00\n",
      "Predicted: 0.96, Actual: 1.00\n",
      "Predicted: -0.03, Actual: 0.00\n",
      "Predicted: 0.08, Actual: 1.00\n",
      "Predicted: 0.94, Actual: 1.00\n",
      "Predicted: 0.94, Actual: 1.00\n",
      "Predicted: 1.00, Actual: 1.00\n",
      "Predicted: 0.06, Actual: 1.00\n",
      "Predicted: -0.05, Actual: 0.00\n",
      "Predicted: 0.94, Actual: 1.00\n",
      "Predicted: 0.14, Actual: 1.00\n",
      "Predicted: 0.75, Actual: 1.00\n",
      "Predicted: 0.14, Actual: 1.00\n",
      "Predicted: 1.01, Actual: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Predict scores on validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Print predictions vs. actual\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Predicted: {pred[0]:.2f}, Actual: {y_val[i]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatter plot of predictions vs. actual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_val, predictions, c='blue', label='Predicted vs Actual')\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Perfect Match')  # Reference line\n",
    "plt.xlabel('Actual Scores')\n",
    "plt.ylabel('Predicted Scores')\n",
    "plt.title('Model Predictions vs. Actual Scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737665614.084719 11090681 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n",
      "W0000 00:00:1737665614.141297 11165536 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737665614.149798 11165536 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step\n",
      "Predicted Score: 0.93\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to check if the knee is lifted and the arm is high\n",
    "def is_knee_lift_arm_high(knee, ankle, shoulder, wrist):\n",
    "    \"\"\"\n",
    "    Determines if the knee is fully lifted and the arm is high during takeoff.\n",
    "    Conditions:\n",
    "    - Knee should be significantly above the ankle.\n",
    "    - Arm (wrist) should be above the shoulder level.\n",
    "    \"\"\"\n",
    "    knee_x, knee_y = knee\n",
    "    ankle_x, ankle_y = ankle\n",
    "    shoulder_x, shoulder_y = shoulder\n",
    "    wrist_x, wrist_y = wrist\n",
    "\n",
    "    knee_lifted = knee_y < ankle_y - 0.1  # Knee should be higher than ankle\n",
    "    arm_high = wrist_y < shoulder_y       # Wrist should be higher than shoulder\n",
    "\n",
    "    return knee_lifted and arm_high\n",
    "\n",
    "# Path for the new test video\n",
    "new_video_path = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage3/test_videos/1_user10.mp4\"\n",
    "\n",
    "# Extract keypoints for the new video\n",
    "new_keypoints = []\n",
    "cap = cv2.VideoCapture(new_video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB for MediaPipe processing\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = pose.process(frame_rgb)\n",
    "\n",
    "    if result.pose_landmarks:\n",
    "        landmarks = result.pose_landmarks.landmark\n",
    "\n",
    "        # Extract keypoints for knee lift and arm high analysis\n",
    "        left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y]\n",
    "        left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y]\n",
    "        left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y]\n",
    "        left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST].y]\n",
    "\n",
    "        right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y]\n",
    "        right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].y]\n",
    "        right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y]\n",
    "        right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST].y]\n",
    "\n",
    "        # Check for knee lift and arm position for both sides\n",
    "        left_takeoff = is_knee_lift_arm_high(left_knee, left_ankle, left_shoulder, left_wrist)\n",
    "        right_takeoff = is_knee_lift_arm_high(right_knee, right_ankle, right_shoulder, right_wrist)\n",
    "\n",
    "        # Store the binary values (0 or 1) for analysis\n",
    "        new_keypoints.append([int(left_takeoff), int(right_takeoff)])\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Pad the sequence to match training input length\n",
    "max_seq_length = X_train.shape[1]  # Ensure it's the same length used during training\n",
    "new_keypoints_padded = pad_sequences([new_keypoints], maxlen=max_seq_length, padding='post', dtype='float32')\n",
    "\n",
    "# Reshape to match model input (samples, timesteps, features)\n",
    "new_keypoints_padded = new_keypoints_padded.reshape((new_keypoints_padded.shape[0], new_keypoints_padded.shape[1], 2))\n",
    "\n",
    "# Predict score for the new video\n",
    "predicted_score = model.predict(new_keypoints_padded)\n",
    "print(f\"Predicted Score: {predicted_score[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_score(prediction):\n",
    "    \"\"\"Classify the prediction into 0, 0.5, or 1 based on thresholds.\"\"\"\n",
    "    if prediction >= 0.75:\n",
    "        return 1.0\n",
    "    elif prediction >= 0.5:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 1.0\n",
      "Classified: 0.5, Actual: 1.0\n",
      "Classified: 0.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Predict scores on validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Apply classification logic\n",
    "classified_predictions = [classify_score(pred[0]) for pred in predictions]\n",
    "\n",
    "# Print classified predictions vs actual scores\n",
    "for i, (pred, actual) in enumerate(zip(classified_predictions, y_val)):\n",
    "    print(f\"Classified: {pred}, Actual: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def weighted_mse(y_true, y_pred):\n",
    "    \"\"\"Weighted Mean Squared Error to prioritize true negatives.\"\"\"\n",
    "    weights = K.switch(y_true < 0.70, 2.0, 1.0)  # Weight true negatives higher\n",
    "    return K.mean(weights * K.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=weighted_mse, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step\n",
      "Classification Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Predict and classify scores\n",
    "classified_predictions = [classify_score(pred[0]) for pred in model.predict(X_val)]\n",
    "\n",
    "# Evaluate accuracy of classification\n",
    "correct = sum(1 for pred, actual in zip(classified_predictions, y_val) if pred == actual)\n",
    "accuracy = correct / len(y_val)\n",
    "\n",
    "print(f\"Classification Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/height_jump/stages/stage3/models/highjump_stage3.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
