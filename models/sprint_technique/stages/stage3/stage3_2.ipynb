{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737643363.237982 8882006 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1737643363.295308 8885097 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737643363.304763 8885097 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737643363.316514 8885104 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clawing motion extraction complete! JSON files saved in 'keypoints' folder.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to determine if an active clawing motion is occurring\n",
    "def is_clawing_motion(hip, knee, ankle):\n",
    "    \"\"\"\n",
    "    Determines active clawing motion by analyzing knee and ankle positions.\n",
    "    The knee should be forward relative to the hip and the ankle should be tucked under the knee.\n",
    "    \"\"\"\n",
    "    knee_forward = knee[0] > hip[0]  # Knee is ahead of the hip in the x-axis\n",
    "    ankle_tucked = ankle[1] < knee[1]  # Ankle is higher (y-coordinate is lower)\n",
    "    \n",
    "    return knee_forward and ankle_tucked\n",
    "\n",
    "# Paths for the stage 3 videos and keypoints storage\n",
    "stage_path = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/sprint_technique/stages/stage3/videos\"\n",
    "keypoints_folder = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/sprint_technique/stages/stage3/keypoints\"\n",
    "\n",
    "# Ensure keypoints folder exists\n",
    "os.makedirs(keypoints_folder, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(stage_path):\n",
    "    if file.endswith(\".mp4\"):\n",
    "        video_file_path = os.path.join(stage_path, file)\n",
    "        cap = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "        keypoints_data = []  # Store keypoints for this video\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Convert frame to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result = pose.process(frame_rgb)\n",
    "\n",
    "            if result.pose_landmarks:\n",
    "                landmarks = result.pose_landmarks.landmark\n",
    "\n",
    "                # Extract relevant keypoints for left and right leg\n",
    "                left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_HIP].y]\n",
    "                left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y]\n",
    "                left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y]\n",
    "\n",
    "                right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y]\n",
    "                right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y]\n",
    "                right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].y]\n",
    "\n",
    "                # Check for active clawing motion in both legs\n",
    "                left_clawing = is_clawing_motion(left_hip, left_knee, left_ankle)\n",
    "                right_clawing = is_clawing_motion(right_hip, right_knee, right_ankle)\n",
    "\n",
    "                # Store data for this frame\n",
    "                keypoints_data.append({\n",
    "                    \"frame\": int(cap.get(cv2.CAP_PROP_POS_FRAMES)),\n",
    "                    \"left_clawing_motion\": left_clawing,\n",
    "                    \"right_clawing_motion\": right_clawing,\n",
    "                    \"left_hip\": left_hip,\n",
    "                    \"left_knee\": left_knee,\n",
    "                    \"left_ankle\": left_ankle,\n",
    "                    \"right_hip\": right_hip,\n",
    "                    \"right_knee\": right_knee,\n",
    "                    \"right_ankle\": right_ankle\n",
    "                })\n",
    "\n",
    "        # Release the video\n",
    "        cap.release()\n",
    "\n",
    "        # Save keypoints to the keypoints folder\n",
    "        json_filename = os.path.splitext(file)[0] + \"_keypoints.json\"\n",
    "        json_path = os.path.join(keypoints_folder, json_filename)\n",
    "        with open(json_path, \"w\") as json_file:\n",
    "            json.dump(keypoints_data, json_file, indent=4)\n",
    "\n",
    "print(\"Clawing motion extraction complete! JSON files saved in 'keypoints' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 sequences with labels.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Path to the keypoints folder for stage 3 (active clawing motion)\n",
    "keypoints_folder = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/sprint_technique/stages/stage3/keypoints\"\n",
    "\n",
    "# Lists to store sequences and labels\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "# Process keypoint JSON files\n",
    "for file in os.listdir(keypoints_folder):\n",
    "    if file.endswith(\"_keypoints.json\"):\n",
    "        file_path = os.path.join(keypoints_folder, file)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Extract clawing motion indicators across all frames\n",
    "        clawing_positions = [\n",
    "            [int(frame[\"left_clawing_motion\"]), int(frame[\"right_clawing_motion\"])]\n",
    "            for frame in data\n",
    "        ]\n",
    "        sequences.append(clawing_positions)\n",
    "\n",
    "        # Extract label from filename (assumes label is the first part of filename)\n",
    "        try:\n",
    "            label = float(file.split(\"_\")[0])  # Modify if filename structure differs\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Unable to extract label from {file}\")\n",
    "            continue\n",
    "        \n",
    "        labels.append(label)\n",
    "\n",
    "# Pad sequences to the same length\n",
    "if sequences:\n",
    "    max_len = max(len(seq) for seq in sequences)\n",
    "    sequences = pad_sequences(sequences, maxlen=max_len, padding='post', dtype='float32')\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    print(f\"Loaded {len(sequences)} sequences with labels.\")\n",
    "else:\n",
    "    print(\"No sequences found in the keypoints folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented dataset size: 80\n"
     ]
    }
   ],
   "source": [
    "def augment_data(sequence):\n",
    "    augmented_sequences = []\n",
    "\n",
    "    # Original\n",
    "    augmented_sequences.append(sequence)\n",
    "\n",
    "    # Mirrored (flip angles horizontally)\n",
    "    mirrored = -sequence\n",
    "    augmented_sequences.append(mirrored)\n",
    "\n",
    "    # Rotation (add a small angle offset)\n",
    "    rotated = sequence + np.random.uniform(-10, 10, size=sequence.shape)\n",
    "    augmented_sequences.append(rotated)\n",
    "\n",
    "    # Noise (add random Gaussian noise)\n",
    "    noisy = sequence + np.random.normal(0, 0.05, size=sequence.shape)\n",
    "    augmented_sequences.append(noisy)\n",
    "\n",
    "    # Scaled (adjust by a small percentage)\n",
    "    scaled = sequence * np.random.uniform(0.9, 1.1)\n",
    "    augmented_sequences.append(scaled)\n",
    "\n",
    "    return augmented_sequences\n",
    "\n",
    "augmented_sequences = []\n",
    "augmented_labels = []\n",
    "\n",
    "for seq, label in zip(sequences, labels):\n",
    "    augmented = augment_data(seq)\n",
    "    augmented_sequences.extend(augmented)\n",
    "    augmented_labels.extend([label] * len(augmented))\n",
    "\n",
    "augmented_sequences = np.array(augmented_sequences)\n",
    "augmented_labels = np.array(augmented_labels)\n",
    "\n",
    "print(f\"Augmented dataset size: {len(augmented_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 61, Validation samples: 19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    augmented_sequences, augmented_labels, test_size=4/17, random_state=42\n",
    ")\n",
    "\n",
    "# Ensure correct shape for LSTM input (samples, timesteps, features)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 2))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 2))\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_6 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_7 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_8 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define enhanced LSTM model\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(128, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1], 2))),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Bidirectional(LSTM(64, activation='tanh', return_sequences=True)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Bidirectional(LSTM(32, activation='tanh', return_sequences=False)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output: Regression score\n",
    "])\n",
    "\n",
    "# Compile the model with a reduced learning rate for better convergence\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse', metrics=['mae'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 317ms/step - loss: 0.3046 - mae: 0.3143 - val_loss: 0.2478 - val_mae: 0.2715\n",
      "Epoch 2/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - loss: 0.2297 - mae: 0.2574 - val_loss: 0.2254 - val_mae: 0.2873\n",
      "Epoch 3/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 226ms/step - loss: 0.2396 - mae: 0.2992 - val_loss: 0.2035 - val_mae: 0.3119\n",
      "Epoch 4/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step - loss: 0.1814 - mae: 0.2702 - val_loss: 0.1891 - val_mae: 0.3382\n",
      "Epoch 5/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 227ms/step - loss: 0.1330 - mae: 0.2621 - val_loss: 0.1845 - val_mae: 0.3666\n",
      "Epoch 6/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 254ms/step - loss: 0.1650 - mae: 0.3114 - val_loss: 0.1932 - val_mae: 0.4041\n",
      "Epoch 7/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 259ms/step - loss: 0.1692 - mae: 0.3413 - val_loss: 0.2137 - val_mae: 0.4392\n",
      "Epoch 8/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 247ms/step - loss: 0.1715 - mae: 0.3590 - val_loss: 0.2227 - val_mae: 0.4487\n",
      "Epoch 9/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 210ms/step - loss: 0.1669 - mae: 0.3542 - val_loss: 0.2250 - val_mae: 0.4471\n",
      "Epoch 10/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 210ms/step - loss: 0.1550 - mae: 0.3309 - val_loss: 0.2230 - val_mae: 0.4391\n",
      "Epoch 11/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239ms/step - loss: 0.1570 - mae: 0.3249 - val_loss: 0.2177 - val_mae: 0.4258\n",
      "Epoch 12/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step - loss: 0.1242 - mae: 0.2801 - val_loss: 0.2154 - val_mae: 0.4142\n",
      "Epoch 13/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 246ms/step - loss: 0.1578 - mae: 0.3227 - val_loss: 0.2221 - val_mae: 0.4129\n",
      "Epoch 14/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - loss: 0.1519 - mae: 0.3188 - val_loss: 0.2186 - val_mae: 0.4039\n",
      "Epoch 15/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - loss: 0.1907 - mae: 0.3437 - val_loss: 0.2223 - val_mae: 0.4098\n",
      "Epoch 16/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 212ms/step - loss: 0.1759 - mae: 0.3487 - val_loss: 0.2145 - val_mae: 0.3953\n",
      "Epoch 17/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 279ms/step - loss: 0.1354 - mae: 0.2921 - val_loss: 0.2140 - val_mae: 0.3905\n",
      "Epoch 18/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 283ms/step - loss: 0.1681 - mae: 0.3298 - val_loss: 0.2161 - val_mae: 0.4004\n",
      "Epoch 19/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - loss: 0.1530 - mae: 0.3155 - val_loss: 0.2214 - val_mae: 0.4061\n",
      "Epoch 20/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 227ms/step - loss: 0.1639 - mae: 0.3262 - val_loss: 0.2230 - val_mae: 0.4008\n",
      "Epoch 21/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 206ms/step - loss: 0.1325 - mae: 0.2843 - val_loss: 0.2128 - val_mae: 0.3783\n",
      "Epoch 22/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240ms/step - loss: 0.0999 - mae: 0.2472 - val_loss: 0.2109 - val_mae: 0.3632\n",
      "Epoch 23/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step - loss: 0.1416 - mae: 0.2846 - val_loss: 0.2169 - val_mae: 0.3694\n",
      "Epoch 24/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 404ms/step - loss: 0.1465 - mae: 0.2981 - val_loss: 0.2134 - val_mae: 0.3657\n",
      "Epoch 25/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - loss: 0.1072 - mae: 0.2583 - val_loss: 0.2113 - val_mae: 0.3453\n",
      "Epoch 26/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280ms/step - loss: 0.1244 - mae: 0.2728 - val_loss: 0.2297 - val_mae: 0.3648\n",
      "Epoch 27/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step - loss: 0.0978 - mae: 0.2485 - val_loss: 0.2106 - val_mae: 0.3425\n",
      "Epoch 28/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - loss: 0.1125 - mae: 0.2434 - val_loss: 0.2100 - val_mae: 0.3376\n",
      "Epoch 29/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 423ms/step - loss: 0.1113 - mae: 0.2611 - val_loss: 0.1926 - val_mae: 0.3060\n",
      "Epoch 30/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - loss: 0.1079 - mae: 0.2485 - val_loss: 0.1838 - val_mae: 0.2866\n",
      "Epoch 31/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step - loss: 0.1060 - mae: 0.2365 - val_loss: 0.1818 - val_mae: 0.2635\n",
      "Epoch 32/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - loss: 0.0903 - mae: 0.2122 - val_loss: 0.1914 - val_mae: 0.2576\n",
      "Epoch 33/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0842 - mae: 0.1969 - val_loss: 0.1858 - val_mae: 0.2676\n",
      "Epoch 34/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 431ms/step - loss: 0.1177 - mae: 0.2584 - val_loss: 0.1855 - val_mae: 0.2733\n",
      "Epoch 35/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step - loss: 0.0858 - mae: 0.2143 - val_loss: 0.1884 - val_mae: 0.2477\n",
      "Epoch 36/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 392ms/step - loss: 0.0850 - mae: 0.2007 - val_loss: 0.1729 - val_mae: 0.2261\n",
      "Epoch 37/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step - loss: 0.1071 - mae: 0.2208 - val_loss: 0.1619 - val_mae: 0.2445\n",
      "Epoch 38/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 279ms/step - loss: 0.0781 - mae: 0.2019 - val_loss: 0.1982 - val_mae: 0.2959\n",
      "Epoch 39/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272ms/step - loss: 0.0749 - mae: 0.1930 - val_loss: 0.1550 - val_mae: 0.2334\n",
      "Epoch 40/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 360ms/step - loss: 0.0720 - mae: 0.1799 - val_loss: 0.1623 - val_mae: 0.2103\n",
      "Epoch 41/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - loss: 0.0659 - mae: 0.1588 - val_loss: 0.1662 - val_mae: 0.2021\n",
      "Epoch 42/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0428 - mae: 0.1300 - val_loss: 0.1628 - val_mae: 0.2301\n",
      "Epoch 43/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step - loss: 0.0364 - mae: 0.1266 - val_loss: 0.1535 - val_mae: 0.2141\n",
      "Epoch 44/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318ms/step - loss: 0.0444 - mae: 0.1509 - val_loss: 0.1557 - val_mae: 0.2172\n",
      "Epoch 45/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314ms/step - loss: 0.0283 - mae: 0.1041 - val_loss: 0.1544 - val_mae: 0.2101\n",
      "Epoch 46/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 450ms/step - loss: 0.0554 - mae: 0.1385 - val_loss: 0.1590 - val_mae: 0.2305\n",
      "Epoch 47/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 475ms/step - loss: 0.0429 - mae: 0.1454 - val_loss: 0.1559 - val_mae: 0.2316\n",
      "Epoch 48/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - loss: 0.0354 - mae: 0.1368 - val_loss: 0.1547 - val_mae: 0.2181\n",
      "Epoch 49/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - loss: 0.0343 - mae: 0.1223 - val_loss: 0.1546 - val_mae: 0.2158\n",
      "Epoch 50/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359ms/step - loss: 0.0527 - mae: 0.1352 - val_loss: 0.1545 - val_mae: 0.2120\n",
      "Epoch 51/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 472ms/step - loss: 0.0494 - mae: 0.1271 - val_loss: 0.1509 - val_mae: 0.2259\n",
      "Epoch 52/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 396ms/step - loss: 0.0855 - mae: 0.1697 - val_loss: 0.1916 - val_mae: 0.2946\n",
      "Epoch 53/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - loss: 0.1275 - mae: 0.2332 - val_loss: 0.1737 - val_mae: 0.2646\n",
      "Epoch 54/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step - loss: 0.1212 - mae: 0.2326 - val_loss: 0.1793 - val_mae: 0.2911\n",
      "Epoch 55/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 397ms/step - loss: 0.1100 - mae: 0.2494 - val_loss: 0.1866 - val_mae: 0.2974\n",
      "Epoch 56/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 423ms/step - loss: 0.0870 - mae: 0.2122 - val_loss: 0.1937 - val_mae: 0.2592\n",
      "Epoch 57/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313ms/step - loss: 0.0568 - mae: 0.1550 - val_loss: 0.1962 - val_mae: 0.2435\n",
      "Epoch 58/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - loss: 0.0554 - mae: 0.1435 - val_loss: 0.1892 - val_mae: 0.2408\n",
      "Epoch 59/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - loss: 0.0559 - mae: 0.1707 - val_loss: 0.2023 - val_mae: 0.2787\n",
      "Epoch 60/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 403ms/step - loss: 0.0550 - mae: 0.1716 - val_loss: 0.2185 - val_mae: 0.2596\n",
      "Epoch 61/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 490ms/step - loss: 0.0442 - mae: 0.1297 - val_loss: 0.2405 - val_mae: 0.3214\n",
      "Epoch 62/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312ms/step - loss: 0.1369 - mae: 0.2321 - val_loss: 0.2340 - val_mae: 0.2620\n",
      "Epoch 63/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323ms/step - loss: 0.0775 - mae: 0.1444 - val_loss: 0.2205 - val_mae: 0.2521\n",
      "Epoch 64/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 400ms/step - loss: 0.0895 - mae: 0.1971 - val_loss: 0.2093 - val_mae: 0.3035\n",
      "Epoch 65/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 395ms/step - loss: 0.1054 - mae: 0.2306 - val_loss: 0.2056 - val_mae: 0.2877\n",
      "Epoch 66/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 396ms/step - loss: 0.0680 - mae: 0.1795 - val_loss: 0.1941 - val_mae: 0.2517\n",
      "Epoch 67/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321ms/step - loss: 0.0748 - mae: 0.1548 - val_loss: 0.1883 - val_mae: 0.2480\n",
      "Epoch 68/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313ms/step - loss: 0.0618 - mae: 0.1531 - val_loss: 0.1635 - val_mae: 0.2454\n",
      "Epoch 69/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291ms/step - loss: 0.0580 - mae: 0.1531 - val_loss: 0.1569 - val_mae: 0.2534\n",
      "Epoch 70/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step - loss: 0.0476 - mae: 0.1423 - val_loss: 0.1584 - val_mae: 0.2509\n",
      "Epoch 71/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - loss: 0.0490 - mae: 0.1525 - val_loss: 0.1699 - val_mae: 0.2551\n",
      "Epoch 72/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - loss: 0.0480 - mae: 0.1511 - val_loss: 0.1853 - val_mae: 0.2704\n",
      "Epoch 73/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 395ms/step - loss: 0.0326 - mae: 0.1323 - val_loss: 0.1965 - val_mae: 0.2831\n",
      "Epoch 74/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303ms/step - loss: 0.0246 - mae: 0.1114 - val_loss: 0.1913 - val_mae: 0.2577\n",
      "Epoch 75/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step - loss: 0.0177 - mae: 0.0806 - val_loss: 0.1957 - val_mae: 0.2593\n",
      "Epoch 76/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step - loss: 0.0193 - mae: 0.0901 - val_loss: 0.2005 - val_mae: 0.2670\n",
      "Epoch 77/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step - loss: 0.0183 - mae: 0.0918 - val_loss: 0.2018 - val_mae: 0.2627\n",
      "Epoch 78/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 396ms/step - loss: 0.0276 - mae: 0.1021 - val_loss: 0.1925 - val_mae: 0.2401\n",
      "Epoch 79/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - loss: 0.0189 - mae: 0.0935 - val_loss: 0.2146 - val_mae: 0.2627\n",
      "Epoch 80/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - loss: 0.0136 - mae: 0.0756 - val_loss: 0.2289 - val_mae: 0.2729\n",
      "Epoch 81/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293ms/step - loss: 0.0181 - mae: 0.0774 - val_loss: 0.2246 - val_mae: 0.2645\n",
      "Epoch 82/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step - loss: 0.0083 - mae: 0.0654 - val_loss: 0.2188 - val_mae: 0.2568\n",
      "Epoch 83/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - loss: 0.0107 - mae: 0.0671 - val_loss: 0.2210 - val_mae: 0.2611\n",
      "Epoch 84/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378ms/step - loss: 0.0253 - mae: 0.0850 - val_loss: 0.2221 - val_mae: 0.2653\n",
      "Epoch 85/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - loss: 0.0147 - mae: 0.0770 - val_loss: 0.2068 - val_mae: 0.2435\n",
      "Epoch 86/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373ms/step - loss: 0.0200 - mae: 0.0749 - val_loss: 0.1990 - val_mae: 0.2388\n",
      "Epoch 87/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 347ms/step - loss: 0.0117 - mae: 0.0725 - val_loss: 0.2062 - val_mae: 0.2663\n",
      "Epoch 88/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334ms/step - loss: 0.0183 - mae: 0.0838 - val_loss: 0.2030 - val_mae: 0.2525\n",
      "Epoch 89/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - loss: 0.0091 - mae: 0.0646 - val_loss: 0.2047 - val_mae: 0.2497\n",
      "Epoch 90/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315ms/step - loss: 0.0069 - mae: 0.0537 - val_loss: 0.2090 - val_mae: 0.2553\n",
      "Epoch 91/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 398ms/step - loss: 0.0155 - mae: 0.0741 - val_loss: 0.2132 - val_mae: 0.2565\n",
      "Epoch 92/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 358ms/step - loss: 0.0124 - mae: 0.0693 - val_loss: 0.2140 - val_mae: 0.2505\n",
      "Epoch 93/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0090 - mae: 0.0599 - val_loss: 0.2177 - val_mae: 0.2692\n",
      "Epoch 94/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 307ms/step - loss: 0.0157 - mae: 0.0771 - val_loss: 0.1997 - val_mae: 0.2626\n",
      "Epoch 95/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step - loss: 0.0150 - mae: 0.0845 - val_loss: 0.1994 - val_mae: 0.2382\n",
      "Epoch 96/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - loss: 0.0135 - mae: 0.0742 - val_loss: 0.2056 - val_mae: 0.2469\n",
      "Epoch 97/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - loss: 0.0088 - mae: 0.0628 - val_loss: 0.2085 - val_mae: 0.2501\n",
      "Epoch 98/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - loss: 0.0102 - mae: 0.0608 - val_loss: 0.2089 - val_mae: 0.2518\n",
      "Epoch 99/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - loss: 0.0162 - mae: 0.0641 - val_loss: 0.2089 - val_mae: 0.2498\n",
      "Epoch 100/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366ms/step - loss: 0.0115 - mae: 0.0595 - val_loss: 0.2093 - val_mae: 0.2514\n",
      "Epoch 101/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step - loss: 0.0087 - mae: 0.0623 - val_loss: 0.2095 - val_mae: 0.2400\n",
      "Epoch 102/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step - loss: 0.0086 - mae: 0.0558 - val_loss: 0.2090 - val_mae: 0.2431\n",
      "Epoch 103/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - loss: 0.0047 - mae: 0.0494 - val_loss: 0.2065 - val_mae: 0.2460\n",
      "Epoch 104/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 282ms/step - loss: 0.0070 - mae: 0.0567 - val_loss: 0.2048 - val_mae: 0.2443\n",
      "Epoch 105/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step - loss: 0.0054 - mae: 0.0444 - val_loss: 0.2044 - val_mae: 0.2460\n",
      "Epoch 106/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - loss: 0.0108 - mae: 0.0611 - val_loss: 0.2014 - val_mae: 0.2406\n",
      "Epoch 107/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0048 - mae: 0.0426 - val_loss: 0.1988 - val_mae: 0.2356\n",
      "Epoch 108/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - loss: 0.0087 - mae: 0.0593 - val_loss: 0.2006 - val_mae: 0.2364\n",
      "Epoch 109/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step - loss: 0.0080 - mae: 0.0544 - val_loss: 0.2024 - val_mae: 0.2405\n",
      "Epoch 110/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step - loss: 0.0106 - mae: 0.0583 - val_loss: 0.2005 - val_mae: 0.2376\n",
      "Epoch 111/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step - loss: 0.0100 - mae: 0.0568 - val_loss: 0.1983 - val_mae: 0.2350\n",
      "Epoch 112/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 0.0120 - mae: 0.0606 - val_loss: 0.2088 - val_mae: 0.2404\n",
      "Epoch 113/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308ms/step - loss: 0.0119 - mae: 0.0637 - val_loss: 0.2151 - val_mae: 0.2527\n",
      "Epoch 114/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - loss: 0.0079 - mae: 0.0559 - val_loss: 0.2169 - val_mae: 0.2566\n",
      "Epoch 115/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - loss: 0.0054 - mae: 0.0438 - val_loss: 0.2141 - val_mae: 0.2494\n",
      "Epoch 116/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294ms/step - loss: 0.0150 - mae: 0.0651 - val_loss: 0.2163 - val_mae: 0.2486\n",
      "Epoch 117/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step - loss: 0.0065 - mae: 0.0555 - val_loss: 0.2059 - val_mae: 0.2494\n",
      "Epoch 118/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292ms/step - loss: 0.0113 - mae: 0.0702 - val_loss: 0.1654 - val_mae: 0.2128\n",
      "Epoch 119/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step - loss: 0.0082 - mae: 0.0535 - val_loss: 0.1540 - val_mae: 0.2035\n",
      "Epoch 120/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - loss: 0.0086 - mae: 0.0604 - val_loss: 0.1561 - val_mae: 0.2082\n",
      "Epoch 121/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - loss: 0.0108 - mae: 0.0571 - val_loss: 0.1574 - val_mae: 0.2201\n",
      "Epoch 122/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 0.0085 - mae: 0.0596 - val_loss: 0.1514 - val_mae: 0.2162\n",
      "Epoch 123/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280ms/step - loss: 0.0058 - mae: 0.0456 - val_loss: 0.1457 - val_mae: 0.2098\n",
      "Epoch 124/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 277ms/step - loss: 0.0045 - mae: 0.0423 - val_loss: 0.1419 - val_mae: 0.2042\n",
      "Epoch 125/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 288ms/step - loss: 0.0066 - mae: 0.0512 - val_loss: 0.1390 - val_mae: 0.2000\n",
      "Epoch 126/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301ms/step - loss: 0.0067 - mae: 0.0522 - val_loss: 0.1381 - val_mae: 0.1978\n",
      "Epoch 127/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355ms/step - loss: 0.0047 - mae: 0.0401 - val_loss: 0.1452 - val_mae: 0.2036\n",
      "Epoch 128/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - loss: 0.0070 - mae: 0.0549 - val_loss: 0.1524 - val_mae: 0.2061\n",
      "Epoch 129/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341ms/step - loss: 0.0062 - mae: 0.0522 - val_loss: 0.1523 - val_mae: 0.2033\n",
      "Epoch 130/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294ms/step - loss: 0.0070 - mae: 0.0522 - val_loss: 0.1497 - val_mae: 0.1994\n",
      "Epoch 131/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322ms/step - loss: 0.0116 - mae: 0.0591 - val_loss: 0.1517 - val_mae: 0.2021\n",
      "Epoch 132/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step - loss: 0.0051 - mae: 0.0463 - val_loss: 0.1580 - val_mae: 0.2100\n",
      "Epoch 133/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291ms/step - loss: 0.0026 - mae: 0.0373 - val_loss: 0.1646 - val_mae: 0.2221\n",
      "Epoch 134/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323ms/step - loss: 0.0071 - mae: 0.0524 - val_loss: 0.1704 - val_mae: 0.2284\n",
      "Epoch 135/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339ms/step - loss: 0.0027 - mae: 0.0350 - val_loss: 0.1747 - val_mae: 0.2288\n",
      "Epoch 136/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0047 - mae: 0.0429 - val_loss: 0.1792 - val_mae: 0.2325\n",
      "Epoch 137/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313ms/step - loss: 0.0031 - mae: 0.0395 - val_loss: 0.1809 - val_mae: 0.2344\n",
      "Epoch 138/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step - loss: 0.0048 - mae: 0.0413 - val_loss: 0.1763 - val_mae: 0.2278\n",
      "Epoch 139/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 281ms/step - loss: 0.0055 - mae: 0.0486 - val_loss: 0.1697 - val_mae: 0.2197\n",
      "Epoch 140/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step - loss: 0.0069 - mae: 0.0500 - val_loss: 0.1638 - val_mae: 0.2120\n",
      "Epoch 141/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - loss: 0.0042 - mae: 0.0406 - val_loss: 0.1608 - val_mae: 0.2086\n",
      "Epoch 142/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 358ms/step - loss: 0.0058 - mae: 0.0469 - val_loss: 0.1624 - val_mae: 0.2138\n",
      "Epoch 143/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374ms/step - loss: 0.0057 - mae: 0.0431 - val_loss: 0.1662 - val_mae: 0.2192\n",
      "Epoch 144/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step - loss: 0.0040 - mae: 0.0397 - val_loss: 0.1633 - val_mae: 0.2159\n",
      "Epoch 145/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303ms/step - loss: 0.0020 - mae: 0.0301 - val_loss: 0.1584 - val_mae: 0.2092\n",
      "Epoch 146/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 284ms/step - loss: 0.0062 - mae: 0.0483 - val_loss: 0.1605 - val_mae: 0.2126\n",
      "Epoch 147/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304ms/step - loss: 0.0097 - mae: 0.0622 - val_loss: 0.1618 - val_mae: 0.2152\n",
      "Epoch 148/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313ms/step - loss: 0.0027 - mae: 0.0340 - val_loss: 0.1616 - val_mae: 0.2162\n",
      "Epoch 149/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350ms/step - loss: 0.0053 - mae: 0.0432 - val_loss: 0.1608 - val_mae: 0.2149\n",
      "Epoch 150/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - loss: 0.0027 - mae: 0.0329 - val_loss: 0.1574 - val_mae: 0.2092\n",
      "Epoch 151/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - loss: 0.0044 - mae: 0.0404 - val_loss: 0.1534 - val_mae: 0.2051\n",
      "Epoch 152/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287ms/step - loss: 0.0076 - mae: 0.0523 - val_loss: 0.1517 - val_mae: 0.2110\n",
      "Epoch 153/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 279ms/step - loss: 0.0084 - mae: 0.0571 - val_loss: 0.1459 - val_mae: 0.2025\n",
      "Epoch 154/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 282ms/step - loss: 0.0043 - mae: 0.0381 - val_loss: 0.1473 - val_mae: 0.2025\n",
      "Epoch 155/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step - loss: 0.0064 - mae: 0.0509 - val_loss: 0.1491 - val_mae: 0.2039\n",
      "Epoch 156/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - loss: 0.0081 - mae: 0.0593 - val_loss: 0.1491 - val_mae: 0.2072\n",
      "Epoch 157/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373ms/step - loss: 0.0042 - mae: 0.0419 - val_loss: 0.1475 - val_mae: 0.2045\n",
      "Epoch 158/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 347ms/step - loss: 0.0052 - mae: 0.0475 - val_loss: 0.1439 - val_mae: 0.1982\n",
      "Epoch 159/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step - loss: 0.0078 - mae: 0.0599 - val_loss: 0.1461 - val_mae: 0.2036\n",
      "Epoch 160/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287ms/step - loss: 0.0052 - mae: 0.0482 - val_loss: 0.1506 - val_mae: 0.2113\n",
      "Epoch 161/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step - loss: 0.0066 - mae: 0.0515 - val_loss: 0.1501 - val_mae: 0.2094\n",
      "Epoch 162/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 0.0067 - mae: 0.0466 - val_loss: 0.1461 - val_mae: 0.2010\n",
      "Epoch 163/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 425ms/step - loss: 0.0036 - mae: 0.0385 - val_loss: 0.1429 - val_mae: 0.1956\n",
      "Epoch 164/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 394ms/step - loss: 0.0051 - mae: 0.0435 - val_loss: 0.1447 - val_mae: 0.1978\n",
      "Epoch 165/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348ms/step - loss: 0.0063 - mae: 0.0472 - val_loss: 0.1460 - val_mae: 0.2036\n",
      "Epoch 166/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295ms/step - loss: 0.0047 - mae: 0.0497 - val_loss: 0.1461 - val_mae: 0.2035\n",
      "Epoch 167/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305ms/step - loss: 0.0058 - mae: 0.0530 - val_loss: 0.1496 - val_mae: 0.2081\n",
      "Epoch 168/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322ms/step - loss: 0.0100 - mae: 0.0555 - val_loss: 0.1591 - val_mae: 0.2180\n",
      "Epoch 169/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 415ms/step - loss: 0.0046 - mae: 0.0459 - val_loss: 0.1612 - val_mae: 0.2170\n",
      "Epoch 170/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 395ms/step - loss: 0.0024 - mae: 0.0348 - val_loss: 0.1583 - val_mae: 0.2102\n",
      "Epoch 171/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step - loss: 0.0054 - mae: 0.0440 - val_loss: 0.1541 - val_mae: 0.2057\n",
      "Epoch 172/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301ms/step - loss: 0.0061 - mae: 0.0469 - val_loss: 0.1495 - val_mae: 0.2004\n",
      "Epoch 173/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step - loss: 0.0097 - mae: 0.0607 - val_loss: 0.1448 - val_mae: 0.1962\n",
      "Epoch 174/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315ms/step - loss: 0.0083 - mae: 0.0517 - val_loss: 0.1402 - val_mae: 0.1902\n",
      "Epoch 175/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 364ms/step - loss: 0.0044 - mae: 0.0396 - val_loss: 0.1411 - val_mae: 0.1918\n",
      "Epoch 176/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - loss: 0.0042 - mae: 0.0445 - val_loss: 0.1450 - val_mae: 0.1996\n",
      "Epoch 177/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - loss: 0.0059 - mae: 0.0431 - val_loss: 0.1456 - val_mae: 0.2023\n",
      "Epoch 178/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 286ms/step - loss: 0.0041 - mae: 0.0347 - val_loss: 0.1452 - val_mae: 0.2028\n",
      "Epoch 179/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 284ms/step - loss: 0.0020 - mae: 0.0309 - val_loss: 0.1431 - val_mae: 0.1988\n",
      "Epoch 180/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - loss: 0.0035 - mae: 0.0320 - val_loss: 0.1422 - val_mae: 0.1996\n",
      "Epoch 181/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380ms/step - loss: 0.0039 - mae: 0.0437 - val_loss: 0.1414 - val_mae: 0.2021\n",
      "Epoch 182/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0037 - mae: 0.0408 - val_loss: 0.1405 - val_mae: 0.2027\n",
      "Epoch 183/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303ms/step - loss: 0.0023 - mae: 0.0323 - val_loss: 0.1379 - val_mae: 0.2000\n",
      "Epoch 184/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287ms/step - loss: 0.0041 - mae: 0.0384 - val_loss: 0.1368 - val_mae: 0.2006\n",
      "Epoch 185/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299ms/step - loss: 0.0038 - mae: 0.0412 - val_loss: 0.1334 - val_mae: 0.1948\n",
      "Epoch 186/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292ms/step - loss: 0.0037 - mae: 0.0362 - val_loss: 0.1321 - val_mae: 0.1912\n",
      "Epoch 187/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304ms/step - loss: 0.0074 - mae: 0.0421 - val_loss: 0.1377 - val_mae: 0.1958\n",
      "Epoch 188/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - loss: 0.0049 - mae: 0.0438 - val_loss: 0.1421 - val_mae: 0.2002\n",
      "Epoch 189/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0042 - mae: 0.0421 - val_loss: 0.1413 - val_mae: 0.1996\n",
      "Epoch 190/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359ms/step - loss: 0.0039 - mae: 0.0391 - val_loss: 0.1405 - val_mae: 0.1990\n",
      "Epoch 191/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - loss: 0.0039 - mae: 0.0371 - val_loss: 0.1416 - val_mae: 0.2028\n",
      "Epoch 192/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315ms/step - loss: 0.0029 - mae: 0.0315 - val_loss: 0.1379 - val_mae: 0.1984\n",
      "Epoch 193/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - loss: 0.0085 - mae: 0.0501 - val_loss: 0.1377 - val_mae: 0.1974\n",
      "Epoch 194/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 407ms/step - loss: 0.0042 - mae: 0.0395 - val_loss: 0.1351 - val_mae: 0.1916\n",
      "Epoch 195/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - loss: 0.0062 - mae: 0.0500 - val_loss: 0.1302 - val_mae: 0.1875\n",
      "Epoch 196/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378ms/step - loss: 0.0035 - mae: 0.0358 - val_loss: 0.1319 - val_mae: 0.1937\n",
      "Epoch 197/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 375ms/step - loss: 0.0085 - mae: 0.0547 - val_loss: 0.1353 - val_mae: 0.1998\n",
      "Epoch 198/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - loss: 0.0040 - mae: 0.0334 - val_loss: 0.1386 - val_mae: 0.2050\n",
      "Epoch 199/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step - loss: 0.0050 - mae: 0.0463 - val_loss: 0.1390 - val_mae: 0.2047\n",
      "Epoch 200/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353ms/step - loss: 0.0019 - mae: 0.0335 - val_loss: 0.1392 - val_mae: 0.2036\n",
      "Epoch 201/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309ms/step - loss: 0.0061 - mae: 0.0443 - val_loss: 0.1378 - val_mae: 0.2017\n",
      "Epoch 202/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372ms/step - loss: 0.0024 - mae: 0.0381 - val_loss: 0.1350 - val_mae: 0.1964\n",
      "Epoch 203/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - loss: 0.0036 - mae: 0.0359 - val_loss: 0.1329 - val_mae: 0.1917\n",
      "Epoch 204/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0028 - mae: 0.0349 - val_loss: 0.1323 - val_mae: 0.1904\n",
      "Epoch 205/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - loss: 0.0044 - mae: 0.0405 - val_loss: 0.1325 - val_mae: 0.1927\n",
      "Epoch 206/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step - loss: 0.0031 - mae: 0.0348 - val_loss: 0.1328 - val_mae: 0.1952\n",
      "Epoch 207/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 401ms/step - loss: 0.0024 - mae: 0.0308 - val_loss: 0.1331 - val_mae: 0.1973\n",
      "Epoch 208/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 454ms/step - loss: 0.0027 - mae: 0.0323 - val_loss: 0.1315 - val_mae: 0.1943\n",
      "Epoch 209/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - loss: 0.0029 - mae: 0.0351 - val_loss: 0.1301 - val_mae: 0.1916\n",
      "Epoch 210/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - loss: 0.0026 - mae: 0.0325 - val_loss: 0.1318 - val_mae: 0.1946\n",
      "Epoch 211/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - loss: 0.0019 - mae: 0.0310 - val_loss: 0.1320 - val_mae: 0.1945\n",
      "Epoch 212/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 400ms/step - loss: 0.0018 - mae: 0.0286 - val_loss: 0.1301 - val_mae: 0.1907\n",
      "Epoch 213/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step - loss: 0.0021 - mae: 0.0302 - val_loss: 0.1310 - val_mae: 0.1915\n",
      "Epoch 214/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315ms/step - loss: 0.0024 - mae: 0.0359 - val_loss: 0.1331 - val_mae: 0.1927\n",
      "Epoch 215/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - loss: 0.0026 - mae: 0.0274 - val_loss: 0.1331 - val_mae: 0.1909\n",
      "Epoch 216/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 412ms/step - loss: 0.0033 - mae: 0.0365 - val_loss: 0.1309 - val_mae: 0.1876\n",
      "Epoch 217/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 422ms/step - loss: 0.0021 - mae: 0.0287 - val_loss: 0.1316 - val_mae: 0.1914\n",
      "Epoch 218/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374ms/step - loss: 0.0034 - mae: 0.0378 - val_loss: 0.1341 - val_mae: 0.1977\n",
      "Epoch 219/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312ms/step - loss: 0.0037 - mae: 0.0331 - val_loss: 0.1310 - val_mae: 0.1933\n",
      "Epoch 220/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305ms/step - loss: 0.0031 - mae: 0.0339 - val_loss: 0.1248 - val_mae: 0.1825\n",
      "Epoch 221/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - loss: 0.0059 - mae: 0.0417 - val_loss: 0.1225 - val_mae: 0.1763\n",
      "Epoch 222/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0022 - mae: 0.0305 - val_loss: 0.1252 - val_mae: 0.1783\n",
      "Epoch 223/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - loss: 0.0022 - mae: 0.0301 - val_loss: 0.1295 - val_mae: 0.1834\n",
      "Epoch 224/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - loss: 0.0040 - mae: 0.0391 - val_loss: 0.1283 - val_mae: 0.1798\n",
      "Epoch 225/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312ms/step - loss: 0.0036 - mae: 0.0407 - val_loss: 0.1263 - val_mae: 0.1779\n",
      "Epoch 226/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - loss: 0.0035 - mae: 0.0376 - val_loss: 0.1252 - val_mae: 0.1789\n",
      "Epoch 227/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367ms/step - loss: 0.0034 - mae: 0.0316 - val_loss: 0.1279 - val_mae: 0.1854\n",
      "Epoch 228/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - loss: 0.0041 - mae: 0.0374 - val_loss: 0.1296 - val_mae: 0.1897\n",
      "Epoch 229/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - loss: 0.0029 - mae: 0.0352 - val_loss: 0.1292 - val_mae: 0.1891\n",
      "Epoch 230/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349ms/step - loss: 0.0029 - mae: 0.0378 - val_loss: 0.1288 - val_mae: 0.1869\n",
      "Epoch 231/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - loss: 0.0026 - mae: 0.0311 - val_loss: 0.1265 - val_mae: 0.1804\n",
      "Epoch 232/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 410ms/step - loss: 0.0039 - mae: 0.0307 - val_loss: 0.1263 - val_mae: 0.1758\n",
      "Epoch 233/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 360ms/step - loss: 0.0061 - mae: 0.0445 - val_loss: 0.1295 - val_mae: 0.1768\n",
      "Epoch 234/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311ms/step - loss: 0.0024 - mae: 0.0276 - val_loss: 0.1316 - val_mae: 0.1778\n",
      "Epoch 235/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step - loss: 0.0057 - mae: 0.0426 - val_loss: 0.1330 - val_mae: 0.1822\n",
      "Epoch 236/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 411ms/step - loss: 0.0039 - mae: 0.0384 - val_loss: 0.1341 - val_mae: 0.1851\n",
      "Epoch 237/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 424ms/step - loss: 0.0028 - mae: 0.0310 - val_loss: 0.1330 - val_mae: 0.1860\n",
      "Epoch 238/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 358ms/step - loss: 0.0048 - mae: 0.0373 - val_loss: 0.1297 - val_mae: 0.1844\n",
      "Epoch 239/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 0.0077 - mae: 0.0458 - val_loss: 0.1242 - val_mae: 0.1776\n",
      "Epoch 240/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 0.0034 - mae: 0.0305 - val_loss: 0.1191 - val_mae: 0.1681\n",
      "Epoch 241/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - loss: 0.0044 - mae: 0.0372 - val_loss: 0.1209 - val_mae: 0.1691\n",
      "Epoch 242/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 405ms/step - loss: 0.0057 - mae: 0.0429 - val_loss: 0.1309 - val_mae: 0.1857\n",
      "Epoch 243/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384ms/step - loss: 0.0027 - mae: 0.0345 - val_loss: 0.1377 - val_mae: 0.1953\n",
      "Epoch 244/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - loss: 0.0032 - mae: 0.0349 - val_loss: 0.1383 - val_mae: 0.1972\n",
      "Epoch 245/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394ms/step - loss: 0.0030 - mae: 0.0347 - val_loss: 0.1346 - val_mae: 0.1959\n",
      "Epoch 246/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355ms/step - loss: 0.0042 - mae: 0.0367 - val_loss: 0.1299 - val_mae: 0.1957\n",
      "Epoch 247/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353ms/step - loss: 0.0032 - mae: 0.0368 - val_loss: 0.1215 - val_mae: 0.1851\n",
      "Epoch 248/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 361ms/step - loss: 0.0026 - mae: 0.0313 - val_loss: 0.1158 - val_mae: 0.1751\n",
      "Epoch 249/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315ms/step - loss: 0.0023 - mae: 0.0280 - val_loss: 0.1129 - val_mae: 0.1688\n",
      "Epoch 250/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309ms/step - loss: 0.0055 - mae: 0.0458 - val_loss: 0.1133 - val_mae: 0.1652\n",
      "Epoch 251/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291ms/step - loss: 0.0030 - mae: 0.0318 - val_loss: 0.1136 - val_mae: 0.1643\n",
      "Epoch 252/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step - loss: 0.0029 - mae: 0.0350 - val_loss: 0.1148 - val_mae: 0.1685\n",
      "Epoch 253/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314ms/step - loss: 0.0022 - mae: 0.0275 - val_loss: 0.1159 - val_mae: 0.1710\n",
      "Epoch 254/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374ms/step - loss: 0.0031 - mae: 0.0344 - val_loss: 0.1160 - val_mae: 0.1706\n",
      "Epoch 255/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368ms/step - loss: 0.0025 - mae: 0.0285 - val_loss: 0.1175 - val_mae: 0.1739\n",
      "Epoch 256/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289ms/step - loss: 0.0035 - mae: 0.0359 - val_loss: 0.1208 - val_mae: 0.1780\n",
      "Epoch 257/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312ms/step - loss: 0.0041 - mae: 0.0361 - val_loss: 0.1211 - val_mae: 0.1756\n",
      "Epoch 258/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 282ms/step - loss: 0.0028 - mae: 0.0333 - val_loss: 0.1200 - val_mae: 0.1745\n",
      "Epoch 259/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371ms/step - loss: 0.0034 - mae: 0.0340 - val_loss: 0.1216 - val_mae: 0.1809\n",
      "Epoch 260/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 414ms/step - loss: 0.0027 - mae: 0.0325 - val_loss: 0.1248 - val_mae: 0.1879\n",
      "Epoch 261/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339ms/step - loss: 0.0042 - mae: 0.0373 - val_loss: 0.1246 - val_mae: 0.1895\n",
      "Epoch 262/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364ms/step - loss: 0.0036 - mae: 0.0355 - val_loss: 0.1193 - val_mae: 0.1801\n",
      "Epoch 263/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step - loss: 0.0022 - mae: 0.0305 - val_loss: 0.1155 - val_mae: 0.1714\n",
      "Epoch 264/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 387ms/step - loss: 0.0034 - mae: 0.0387 - val_loss: 0.1143 - val_mae: 0.1688\n",
      "Epoch 265/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371ms/step - loss: 0.0028 - mae: 0.0282 - val_loss: 0.1120 - val_mae: 0.1658\n",
      "Epoch 266/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338ms/step - loss: 0.0031 - mae: 0.0338 - val_loss: 0.1121 - val_mae: 0.1704\n",
      "Epoch 267/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - loss: 0.0022 - mae: 0.0286 - val_loss: 0.1125 - val_mae: 0.1740\n",
      "Epoch 268/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373ms/step - loss: 0.0027 - mae: 0.0303 - val_loss: 0.1130 - val_mae: 0.1766\n",
      "Epoch 269/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - loss: 0.0017 - mae: 0.0268 - val_loss: 0.1129 - val_mae: 0.1762\n",
      "Epoch 270/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 362ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.1132 - val_mae: 0.1762\n",
      "Epoch 271/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - loss: 0.0060 - mae: 0.0421 - val_loss: 0.1112 - val_mae: 0.1690\n",
      "Epoch 272/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - loss: 0.0017 - mae: 0.0260 - val_loss: 0.1100 - val_mae: 0.1652\n",
      "Epoch 273/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - loss: 0.0017 - mae: 0.0303 - val_loss: 0.1099 - val_mae: 0.1657\n",
      "Epoch 274/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 0.1105 - val_mae: 0.1680\n",
      "Epoch 275/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 0.0029 - mae: 0.0304 - val_loss: 0.1097 - val_mae: 0.1672\n",
      "Epoch 276/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - loss: 0.0021 - mae: 0.0293 - val_loss: 0.1085 - val_mae: 0.1654\n",
      "Epoch 277/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353ms/step - loss: 0.0031 - mae: 0.0290 - val_loss: 0.1080 - val_mae: 0.1643\n",
      "Epoch 278/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349ms/step - loss: 0.0013 - mae: 0.0230 - val_loss: 0.1070 - val_mae: 0.1630\n",
      "Epoch 279/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 0.1073 - val_mae: 0.1654\n",
      "Epoch 280/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - loss: 0.0013 - mae: 0.0227 - val_loss: 0.1075 - val_mae: 0.1669\n",
      "Epoch 281/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 0.0018 - mae: 0.0230 - val_loss: 0.1083 - val_mae: 0.1700\n",
      "Epoch 282/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - loss: 0.0024 - mae: 0.0300 - val_loss: 0.1073 - val_mae: 0.1681\n",
      "Epoch 283/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - loss: 0.0012 - mae: 0.0257 - val_loss: 0.1059 - val_mae: 0.1650\n",
      "Epoch 284/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 412ms/step - loss: 0.0014 - mae: 0.0266 - val_loss: 0.1038 - val_mae: 0.1583\n",
      "Epoch 285/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356ms/step - loss: 0.0027 - mae: 0.0297 - val_loss: 0.1036 - val_mae: 0.1570\n",
      "Epoch 286/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step - loss: 8.8765e-04 - mae: 0.0197 - val_loss: 0.1051 - val_mae: 0.1610\n",
      "Epoch 287/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - loss: 0.0018 - mae: 0.0253 - val_loss: 0.1060 - val_mae: 0.1628\n",
      "Epoch 288/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375ms/step - loss: 0.0019 - mae: 0.0276 - val_loss: 0.1061 - val_mae: 0.1633\n",
      "Epoch 289/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 397ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.1051 - val_mae: 0.1612\n",
      "Epoch 290/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - loss: 0.0018 - mae: 0.0271 - val_loss: 0.1038 - val_mae: 0.1572\n",
      "Epoch 291/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - loss: 0.0014 - mae: 0.0242 - val_loss: 0.1037 - val_mae: 0.1549\n",
      "Epoch 292/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - loss: 0.0026 - mae: 0.0289 - val_loss: 0.1049 - val_mae: 0.1580\n",
      "Epoch 293/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 363ms/step - loss: 0.0027 - mae: 0.0352 - val_loss: 0.1046 - val_mae: 0.1583\n",
      "Epoch 294/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - loss: 0.0026 - mae: 0.0321 - val_loss: 0.1030 - val_mae: 0.1577\n",
      "Epoch 295/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311ms/step - loss: 0.0039 - mae: 0.0370 - val_loss: 0.1024 - val_mae: 0.1574\n",
      "Epoch 296/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 0.0037 - mae: 0.0322 - val_loss: 0.1026 - val_mae: 0.1576\n",
      "Epoch 297/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - loss: 0.0031 - mae: 0.0308 - val_loss: 0.1023 - val_mae: 0.1579\n",
      "Epoch 298/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - loss: 0.0028 - mae: 0.0320 - val_loss: 0.1017 - val_mae: 0.1579\n",
      "Epoch 299/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 0.1020 - val_mae: 0.1589\n",
      "Epoch 300/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 385ms/step - loss: 0.0033 - mae: 0.0330 - val_loss: 0.1027 - val_mae: 0.1570\n",
      "Epoch 301/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318ms/step - loss: 0.0012 - mae: 0.0242 - val_loss: 0.1045 - val_mae: 0.1598\n",
      "Epoch 302/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 282ms/step - loss: 0.0016 - mae: 0.0269 - val_loss: 0.1057 - val_mae: 0.1647\n",
      "Epoch 303/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - loss: 0.0022 - mae: 0.0284 - val_loss: 0.1064 - val_mae: 0.1679\n",
      "Epoch 304/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - loss: 0.0023 - mae: 0.0299 - val_loss: 0.1061 - val_mae: 0.1659\n",
      "Epoch 305/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0010 - mae: 0.0231 - val_loss: 0.1053 - val_mae: 0.1613\n",
      "Epoch 306/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - loss: 0.0032 - mae: 0.0315 - val_loss: 0.1049 - val_mae: 0.1586\n",
      "Epoch 307/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 0.1048 - val_mae: 0.1623\n",
      "Epoch 308/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314ms/step - loss: 0.0024 - mae: 0.0312 - val_loss: 0.1035 - val_mae: 0.1630\n",
      "Epoch 309/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0042 - mae: 0.0424 - val_loss: 0.1027 - val_mae: 0.1638\n",
      "Epoch 310/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367ms/step - loss: 0.0015 - mae: 0.0234 - val_loss: 0.1041 - val_mae: 0.1656\n",
      "Epoch 311/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - loss: 0.0033 - mae: 0.0330 - val_loss: 0.1041 - val_mae: 0.1616\n",
      "Epoch 312/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - loss: 0.0024 - mae: 0.0312 - val_loss: 0.1051 - val_mae: 0.1561\n",
      "Epoch 313/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - loss: 0.0015 - mae: 0.0236 - val_loss: 0.1058 - val_mae: 0.1494\n",
      "Epoch 314/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step - loss: 0.0020 - mae: 0.0304 - val_loss: 0.1095 - val_mae: 0.1550\n",
      "Epoch 315/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292ms/step - loss: 0.0025 - mae: 0.0316 - val_loss: 0.1187 - val_mae: 0.1694\n",
      "Epoch 316/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294ms/step - loss: 0.0013 - mae: 0.0230 - val_loss: 0.1334 - val_mae: 0.1853\n",
      "Epoch 317/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.1488 - val_mae: 0.1953\n",
      "Epoch 318/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - loss: 0.0021 - mae: 0.0290 - val_loss: 0.1594 - val_mae: 0.2020\n",
      "Epoch 319/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308ms/step - loss: 0.0028 - mae: 0.0345 - val_loss: 0.1682 - val_mae: 0.2080\n",
      "Epoch 320/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278ms/step - loss: 0.0026 - mae: 0.0279 - val_loss: 0.1695 - val_mae: 0.2076\n",
      "Epoch 321/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step - loss: 0.0014 - mae: 0.0238 - val_loss: 0.1714 - val_mae: 0.2085\n",
      "Epoch 322/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295ms/step - loss: 0.0013 - mae: 0.0208 - val_loss: 0.1731 - val_mae: 0.2104\n",
      "Epoch 323/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293ms/step - loss: 0.0017 - mae: 0.0266 - val_loss: 0.1747 - val_mae: 0.2109\n",
      "Epoch 324/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334ms/step - loss: 0.0020 - mae: 0.0275 - val_loss: 0.1769 - val_mae: 0.2129\n",
      "Epoch 325/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364ms/step - loss: 0.0020 - mae: 0.0260 - val_loss: 0.1791 - val_mae: 0.2151\n",
      "Epoch 326/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - loss: 0.0019 - mae: 0.0252 - val_loss: 0.1789 - val_mae: 0.2145\n",
      "Epoch 327/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305ms/step - loss: 0.0022 - mae: 0.0283 - val_loss: 0.1731 - val_mae: 0.2064\n",
      "Epoch 328/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293ms/step - loss: 0.0029 - mae: 0.0332 - val_loss: 0.1641 - val_mae: 0.1979\n",
      "Epoch 329/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294ms/step - loss: 0.0024 - mae: 0.0266 - val_loss: 0.1640 - val_mae: 0.2002\n",
      "Epoch 330/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299ms/step - loss: 0.0019 - mae: 0.0270 - val_loss: 0.1619 - val_mae: 0.2009\n",
      "Epoch 331/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 0.0018 - mae: 0.0273 - val_loss: 0.1625 - val_mae: 0.2028\n",
      "Epoch 332/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - loss: 7.8067e-04 - mae: 0.0193 - val_loss: 0.1656 - val_mae: 0.2070\n",
      "Epoch 333/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - loss: 0.0032 - mae: 0.0330 - val_loss: 0.1643 - val_mae: 0.2076\n",
      "Epoch 334/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272ms/step - loss: 0.0024 - mae: 0.0272 - val_loss: 0.1610 - val_mae: 0.2017\n",
      "Epoch 335/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - loss: 0.0012 - mae: 0.0202 - val_loss: 0.1606 - val_mae: 0.1990\n",
      "Epoch 336/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step - loss: 0.0028 - mae: 0.0310 - val_loss: 0.1678 - val_mae: 0.2068\n",
      "Epoch 337/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 282ms/step - loss: 0.0013 - mae: 0.0223 - val_loss: 0.1706 - val_mae: 0.2116\n",
      "Epoch 338/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - loss: 0.0020 - mae: 0.0275 - val_loss: 0.1686 - val_mae: 0.2106\n",
      "Epoch 339/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - loss: 0.0017 - mae: 0.0253 - val_loss: 0.1667 - val_mae: 0.2082\n",
      "Epoch 340/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - loss: 0.0019 - mae: 0.0263 - val_loss: 0.1664 - val_mae: 0.2063\n",
      "Epoch 341/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - loss: 0.0029 - mae: 0.0292 - val_loss: 0.1688 - val_mae: 0.2084\n",
      "Epoch 342/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293ms/step - loss: 0.0016 - mae: 0.0250 - val_loss: 0.1729 - val_mae: 0.2132\n",
      "Epoch 343/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305ms/step - loss: 0.0015 - mae: 0.0244 - val_loss: 0.1827 - val_mae: 0.2226\n",
      "Epoch 344/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - loss: 0.0021 - mae: 0.0272 - val_loss: 0.1882 - val_mae: 0.2272\n",
      "Epoch 345/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0029 - mae: 0.0285 - val_loss: 0.1899 - val_mae: 0.2273\n",
      "Epoch 346/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - loss: 0.0025 - mae: 0.0311 - val_loss: 0.1901 - val_mae: 0.2226\n",
      "Epoch 347/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 358ms/step - loss: 8.2181e-04 - mae: 0.0195 - val_loss: 0.1890 - val_mae: 0.2192\n",
      "Epoch 348/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364ms/step - loss: 0.0021 - mae: 0.0262 - val_loss: 0.1882 - val_mae: 0.2190\n",
      "Epoch 349/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280ms/step - loss: 0.0028 - mae: 0.0318 - val_loss: 0.1668 - val_mae: 0.2103\n",
      "Epoch 350/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step - loss: 0.0020 - mae: 0.0252 - val_loss: 0.1376 - val_mae: 0.1911\n",
      "Epoch 351/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278ms/step - loss: 0.0021 - mae: 0.0250 - val_loss: 0.1238 - val_mae: 0.1799\n",
      "Epoch 352/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 307ms/step - loss: 0.0013 - mae: 0.0252 - val_loss: 0.1185 - val_mae: 0.1746\n",
      "Epoch 353/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 423ms/step - loss: 0.0015 - mae: 0.0226 - val_loss: 0.1133 - val_mae: 0.1696\n",
      "Epoch 354/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0016 - mae: 0.0247 - val_loss: 0.1091 - val_mae: 0.1634\n",
      "Epoch 355/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 282ms/step - loss: 0.0013 - mae: 0.0235 - val_loss: 0.1079 - val_mae: 0.1623\n",
      "Epoch 356/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - loss: 0.0014 - mae: 0.0236 - val_loss: 0.1079 - val_mae: 0.1651\n",
      "Epoch 357/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step - loss: 0.0014 - mae: 0.0235 - val_loss: 0.1079 - val_mae: 0.1678\n",
      "Epoch 358/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287ms/step - loss: 0.0012 - mae: 0.0241 - val_loss: 0.1077 - val_mae: 0.1684\n",
      "Epoch 359/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - loss: 0.0013 - mae: 0.0230 - val_loss: 0.1066 - val_mae: 0.1647\n",
      "Epoch 360/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - loss: 0.0018 - mae: 0.0264 - val_loss: 0.1047 - val_mae: 0.1541\n",
      "Epoch 361/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368ms/step - loss: 0.0015 - mae: 0.0244 - val_loss: 0.1040 - val_mae: 0.1493\n",
      "Epoch 362/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 358ms/step - loss: 0.0016 - mae: 0.0234 - val_loss: 0.1045 - val_mae: 0.1517\n",
      "Epoch 363/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step - loss: 0.0021 - mae: 0.0275 - val_loss: 0.1057 - val_mae: 0.1530\n",
      "Epoch 364/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366ms/step - loss: 0.0013 - mae: 0.0252 - val_loss: 0.1070 - val_mae: 0.1531\n",
      "Epoch 365/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 417ms/step - loss: 0.0012 - mae: 0.0216 - val_loss: 0.1089 - val_mae: 0.1561\n",
      "Epoch 366/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 361ms/step - loss: 0.0012 - mae: 0.0222 - val_loss: 0.1102 - val_mae: 0.1596\n",
      "Epoch 367/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - loss: 0.0019 - mae: 0.0283 - val_loss: 0.1113 - val_mae: 0.1607\n",
      "Epoch 368/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305ms/step - loss: 0.0016 - mae: 0.0246 - val_loss: 0.1118 - val_mae: 0.1599\n",
      "Epoch 369/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 0.1119 - val_mae: 0.1616\n",
      "Epoch 370/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 0.1128 - val_mae: 0.1646\n",
      "Epoch 371/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - loss: 0.0026 - mae: 0.0302 - val_loss: 0.1119 - val_mae: 0.1650\n",
      "Epoch 372/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348ms/step - loss: 0.0016 - mae: 0.0252 - val_loss: 0.1087 - val_mae: 0.1617\n",
      "Epoch 373/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 0.1067 - val_mae: 0.1606\n",
      "Epoch 374/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 0.1053 - val_mae: 0.1624\n",
      "Epoch 375/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step - loss: 0.0040 - mae: 0.0375 - val_loss: 0.1050 - val_mae: 0.1649\n",
      "Epoch 376/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 307ms/step - loss: 0.0018 - mae: 0.0229 - val_loss: 0.1041 - val_mae: 0.1633\n",
      "Epoch 377/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - loss: 0.0011 - mae: 0.0204 - val_loss: 0.1030 - val_mae: 0.1585\n",
      "Epoch 378/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 0.0024 - mae: 0.0270 - val_loss: 0.1020 - val_mae: 0.1540\n",
      "Epoch 379/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368ms/step - loss: 0.0026 - mae: 0.0287 - val_loss: 0.1012 - val_mae: 0.1517\n",
      "Epoch 380/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 307ms/step - loss: 0.0019 - mae: 0.0288 - val_loss: 0.1011 - val_mae: 0.1498\n",
      "Epoch 381/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287ms/step - loss: 0.0023 - mae: 0.0286 - val_loss: 0.1001 - val_mae: 0.1498\n",
      "Epoch 382/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - loss: 0.0023 - mae: 0.0258 - val_loss: 0.1003 - val_mae: 0.1552\n",
      "Epoch 383/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step - loss: 0.0026 - mae: 0.0302 - val_loss: 0.1003 - val_mae: 0.1570\n",
      "Epoch 384/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 432ms/step - loss: 0.0022 - mae: 0.0290 - val_loss: 0.1004 - val_mae: 0.1549\n",
      "Epoch 385/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 0.1003 - val_mae: 0.1497\n",
      "Epoch 386/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349ms/step - loss: 9.6060e-04 - mae: 0.0217 - val_loss: 0.1012 - val_mae: 0.1465\n",
      "Epoch 387/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - loss: 8.7819e-04 - mae: 0.0194 - val_loss: 0.1016 - val_mae: 0.1471\n",
      "Epoch 388/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382ms/step - loss: 0.0012 - mae: 0.0214 - val_loss: 0.1011 - val_mae: 0.1513\n",
      "Epoch 389/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369ms/step - loss: 0.0019 - mae: 0.0232 - val_loss: 0.1019 - val_mae: 0.1541\n",
      "Epoch 390/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - loss: 9.5655e-04 - mae: 0.0191 - val_loss: 0.1027 - val_mae: 0.1551\n",
      "Epoch 391/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322ms/step - loss: 0.0011 - mae: 0.0213 - val_loss: 0.1033 - val_mae: 0.1548\n",
      "Epoch 392/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - loss: 0.0017 - mae: 0.0236 - val_loss: 0.1020 - val_mae: 0.1518\n",
      "Epoch 393/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370ms/step - loss: 7.8426e-04 - mae: 0.0181 - val_loss: 0.1001 - val_mae: 0.1489\n",
      "Epoch 394/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step - loss: 0.0017 - mae: 0.0228 - val_loss: 0.0990 - val_mae: 0.1481\n",
      "Epoch 395/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 0.0022 - mae: 0.0299 - val_loss: 0.1001 - val_mae: 0.1487\n",
      "Epoch 396/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - loss: 0.0011 - mae: 0.0203 - val_loss: 0.1017 - val_mae: 0.1515\n",
      "Epoch 397/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366ms/step - loss: 0.0025 - mae: 0.0325 - val_loss: 0.1011 - val_mae: 0.1498\n",
      "Epoch 398/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 398ms/step - loss: 0.0016 - mae: 0.0240 - val_loss: 0.1007 - val_mae: 0.1503\n",
      "Epoch 399/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 385ms/step - loss: 0.0016 - mae: 0.0239 - val_loss: 0.0997 - val_mae: 0.1494\n",
      "Epoch 400/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step - loss: 0.0028 - mae: 0.0336 - val_loss: 0.1002 - val_mae: 0.1500\n",
      "Epoch 401/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - loss: 0.0014 - mae: 0.0225 - val_loss: 0.1004 - val_mae: 0.1499\n",
      "Epoch 402/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - loss: 7.2146e-04 - mae: 0.0154 - val_loss: 0.1001 - val_mae: 0.1510\n",
      "Epoch 403/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 361ms/step - loss: 7.3259e-04 - mae: 0.0156 - val_loss: 0.1007 - val_mae: 0.1583\n",
      "Epoch 404/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - loss: 0.0014 - mae: 0.0242 - val_loss: 0.1017 - val_mae: 0.1630\n",
      "Epoch 405/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 7.4857e-04 - mae: 0.0165 - val_loss: 0.1021 - val_mae: 0.1644\n",
      "Epoch 406/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - loss: 0.0022 - mae: 0.0262 - val_loss: 0.1004 - val_mae: 0.1595\n",
      "Epoch 407/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 389ms/step - loss: 8.7103e-04 - mae: 0.0192 - val_loss: 0.0998 - val_mae: 0.1535\n",
      "Epoch 408/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370ms/step - loss: 0.0026 - mae: 0.0263 - val_loss: 0.1002 - val_mae: 0.1501\n",
      "Epoch 409/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 283ms/step - loss: 0.0015 - mae: 0.0242 - val_loss: 0.0998 - val_mae: 0.1505\n",
      "Epoch 410/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - loss: 0.0018 - mae: 0.0215 - val_loss: 0.0997 - val_mae: 0.1530\n",
      "Epoch 411/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - loss: 0.0013 - mae: 0.0211 - val_loss: 0.0993 - val_mae: 0.1551\n",
      "Epoch 412/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 7.3269e-04 - mae: 0.0183 - val_loss: 0.0995 - val_mae: 0.1557\n",
      "Epoch 413/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355ms/step - loss: 0.0017 - mae: 0.0223 - val_loss: 0.0998 - val_mae: 0.1555\n",
      "Epoch 414/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 0.1001 - val_mae: 0.1536\n",
      "Epoch 415/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321ms/step - loss: 0.0019 - mae: 0.0278 - val_loss: 0.1001 - val_mae: 0.1502\n",
      "Epoch 416/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - loss: 0.0013 - mae: 0.0210 - val_loss: 0.0998 - val_mae: 0.1490\n",
      "Epoch 417/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - loss: 9.2702e-04 - mae: 0.0210 - val_loss: 0.1003 - val_mae: 0.1517\n",
      "Epoch 418/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - loss: 0.0026 - mae: 0.0286 - val_loss: 0.1017 - val_mae: 0.1536\n",
      "Epoch 419/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - loss: 9.6965e-04 - mae: 0.0201 - val_loss: 0.1014 - val_mae: 0.1525\n",
      "Epoch 420/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - loss: 9.6290e-04 - mae: 0.0194 - val_loss: 0.1013 - val_mae: 0.1537\n",
      "Epoch 421/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - loss: 0.0013 - mae: 0.0219 - val_loss: 0.1025 - val_mae: 0.1614\n",
      "Epoch 422/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377ms/step - loss: 7.2359e-04 - mae: 0.0173 - val_loss: 0.1044 - val_mae: 0.1664\n",
      "Epoch 423/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - loss: 0.0014 - mae: 0.0230 - val_loss: 0.1039 - val_mae: 0.1648\n",
      "Epoch 424/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 354ms/step - loss: 0.0018 - mae: 0.0234 - val_loss: 0.1022 - val_mae: 0.1585\n",
      "Epoch 425/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359ms/step - loss: 6.0426e-04 - mae: 0.0160 - val_loss: 0.1021 - val_mae: 0.1554\n",
      "Epoch 426/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 0.1031 - val_mae: 0.1587\n",
      "Epoch 427/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 401ms/step - loss: 0.0022 - mae: 0.0260 - val_loss: 0.1023 - val_mae: 0.1591\n",
      "Epoch 428/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - loss: 0.0011 - mae: 0.0188 - val_loss: 0.1020 - val_mae: 0.1615\n",
      "Epoch 429/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - loss: 0.0027 - mae: 0.0309 - val_loss: 0.1002 - val_mae: 0.1563\n",
      "Epoch 430/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322ms/step - loss: 9.6712e-04 - mae: 0.0239 - val_loss: 0.0995 - val_mae: 0.1511\n",
      "Epoch 431/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 423ms/step - loss: 0.0011 - mae: 0.0199 - val_loss: 0.0993 - val_mae: 0.1493\n",
      "Epoch 432/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386ms/step - loss: 0.0011 - mae: 0.0210 - val_loss: 0.0993 - val_mae: 0.1490\n",
      "Epoch 433/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 363ms/step - loss: 6.1851e-04 - mae: 0.0145 - val_loss: 0.0991 - val_mae: 0.1503\n",
      "Epoch 434/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - loss: 0.0015 - mae: 0.0235 - val_loss: 0.0990 - val_mae: 0.1513\n",
      "Epoch 435/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - loss: 0.0016 - mae: 0.0228 - val_loss: 0.0994 - val_mae: 0.1503\n",
      "Epoch 436/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378ms/step - loss: 0.0016 - mae: 0.0246 - val_loss: 0.1005 - val_mae: 0.1508\n",
      "Epoch 437/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - loss: 0.0015 - mae: 0.0227 - val_loss: 0.1023 - val_mae: 0.1549\n",
      "Epoch 438/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0020 - mae: 0.0250 - val_loss: 0.1079 - val_mae: 0.1662\n",
      "Epoch 439/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291ms/step - loss: 0.0014 - mae: 0.0210 - val_loss: 0.1138 - val_mae: 0.1737\n",
      "Epoch 440/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315ms/step - loss: 7.3558e-04 - mae: 0.0162 - val_loss: 0.1214 - val_mae: 0.1815\n",
      "Epoch 441/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 405ms/step - loss: 0.0013 - mae: 0.0204 - val_loss: 0.1271 - val_mae: 0.1853\n",
      "Epoch 442/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 0.0014 - mae: 0.0204 - val_loss: 0.1208 - val_mae: 0.1775\n",
      "Epoch 443/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 360ms/step - loss: 0.0010 - mae: 0.0196 - val_loss: 0.1202 - val_mae: 0.1794\n",
      "Epoch 444/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348ms/step - loss: 0.0023 - mae: 0.0301 - val_loss: 0.1190 - val_mae: 0.1798\n",
      "Epoch 445/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334ms/step - loss: 0.0019 - mae: 0.0241 - val_loss: 0.1183 - val_mae: 0.1786\n",
      "Epoch 446/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 402ms/step - loss: 6.5443e-04 - mae: 0.0152 - val_loss: 0.1118 - val_mae: 0.1708\n",
      "Epoch 447/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 388ms/step - loss: 0.0020 - mae: 0.0241 - val_loss: 0.1025 - val_mae: 0.1556\n",
      "Epoch 448/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 404ms/step - loss: 0.0016 - mae: 0.0236 - val_loss: 0.0986 - val_mae: 0.1477\n",
      "Epoch 449/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - loss: 0.0021 - mae: 0.0291 - val_loss: 0.0967 - val_mae: 0.1443\n",
      "Epoch 450/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - loss: 0.0016 - mae: 0.0231 - val_loss: 0.0959 - val_mae: 0.1456\n",
      "Epoch 451/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - loss: 0.0013 - mae: 0.0216 - val_loss: 0.0961 - val_mae: 0.1454\n",
      "Epoch 452/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373ms/step - loss: 0.0021 - mae: 0.0278 - val_loss: 0.0962 - val_mae: 0.1393\n",
      "Epoch 453/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - loss: 0.0017 - mae: 0.0236 - val_loss: 0.0961 - val_mae: 0.1378\n",
      "Epoch 454/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368ms/step - loss: 0.0018 - mae: 0.0265 - val_loss: 0.0957 - val_mae: 0.1430\n",
      "Epoch 455/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - loss: 8.8178e-04 - mae: 0.0185 - val_loss: 0.0964 - val_mae: 0.1475\n",
      "Epoch 456/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - loss: 0.0014 - mae: 0.0222 - val_loss: 0.0969 - val_mae: 0.1465\n",
      "Epoch 457/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 5.6343e-04 - mae: 0.0167 - val_loss: 0.0973 - val_mae: 0.1451\n",
      "Epoch 458/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313ms/step - loss: 9.2339e-04 - mae: 0.0182 - val_loss: 0.0978 - val_mae: 0.1432\n",
      "Epoch 459/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359ms/step - loss: 0.0010 - mae: 0.0204 - val_loss: 0.0982 - val_mae: 0.1443\n",
      "Epoch 460/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - loss: 4.8824e-04 - mae: 0.0140 - val_loss: 0.0979 - val_mae: 0.1450\n",
      "Epoch 461/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 402ms/step - loss: 0.0013 - mae: 0.0201 - val_loss: 0.0979 - val_mae: 0.1476\n",
      "Epoch 462/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 378ms/step - loss: 9.7410e-04 - mae: 0.0183 - val_loss: 0.0978 - val_mae: 0.1489\n",
      "Epoch 463/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - loss: 0.0014 - mae: 0.0217 - val_loss: 0.0971 - val_mae: 0.1470\n",
      "Epoch 464/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - loss: 0.0018 - mae: 0.0254 - val_loss: 0.0964 - val_mae: 0.1462\n",
      "Epoch 465/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 397ms/step - loss: 0.0013 - mae: 0.0219 - val_loss: 0.0962 - val_mae: 0.1459\n",
      "Epoch 466/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - loss: 0.0015 - mae: 0.0237 - val_loss: 0.0958 - val_mae: 0.1435\n",
      "Epoch 467/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step - loss: 0.0017 - mae: 0.0246 - val_loss: 0.0949 - val_mae: 0.1440\n",
      "Epoch 468/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - loss: 3.4324e-04 - mae: 0.0122 - val_loss: 0.0942 - val_mae: 0.1425\n",
      "Epoch 469/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291ms/step - loss: 0.0015 - mae: 0.0225 - val_loss: 0.0937 - val_mae: 0.1414\n",
      "Epoch 470/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334ms/step - loss: 9.8226e-04 - mae: 0.0186 - val_loss: 0.0935 - val_mae: 0.1411\n",
      "Epoch 471/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364ms/step - loss: 6.4798e-04 - mae: 0.0175 - val_loss: 0.0932 - val_mae: 0.1390\n",
      "Epoch 472/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312ms/step - loss: 0.0014 - mae: 0.0238 - val_loss: 0.0938 - val_mae: 0.1422\n",
      "Epoch 473/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step - loss: 5.0697e-04 - mae: 0.0159 - val_loss: 0.0945 - val_mae: 0.1473\n",
      "Epoch 474/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301ms/step - loss: 7.7157e-04 - mae: 0.0158 - val_loss: 0.0953 - val_mae: 0.1504\n",
      "Epoch 475/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313ms/step - loss: 0.0017 - mae: 0.0222 - val_loss: 0.0955 - val_mae: 0.1505\n",
      "Epoch 476/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301ms/step - loss: 0.0020 - mae: 0.0258 - val_loss: 0.0949 - val_mae: 0.1455\n",
      "Epoch 477/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step - loss: 7.2074e-04 - mae: 0.0180 - val_loss: 0.0948 - val_mae: 0.1428\n",
      "Epoch 478/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - loss: 5.2852e-04 - mae: 0.0129 - val_loss: 0.0947 - val_mae: 0.1443\n",
      "Epoch 479/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308ms/step - loss: 8.4183e-04 - mae: 0.0175 - val_loss: 0.0952 - val_mae: 0.1441\n",
      "Epoch 480/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287ms/step - loss: 0.0012 - mae: 0.0216 - val_loss: 0.0959 - val_mae: 0.1464\n",
      "Epoch 481/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 8.1546e-04 - mae: 0.0178 - val_loss: 0.0968 - val_mae: 0.1488\n",
      "Epoch 482/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309ms/step - loss: 0.0015 - mae: 0.0221 - val_loss: 0.0975 - val_mae: 0.1495\n",
      "Epoch 483/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291ms/step - loss: 8.6197e-04 - mae: 0.0194 - val_loss: 0.0981 - val_mae: 0.1494\n",
      "Epoch 484/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - loss: 0.0014 - mae: 0.0239 - val_loss: 0.0986 - val_mae: 0.1492\n",
      "Epoch 485/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 8.5415e-04 - mae: 0.0167 - val_loss: 0.0989 - val_mae: 0.1484\n",
      "Epoch 486/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 425ms/step - loss: 0.0011 - mae: 0.0189 - val_loss: 0.1001 - val_mae: 0.1516\n",
      "Epoch 487/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314ms/step - loss: 0.0014 - mae: 0.0196 - val_loss: 0.1034 - val_mae: 0.1590\n",
      "Epoch 488/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - loss: 9.2009e-04 - mae: 0.0175 - val_loss: 0.1039 - val_mae: 0.1600\n",
      "Epoch 489/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 412ms/step - loss: 9.9125e-04 - mae: 0.0172 - val_loss: 0.1011 - val_mae: 0.1584\n",
      "Epoch 490/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 411ms/step - loss: 0.0010 - mae: 0.0174 - val_loss: 0.0991 - val_mae: 0.1523\n",
      "Epoch 491/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 400ms/step - loss: 0.0015 - mae: 0.0234 - val_loss: 0.0985 - val_mae: 0.1485\n",
      "Epoch 492/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 358ms/step - loss: 9.1997e-04 - mae: 0.0175 - val_loss: 0.0985 - val_mae: 0.1482\n",
      "Epoch 493/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - loss: 5.3517e-04 - mae: 0.0142 - val_loss: 0.0988 - val_mae: 0.1509\n",
      "Epoch 494/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 435ms/step - loss: 8.2837e-04 - mae: 0.0188 - val_loss: 0.0991 - val_mae: 0.1532\n",
      "Epoch 495/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 401ms/step - loss: 7.2968e-04 - mae: 0.0177 - val_loss: 0.0989 - val_mae: 0.1522\n",
      "Epoch 496/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 0.0011 - mae: 0.0200 - val_loss: 0.0992 - val_mae: 0.1529\n",
      "Epoch 497/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 288ms/step - loss: 0.0012 - mae: 0.0202 - val_loss: 0.0995 - val_mae: 0.1515\n",
      "Epoch 498/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - loss: 9.0165e-04 - mae: 0.0180 - val_loss: 0.0991 - val_mae: 0.1481\n",
      "Epoch 499/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304ms/step - loss: 0.0016 - mae: 0.0247 - val_loss: 0.0990 - val_mae: 0.1464\n",
      "Epoch 500/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - loss: 0.0014 - mae: 0.0224 - val_loss: 0.0982 - val_mae: 0.1470\n"
     ]
    }
   ],
   "source": [
    "# Train the LSTM model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=500,  # You can adjust based on convergence\n",
    "    batch_size=16,  # Smaller batch size for augmented data\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0982, Validation MAE: 0.1470\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_mae = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation MAE: {val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "Predicted: 0.00, Actual: 0.00\n",
      "Predicted: 0.02, Actual: 0.00\n",
      "Predicted: 0.71, Actual: 1.00\n",
      "Predicted: 0.00, Actual: 0.00\n",
      "Predicted: 0.00, Actual: 0.00\n",
      "Predicted: 0.01, Actual: 0.00\n",
      "Predicted: 0.86, Actual: 1.00\n",
      "Predicted: 0.00, Actual: 0.00\n",
      "Predicted: -0.00, Actual: 0.00\n",
      "Predicted: 0.66, Actual: 1.00\n",
      "Predicted: 0.01, Actual: 0.00\n",
      "Predicted: 0.00, Actual: 0.00\n",
      "Predicted: 0.80, Actual: 0.00\n",
      "Predicted: 0.01, Actual: 0.00\n",
      "Predicted: 0.00, Actual: 0.00\n",
      "Predicted: 0.01, Actual: 0.00\n",
      "Predicted: 0.00, Actual: 0.00\n",
      "Predicted: 0.01, Actual: 1.00\n",
      "Predicted: 0.84, Actual: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Predict scores on validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Print predictions vs. actual\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Predicted: {pred[0]:.2f}, Actual: {y_val[i]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatter plot of predictions vs. actual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_val, predictions, c='blue', label='Predicted vs Actual')\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Perfect Match')  # Reference line\n",
    "plt.xlabel('Actual Scores')\n",
    "plt.ylabel('Predicted Scores')\n",
    "plt.title('Model Predictions vs. Actual Scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737644238.637476 8882006 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n",
      "W0000 00:00:1737644238.705476 8940627 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737644238.714259 8940627 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n",
      "Predicted Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to determine active clawing motion\n",
    "def is_clawing_motion(hip, knee, ankle):\n",
    "    \"\"\"\n",
    "    Determines active clawing motion by analyzing knee and ankle positions.\n",
    "    The knee should be forward relative to the hip, and the ankle should be tucked under the knee.\n",
    "    \"\"\"\n",
    "    knee_forward = knee[0] > hip[0]  # Knee is ahead of the hip in the x-axis\n",
    "    ankle_tucked = ankle[1] < knee[1]  # Ankle is higher (y-coordinate is lower)\n",
    "    return knee_forward and ankle_tucked\n",
    "\n",
    "# Path for the new test video\n",
    "new_video_path = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/sprint_technique/stages/stage3/test_videos/VID20250113142648.mp4\"\n",
    "\n",
    "# Extract keypoints for the new video\n",
    "new_keypoints = []\n",
    "cap = cv2.VideoCapture(new_video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB for MediaPipe processing\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = pose.process(frame_rgb)\n",
    "\n",
    "    if result.pose_landmarks:\n",
    "        landmarks = result.pose_landmarks.landmark\n",
    "\n",
    "        # Extract relevant keypoints for knees, hips, and ankles\n",
    "        left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.LEFT_HIP].y]\n",
    "        left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y]\n",
    "        left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y]\n",
    "\n",
    "        right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y]\n",
    "        right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y]\n",
    "        right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].y]\n",
    "\n",
    "        # Check for active clawing motion\n",
    "        left_clawing = is_clawing_motion(left_hip, left_knee, left_ankle)\n",
    "        right_clawing = is_clawing_motion(right_hip, right_knee, right_ankle)\n",
    "\n",
    "        # Store the binary values (0 or 1) for analysis\n",
    "        new_keypoints.append([int(left_clawing), int(right_clawing)])\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Pad the sequence to match training input length\n",
    "max_seq_length = X_train.shape[1]  # Ensure it's the same length used during training\n",
    "new_keypoints_padded = pad_sequences([new_keypoints], maxlen=max_seq_length, padding='post', dtype='float32')\n",
    "\n",
    "# Reshape to match model input (samples, timesteps, features)\n",
    "new_keypoints_padded = new_keypoints_padded.reshape((new_keypoints_padded.shape[0], new_keypoints_padded.shape[1], 2))\n",
    "\n",
    "# Predict score for the new video\n",
    "predicted_score = model.predict(new_keypoints_padded)\n",
    "print(f\"Predicted Score: {predicted_score[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_score(prediction):\n",
    "    \"\"\"Classify the prediction into 0, 0.5, or 1 based on thresholds.\"\"\"\n",
    "    if prediction >= 0.7:\n",
    "        return 1.0\n",
    "    elif prediction >= 0.6:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.5, Actual: 1.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Predict scores on validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Apply classification logic\n",
    "classified_predictions = [classify_score(pred[0]) for pred in predictions]\n",
    "\n",
    "# Print classified predictions vs actual scores\n",
    "for i, (pred, actual) in enumerate(zip(classified_predictions, y_val)):\n",
    "    print(f\"Classified: {pred}, Actual: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def weighted_mse(y_true, y_pred):\n",
    "    \"\"\"Weighted Mean Squared Error to prioritize true negatives.\"\"\"\n",
    "    weights = K.switch(y_true < 0.70, 2.0, 1.0)  # Weight true negatives higher\n",
    "    return K.mean(weights * K.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=weighted_mse, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
      "Classification Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Predict and classify scores\n",
    "classified_predictions = [classify_score(pred[0]) for pred in model.predict(X_val)]\n",
    "\n",
    "# Evaluate accuracy of classification\n",
    "correct = sum(1 for pred, actual in zip(classified_predictions, y_val) if pred == actual)\n",
    "accuracy = correct / len(y_val)\n",
    "\n",
    "print(f\"Classification Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/sprint_technique/stages/stage3/models/sprint_stage3.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
