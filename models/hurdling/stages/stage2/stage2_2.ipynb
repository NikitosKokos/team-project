{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737656957.036083 10178720 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1737656957.092297 10178978 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737656957.103368 10178986 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737656957.116049 10178980 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hurdle clearance analysis complete! JSON files saved in 'keypoints' folder.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to determine if the first hurdle is cleared\n",
    "def is_hurdle_cleared(knee, hurdle_height):\n",
    "    \"\"\"\n",
    "    Determines if the first hurdle is cleared by analyzing the knee position.\n",
    "    The knee should be above a defined hurdle height.\n",
    "    \"\"\"\n",
    "    _, knee_y = knee\n",
    "    return knee_y < hurdle_height  # Lower y-value means higher in the frame\n",
    "\n",
    "# Paths for the stage 2 videos and keypoints storage\n",
    "stage_path = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/hurdling/stages/stage2/videos\"\n",
    "keypoints_folder = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/hurdling/stages/stage2/keypoints\"\n",
    "\n",
    "# Ensure keypoints folder exists\n",
    "os.makedirs(keypoints_folder, exist_ok=True)\n",
    "\n",
    "# Define a hurdle height threshold (y-axis, normalized value)\n",
    "hurdle_height_threshold = 0.5  # Adjust based on video analysis\n",
    "\n",
    "for file in os.listdir(stage_path):\n",
    "    if file.endswith(\".mp4\"):\n",
    "        video_file_path = os.path.join(stage_path, file)\n",
    "        cap = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "        keypoints_data = []  # Store keypoints for this video\n",
    "        frame_count = 0\n",
    "        hurdle_cleared = False\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "            # Convert frame to RGB for MediaPipe processing\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result = pose.process(frame_rgb)\n",
    "\n",
    "            if result.pose_landmarks:\n",
    "                landmarks = result.pose_landmarks.landmark\n",
    "\n",
    "                # Extract knee keypoints for hurdle analysis\n",
    "                right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y]\n",
    "                left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y]\n",
    "\n",
    "                # Check if either knee has cleared the hurdle\n",
    "                if is_hurdle_cleared(right_knee, hurdle_height_threshold) or is_hurdle_cleared(left_knee, hurdle_height_threshold):\n",
    "                    hurdle_cleared = True\n",
    "\n",
    "                # Store data for this frame\n",
    "                keypoints_data.append({\n",
    "                    \"frame\": frame_count,\n",
    "                    \"right_knee\": right_knee,\n",
    "                    \"left_knee\": left_knee\n",
    "                })\n",
    "\n",
    "        # Release the video\n",
    "        cap.release()\n",
    "\n",
    "        # Save keypoints and hurdle clearance status to the keypoints folder\n",
    "        json_filename = os.path.splitext(file)[0] + \"_keypoints.json\"\n",
    "        json_path = os.path.join(keypoints_folder, json_filename)\n",
    "        with open(json_path, \"w\") as json_file:\n",
    "            json.dump({\"hurdle_cleared\": hurdle_cleared, \"keypoints\": keypoints_data}, json_file, indent=4)\n",
    "\n",
    "print(\"Hurdle clearance analysis complete! JSON files saved in 'keypoints' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 sequences with labels.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Path to the keypoints folder for hurdle clearance analysis\n",
    "keypoints_folder = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/hurdling/stages/stage2/keypoints\"\n",
    "\n",
    "# Lists to store sequences and labels\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "# Process keypoint JSON files\n",
    "for file in os.listdir(keypoints_folder):\n",
    "    if file.endswith(\"_keypoints.json\"):\n",
    "        file_path = os.path.join(keypoints_folder, file)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Extract hurdle clearance indicator from the JSON\n",
    "        hurdle_cleared = int(data.get(\"hurdle_cleared\", 0))  # 1 if cleared, 0 if not\n",
    "\n",
    "        # Store the hurdle clearance status\n",
    "        sequences.append([hurdle_cleared])\n",
    "\n",
    "        # Extract label from filename (assumes label is the first part of filename)\n",
    "        try:\n",
    "            label = float(file.split(\"_\")[0])  # Modify if filename structure differs\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Unable to extract label from {file}\")\n",
    "            continue\n",
    "        \n",
    "        labels.append(label)\n",
    "\n",
    "# Pad sequences to ensure uniform input shape\n",
    "if sequences:\n",
    "    max_len = max(len(seq) for seq in sequences)\n",
    "    sequences = pad_sequences(sequences, maxlen=max_len, padding='post', dtype='float32')\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    print(f\"Loaded {len(sequences)} sequences with labels.\")\n",
    "else:\n",
    "    print(\"No sequences found in the keypoints folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented dataset size: 80\n"
     ]
    }
   ],
   "source": [
    "def augment_data(sequence):\n",
    "    augmented_sequences = []\n",
    "\n",
    "    # Original\n",
    "    augmented_sequences.append(sequence)\n",
    "\n",
    "    # Mirrored (flip angles horizontally)\n",
    "    mirrored = -sequence\n",
    "    augmented_sequences.append(mirrored)\n",
    "\n",
    "    # Rotation (add a small angle offset)\n",
    "    rotated = sequence + np.random.uniform(-10, 10, size=sequence.shape)\n",
    "    augmented_sequences.append(rotated)\n",
    "\n",
    "    # Noise (add random Gaussian noise)\n",
    "    noisy = sequence + np.random.normal(0, 0.05, size=sequence.shape)\n",
    "    augmented_sequences.append(noisy)\n",
    "\n",
    "    # Scaled (adjust by a small percentage)\n",
    "    scaled = sequence * np.random.uniform(0.9, 1.1)\n",
    "    augmented_sequences.append(scaled)\n",
    "\n",
    "    return augmented_sequences\n",
    "\n",
    "augmented_sequences = []\n",
    "augmented_labels = []\n",
    "\n",
    "for seq, label in zip(sequences, labels):\n",
    "    augmented = augment_data(seq)\n",
    "    augmented_sequences.extend(augmented)\n",
    "    augmented_labels.extend([label] * len(augmented))\n",
    "\n",
    "augmented_sequences = np.array(augmented_sequences)\n",
    "augmented_labels = np.array(augmented_labels)\n",
    "\n",
    "print(f\"Augmented dataset size: {len(augmented_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train original shape: (61, 1)\n",
      "X_val original shape: (19, 1)\n",
      "Training samples: 61, Validation samples: 19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    augmented_sequences, augmented_labels, test_size=4/17, random_state=42\n",
    ")\n",
    "\n",
    "# Debug shape\n",
    "print(\"X_train original shape:\", X_train.shape)\n",
    "print(\"X_val original shape:\", X_val.shape)\n",
    "\n",
    "# Determine the correct reshape dimensions\n",
    "num_samples, total_timesteps = X_train.shape\n",
    "num_features = 1  # Adjust based on feature count\n",
    "\n",
    "X_train = X_train.reshape((num_samples, total_timesteps, num_features))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], num_features))\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define enhanced LSTM model\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(128, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1], 2))),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Bidirectional(LSTM(64, activation='tanh', return_sequences=True)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Bidirectional(LSTM(32, activation='tanh', return_sequences=False)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output: Regression score\n",
    "])\n",
    "\n",
    "# Compile the model with a reduced learning rate for better convergence\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.5148 - mae: 0.5187 - val_loss: 0.4527 - val_mae: 0.4749\n",
      "Epoch 2/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5039 - mae: 0.5313 - val_loss: 0.4274 - val_mae: 0.4762\n",
      "Epoch 3/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3690 - mae: 0.4225 - val_loss: 0.4001 - val_mae: 0.4779\n",
      "Epoch 4/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4432 - mae: 0.5265 - val_loss: 0.3693 - val_mae: 0.4797\n",
      "Epoch 5/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3852 - mae: 0.5021 - val_loss: 0.3365 - val_mae: 0.4818\n",
      "Epoch 6/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3504 - mae: 0.5040 - val_loss: 0.3026 - val_mae: 0.4839\n",
      "Epoch 7/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2693 - mae: 0.4550 - val_loss: 0.2729 - val_mae: 0.4855\n",
      "Epoch 8/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2943 - mae: 0.5110 - val_loss: 0.2512 - val_mae: 0.4870\n",
      "Epoch 9/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2548 - mae: 0.4931 - val_loss: 0.2445 - val_mae: 0.4880\n",
      "Epoch 10/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2609 - mae: 0.5059 - val_loss: 0.2466 - val_mae: 0.4891\n",
      "Epoch 11/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2599 - mae: 0.5037 - val_loss: 0.2463 - val_mae: 0.4893\n",
      "Epoch 12/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2694 - mae: 0.5084 - val_loss: 0.2448 - val_mae: 0.4900\n",
      "Epoch 13/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2586 - mae: 0.5033 - val_loss: 0.2418 - val_mae: 0.4899\n",
      "Epoch 14/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2457 - mae: 0.4931 - val_loss: 0.2417 - val_mae: 0.4904\n",
      "Epoch 15/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2612 - mae: 0.5089 - val_loss: 0.2432 - val_mae: 0.4922\n",
      "Epoch 16/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2460 - mae: 0.4936 - val_loss: 0.2446 - val_mae: 0.4935\n",
      "Epoch 17/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2485 - mae: 0.4965 - val_loss: 0.2458 - val_mae: 0.4947\n",
      "Epoch 18/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2585 - mae: 0.5067 - val_loss: 0.2469 - val_mae: 0.4957\n",
      "Epoch 19/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2559 - mae: 0.5034 - val_loss: 0.2477 - val_mae: 0.4973\n",
      "Epoch 20/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2537 - mae: 0.5021 - val_loss: 0.2492 - val_mae: 0.4989\n",
      "Epoch 21/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2578 - mae: 0.5069 - val_loss: 0.2510 - val_mae: 0.5006\n",
      "Epoch 22/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2586 - mae: 0.5077 - val_loss: 0.2515 - val_mae: 0.5014\n",
      "Epoch 23/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2425 - mae: 0.4917 - val_loss: 0.2526 - val_mae: 0.5024\n",
      "Epoch 24/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2427 - mae: 0.4917 - val_loss: 0.2530 - val_mae: 0.5028\n",
      "Epoch 25/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2456 - mae: 0.4947 - val_loss: 0.2542 - val_mae: 0.5038\n",
      "Epoch 26/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2516 - mae: 0.5006 - val_loss: 0.2553 - val_mae: 0.5048\n",
      "Epoch 27/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2424 - mae: 0.4912 - val_loss: 0.2567 - val_mae: 0.5061\n",
      "Epoch 28/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2406 - mae: 0.4886 - val_loss: 0.2577 - val_mae: 0.5065\n",
      "Epoch 29/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2505 - mae: 0.4975 - val_loss: 0.2585 - val_mae: 0.5072\n",
      "Epoch 30/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2436 - mae: 0.4919 - val_loss: 0.2585 - val_mae: 0.5074\n",
      "Epoch 31/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2529 - mae: 0.5011 - val_loss: 0.2572 - val_mae: 0.5062\n",
      "Epoch 32/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2554 - mae: 0.5042 - val_loss: 0.2575 - val_mae: 0.5063\n",
      "Epoch 33/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2534 - mae: 0.5016 - val_loss: 0.2574 - val_mae: 0.5056\n",
      "Epoch 34/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2514 - mae: 0.4979 - val_loss: 0.2582 - val_mae: 0.5064\n",
      "Epoch 35/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2519 - mae: 0.4988 - val_loss: 0.2596 - val_mae: 0.5079\n",
      "Epoch 36/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2562 - mae: 0.5050 - val_loss: 0.2610 - val_mae: 0.5093\n",
      "Epoch 37/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2427 - mae: 0.4908 - val_loss: 0.2620 - val_mae: 0.5096\n",
      "Epoch 38/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2523 - mae: 0.4995 - val_loss: 0.2621 - val_mae: 0.5095\n",
      "Epoch 39/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2560 - mae: 0.5042 - val_loss: 0.2612 - val_mae: 0.5090\n",
      "Epoch 40/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2490 - mae: 0.4973 - val_loss: 0.2629 - val_mae: 0.5106\n",
      "Epoch 41/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2464 - mae: 0.4940 - val_loss: 0.2629 - val_mae: 0.5106\n",
      "Epoch 42/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2440 - mae: 0.4908 - val_loss: 0.2636 - val_mae: 0.5114\n",
      "Epoch 43/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2527 - mae: 0.5008 - val_loss: 0.2637 - val_mae: 0.5113\n",
      "Epoch 44/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2427 - mae: 0.4888 - val_loss: 0.2648 - val_mae: 0.5123\n",
      "Epoch 45/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2578 - mae: 0.5039 - val_loss: 0.2640 - val_mae: 0.5121\n",
      "Epoch 46/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2324 - mae: 0.4789 - val_loss: 0.2650 - val_mae: 0.5131\n",
      "Epoch 47/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2593 - mae: 0.5064 - val_loss: 0.2645 - val_mae: 0.5126\n",
      "Epoch 48/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2520 - mae: 0.4993 - val_loss: 0.2639 - val_mae: 0.5121\n",
      "Epoch 49/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2508 - mae: 0.4986 - val_loss: 0.2640 - val_mae: 0.5123\n",
      "Epoch 50/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2422 - mae: 0.4876 - val_loss: 0.2639 - val_mae: 0.5122\n",
      "Epoch 51/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2375 - mae: 0.4841 - val_loss: 0.2649 - val_mae: 0.5126\n",
      "Epoch 52/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2369 - mae: 0.4843 - val_loss: 0.2660 - val_mae: 0.5133\n",
      "Epoch 53/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2428 - mae: 0.4888 - val_loss: 0.2665 - val_mae: 0.5138\n",
      "Epoch 54/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2468 - mae: 0.4927 - val_loss: 0.2649 - val_mae: 0.5119\n",
      "Epoch 55/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2507 - mae: 0.4967 - val_loss: 0.2644 - val_mae: 0.5119\n",
      "Epoch 56/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2539 - mae: 0.5008 - val_loss: 0.2637 - val_mae: 0.5115\n",
      "Epoch 57/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2389 - mae: 0.4865 - val_loss: 0.2641 - val_mae: 0.5122\n",
      "Epoch 58/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2517 - mae: 0.4976 - val_loss: 0.2629 - val_mae: 0.5111\n",
      "Epoch 59/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2463 - mae: 0.4937 - val_loss: 0.2620 - val_mae: 0.5098\n",
      "Epoch 60/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2466 - mae: 0.4918 - val_loss: 0.2628 - val_mae: 0.5105\n",
      "Epoch 61/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2494 - mae: 0.4938 - val_loss: 0.2628 - val_mae: 0.5104\n",
      "Epoch 62/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2622 - mae: 0.5089 - val_loss: 0.2603 - val_mae: 0.5085\n",
      "Epoch 63/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2476 - mae: 0.4960 - val_loss: 0.2597 - val_mae: 0.5078\n",
      "Epoch 64/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2546 - mae: 0.5031 - val_loss: 0.2590 - val_mae: 0.5074\n",
      "Epoch 65/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2452 - mae: 0.4913 - val_loss: 0.2587 - val_mae: 0.5068\n",
      "Epoch 66/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2466 - mae: 0.4935 - val_loss: 0.2595 - val_mae: 0.5077\n",
      "Epoch 67/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2521 - mae: 0.5000 - val_loss: 0.2596 - val_mae: 0.5080\n",
      "Epoch 68/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2471 - mae: 0.4953 - val_loss: 0.2607 - val_mae: 0.5091\n",
      "Epoch 69/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2503 - mae: 0.4981 - val_loss: 0.2612 - val_mae: 0.5099\n",
      "Epoch 70/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2552 - mae: 0.5022 - val_loss: 0.2605 - val_mae: 0.5090\n",
      "Epoch 71/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2414 - mae: 0.4881 - val_loss: 0.2602 - val_mae: 0.5085\n",
      "Epoch 72/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2484 - mae: 0.4957 - val_loss: 0.2590 - val_mae: 0.5073\n",
      "Epoch 73/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2528 - mae: 0.5006 - val_loss: 0.2590 - val_mae: 0.5071\n",
      "Epoch 74/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2565 - mae: 0.5039 - val_loss: 0.2599 - val_mae: 0.5080\n",
      "Epoch 75/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2492 - mae: 0.4968 - val_loss: 0.2603 - val_mae: 0.5086\n",
      "Epoch 76/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2584 - mae: 0.5058 - val_loss: 0.2599 - val_mae: 0.5083\n",
      "Epoch 77/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2492 - mae: 0.4974 - val_loss: 0.2602 - val_mae: 0.5085\n",
      "Epoch 78/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2547 - mae: 0.5006 - val_loss: 0.2602 - val_mae: 0.5088\n",
      "Epoch 79/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2593 - mae: 0.5078 - val_loss: 0.2600 - val_mae: 0.5088\n",
      "Epoch 80/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2650 - mae: 0.5121 - val_loss: 0.2612 - val_mae: 0.5097\n",
      "Epoch 81/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2532 - mae: 0.5007 - val_loss: 0.2592 - val_mae: 0.5079\n",
      "Epoch 82/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2490 - mae: 0.4977 - val_loss: 0.2594 - val_mae: 0.5079\n",
      "Epoch 83/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2469 - mae: 0.4943 - val_loss: 0.2592 - val_mae: 0.5073\n",
      "Epoch 84/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2490 - mae: 0.4958 - val_loss: 0.2587 - val_mae: 0.5065\n",
      "Epoch 85/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2523 - mae: 0.4995 - val_loss: 0.2577 - val_mae: 0.5060\n",
      "Epoch 86/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2473 - mae: 0.4955 - val_loss: 0.2578 - val_mae: 0.5062\n",
      "Epoch 87/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2526 - mae: 0.4990 - val_loss: 0.2574 - val_mae: 0.5060\n",
      "Epoch 88/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2440 - mae: 0.4903 - val_loss: 0.2583 - val_mae: 0.5069\n",
      "Epoch 89/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2455 - mae: 0.4931 - val_loss: 0.2582 - val_mae: 0.5070\n",
      "Epoch 90/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2532 - mae: 0.5016 - val_loss: 0.2580 - val_mae: 0.5069\n",
      "Epoch 91/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2520 - mae: 0.4999 - val_loss: 0.2581 - val_mae: 0.5070\n",
      "Epoch 92/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2485 - mae: 0.4960 - val_loss: 0.2586 - val_mae: 0.5073\n",
      "Epoch 93/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2546 - mae: 0.5018 - val_loss: 0.2587 - val_mae: 0.5073\n",
      "Epoch 94/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2500 - mae: 0.4978 - val_loss: 0.2580 - val_mae: 0.5067\n",
      "Epoch 95/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2343 - mae: 0.4817 - val_loss: 0.2570 - val_mae: 0.5057\n",
      "Epoch 96/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2491 - mae: 0.4964 - val_loss: 0.2575 - val_mae: 0.5059\n",
      "Epoch 97/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2469 - mae: 0.4950 - val_loss: 0.2570 - val_mae: 0.5053\n",
      "Epoch 98/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2549 - mae: 0.5026 - val_loss: 0.2579 - val_mae: 0.5062\n",
      "Epoch 99/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2526 - mae: 0.4994 - val_loss: 0.2586 - val_mae: 0.5069\n",
      "Epoch 100/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2485 - mae: 0.4964 - val_loss: 0.2597 - val_mae: 0.5082\n",
      "Epoch 101/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2517 - mae: 0.4990 - val_loss: 0.2608 - val_mae: 0.5091\n",
      "Epoch 102/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2534 - mae: 0.5003 - val_loss: 0.2601 - val_mae: 0.5088\n",
      "Epoch 103/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2481 - mae: 0.4961 - val_loss: 0.2596 - val_mae: 0.5084\n",
      "Epoch 104/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2484 - mae: 0.4969 - val_loss: 0.2613 - val_mae: 0.5102\n",
      "Epoch 105/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2460 - mae: 0.4936 - val_loss: 0.2625 - val_mae: 0.5110\n",
      "Epoch 106/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2523 - mae: 0.5007 - val_loss: 0.2642 - val_mae: 0.5123\n",
      "Epoch 107/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2523 - mae: 0.5003 - val_loss: 0.2641 - val_mae: 0.5119\n",
      "Epoch 108/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2416 - mae: 0.4876 - val_loss: 0.2644 - val_mae: 0.5120\n",
      "Epoch 109/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2451 - mae: 0.4933 - val_loss: 0.2645 - val_mae: 0.5122\n",
      "Epoch 110/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2476 - mae: 0.4937 - val_loss: 0.2657 - val_mae: 0.5130\n",
      "Epoch 111/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2422 - mae: 0.4883 - val_loss: 0.2663 - val_mae: 0.5134\n",
      "Epoch 112/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2513 - mae: 0.4964 - val_loss: 0.2645 - val_mae: 0.5126\n",
      "Epoch 113/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2517 - mae: 0.4994 - val_loss: 0.2631 - val_mae: 0.5115\n",
      "Epoch 114/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2475 - mae: 0.4941 - val_loss: 0.2627 - val_mae: 0.5110\n",
      "Epoch 115/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2440 - mae: 0.4901 - val_loss: 0.2611 - val_mae: 0.5094\n",
      "Epoch 116/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2367 - mae: 0.4837 - val_loss: 0.2599 - val_mae: 0.5082\n",
      "Epoch 117/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2562 - mae: 0.5020 - val_loss: 0.2580 - val_mae: 0.5066\n",
      "Epoch 118/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2420 - mae: 0.4890 - val_loss: 0.2572 - val_mae: 0.5055\n",
      "Epoch 119/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2451 - mae: 0.4929 - val_loss: 0.2572 - val_mae: 0.5053\n",
      "Epoch 120/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2597 - mae: 0.5050 - val_loss: 0.2568 - val_mae: 0.5050\n",
      "Epoch 121/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2497 - mae: 0.4969 - val_loss: 0.2573 - val_mae: 0.5059\n",
      "Epoch 122/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2477 - mae: 0.4958 - val_loss: 0.2587 - val_mae: 0.5072\n",
      "Epoch 123/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2473 - mae: 0.4920 - val_loss: 0.2613 - val_mae: 0.5094\n",
      "Epoch 124/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2517 - mae: 0.4991 - val_loss: 0.2599 - val_mae: 0.5087\n",
      "Epoch 125/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2477 - mae: 0.4945 - val_loss: 0.2590 - val_mae: 0.5079\n",
      "Epoch 126/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2394 - mae: 0.4873 - val_loss: 0.2598 - val_mae: 0.5082\n",
      "Epoch 127/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2449 - mae: 0.4931 - val_loss: 0.2585 - val_mae: 0.5070\n",
      "Epoch 128/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2449 - mae: 0.4928 - val_loss: 0.2568 - val_mae: 0.5053\n",
      "Epoch 129/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2511 - mae: 0.4955 - val_loss: 0.2577 - val_mae: 0.5063\n",
      "Epoch 130/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2528 - mae: 0.5005 - val_loss: 0.2576 - val_mae: 0.5056\n",
      "Epoch 131/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2513 - mae: 0.4989 - val_loss: 0.2570 - val_mae: 0.5043\n",
      "Epoch 132/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2550 - mae: 0.5017 - val_loss: 0.2575 - val_mae: 0.5047\n",
      "Epoch 133/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2405 - mae: 0.4875 - val_loss: 0.2591 - val_mae: 0.5063\n",
      "Epoch 134/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2517 - mae: 0.4966 - val_loss: 0.2615 - val_mae: 0.5085\n",
      "Epoch 135/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2526 - mae: 0.4982 - val_loss: 0.2618 - val_mae: 0.5090\n",
      "Epoch 136/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2558 - mae: 0.5018 - val_loss: 0.2596 - val_mae: 0.5077\n",
      "Epoch 137/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2464 - mae: 0.4937 - val_loss: 0.2582 - val_mae: 0.5065\n",
      "Epoch 138/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2392 - mae: 0.4871 - val_loss: 0.2574 - val_mae: 0.5052\n",
      "Epoch 139/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2517 - mae: 0.4982 - val_loss: 0.2579 - val_mae: 0.5057\n",
      "Epoch 140/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2432 - mae: 0.4909 - val_loss: 0.2569 - val_mae: 0.5043\n",
      "Epoch 141/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2519 - mae: 0.4985 - val_loss: 0.2556 - val_mae: 0.5033\n",
      "Epoch 142/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2461 - mae: 0.4929 - val_loss: 0.2561 - val_mae: 0.5040\n",
      "Epoch 143/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2445 - mae: 0.4912 - val_loss: 0.2573 - val_mae: 0.5057\n",
      "Epoch 144/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2420 - mae: 0.4888 - val_loss: 0.2575 - val_mae: 0.5059\n",
      "Epoch 145/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2438 - mae: 0.4902 - val_loss: 0.2583 - val_mae: 0.5064\n",
      "Epoch 146/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2581 - mae: 0.5058 - val_loss: 0.2569 - val_mae: 0.5044\n",
      "Epoch 147/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2523 - mae: 0.4995 - val_loss: 0.2570 - val_mae: 0.5048\n",
      "Epoch 148/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2642 - mae: 0.5068 - val_loss: 0.2552 - val_mae: 0.5026\n",
      "Epoch 149/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2340 - mae: 0.4784 - val_loss: 0.2539 - val_mae: 0.5017\n",
      "Epoch 150/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2452 - mae: 0.4929 - val_loss: 0.2531 - val_mae: 0.5018\n",
      "Epoch 151/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2501 - mae: 0.4966 - val_loss: 0.2529 - val_mae: 0.5019\n",
      "Epoch 152/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2539 - mae: 0.5015 - val_loss: 0.2516 - val_mae: 0.5005\n",
      "Epoch 153/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2563 - mae: 0.5029 - val_loss: 0.2514 - val_mae: 0.5003\n",
      "Epoch 154/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2514 - mae: 0.4982 - val_loss: 0.2525 - val_mae: 0.5014\n",
      "Epoch 155/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2553 - mae: 0.5031 - val_loss: 0.2555 - val_mae: 0.5046\n",
      "Epoch 156/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2676 - mae: 0.5137 - val_loss: 0.2578 - val_mae: 0.5065\n",
      "Epoch 157/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2474 - mae: 0.4937 - val_loss: 0.2574 - val_mae: 0.5060\n",
      "Epoch 158/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2596 - mae: 0.5074 - val_loss: 0.2596 - val_mae: 0.5082\n",
      "Epoch 159/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2578 - mae: 0.5050 - val_loss: 0.2599 - val_mae: 0.5088\n",
      "Epoch 160/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2416 - mae: 0.4894 - val_loss: 0.2597 - val_mae: 0.5085\n",
      "Epoch 161/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2389 - mae: 0.4861 - val_loss: 0.2616 - val_mae: 0.5101\n",
      "Epoch 162/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2421 - mae: 0.4889 - val_loss: 0.2628 - val_mae: 0.5112\n",
      "Epoch 163/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2397 - mae: 0.4861 - val_loss: 0.2628 - val_mae: 0.5109\n",
      "Epoch 164/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2450 - mae: 0.4923 - val_loss: 0.2624 - val_mae: 0.5107\n",
      "Epoch 165/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2478 - mae: 0.4934 - val_loss: 0.2615 - val_mae: 0.5096\n",
      "Epoch 166/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2364 - mae: 0.4818 - val_loss: 0.2605 - val_mae: 0.5086\n",
      "Epoch 167/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2393 - mae: 0.4853 - val_loss: 0.2597 - val_mae: 0.5079\n",
      "Epoch 168/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2366 - mae: 0.4824 - val_loss: 0.2594 - val_mae: 0.5074\n",
      "Epoch 169/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2501 - mae: 0.4967 - val_loss: 0.2587 - val_mae: 0.5072\n",
      "Epoch 170/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2538 - mae: 0.5017 - val_loss: 0.2588 - val_mae: 0.5075\n",
      "Epoch 171/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2451 - mae: 0.4914 - val_loss: 0.2586 - val_mae: 0.5072\n",
      "Epoch 172/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2555 - mae: 0.5019 - val_loss: 0.2597 - val_mae: 0.5085\n",
      "Epoch 173/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2500 - mae: 0.4964 - val_loss: 0.2600 - val_mae: 0.5087\n",
      "Epoch 174/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2570 - mae: 0.5043 - val_loss: 0.2612 - val_mae: 0.5096\n",
      "Epoch 175/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2477 - mae: 0.4937 - val_loss: 0.2599 - val_mae: 0.5087\n",
      "Epoch 176/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2589 - mae: 0.5072 - val_loss: 0.2581 - val_mae: 0.5069\n",
      "Epoch 177/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2444 - mae: 0.4923 - val_loss: 0.2571 - val_mae: 0.5054\n",
      "Epoch 178/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2420 - mae: 0.4895 - val_loss: 0.2581 - val_mae: 0.5062\n",
      "Epoch 179/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2528 - mae: 0.4997 - val_loss: 0.2561 - val_mae: 0.5042\n",
      "Epoch 180/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2476 - mae: 0.4936 - val_loss: 0.2561 - val_mae: 0.5042\n",
      "Epoch 181/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2515 - mae: 0.4982 - val_loss: 0.2553 - val_mae: 0.5034\n",
      "Epoch 182/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2450 - mae: 0.4916 - val_loss: 0.2560 - val_mae: 0.5041\n",
      "Epoch 183/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2432 - mae: 0.4906 - val_loss: 0.2579 - val_mae: 0.5057\n",
      "Epoch 184/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2464 - mae: 0.4922 - val_loss: 0.2596 - val_mae: 0.5071\n",
      "Epoch 185/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2569 - mae: 0.5026 - val_loss: 0.2610 - val_mae: 0.5088\n",
      "Epoch 186/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2411 - mae: 0.4876 - val_loss: 0.2597 - val_mae: 0.5075\n",
      "Epoch 187/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2478 - mae: 0.4934 - val_loss: 0.2591 - val_mae: 0.5067\n",
      "Epoch 188/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2578 - mae: 0.5030 - val_loss: 0.2556 - val_mae: 0.5037\n",
      "Epoch 189/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2388 - mae: 0.4847 - val_loss: 0.2565 - val_mae: 0.5046\n",
      "Epoch 190/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2439 - mae: 0.4917 - val_loss: 0.2560 - val_mae: 0.5038\n",
      "Epoch 191/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2454 - mae: 0.4915 - val_loss: 0.2547 - val_mae: 0.5023\n",
      "Epoch 192/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2504 - mae: 0.4960 - val_loss: 0.2544 - val_mae: 0.5022\n",
      "Epoch 193/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2475 - mae: 0.4948 - val_loss: 0.2538 - val_mae: 0.5012\n",
      "Epoch 194/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2510 - mae: 0.4977 - val_loss: 0.2526 - val_mae: 0.5002\n",
      "Epoch 195/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2352 - mae: 0.4802 - val_loss: 0.2512 - val_mae: 0.4988\n",
      "Epoch 196/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2531 - mae: 0.4982 - val_loss: 0.2504 - val_mae: 0.4979\n",
      "Epoch 197/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2413 - mae: 0.4879 - val_loss: 0.2507 - val_mae: 0.4983\n",
      "Epoch 198/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2403 - mae: 0.4858 - val_loss: 0.2517 - val_mae: 0.4995\n",
      "Epoch 199/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2502 - mae: 0.4966 - val_loss: 0.2535 - val_mae: 0.5012\n",
      "Epoch 200/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2552 - mae: 0.5008 - val_loss: 0.2538 - val_mae: 0.5020\n",
      "Epoch 201/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2515 - mae: 0.4951 - val_loss: 0.2549 - val_mae: 0.5034\n",
      "Epoch 202/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2466 - mae: 0.4938 - val_loss: 0.2555 - val_mae: 0.5042\n",
      "Epoch 203/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2398 - mae: 0.4868 - val_loss: 0.2532 - val_mae: 0.5016\n",
      "Epoch 204/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2438 - mae: 0.4906 - val_loss: 0.2509 - val_mae: 0.4990\n",
      "Epoch 205/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2471 - mae: 0.4944 - val_loss: 0.2512 - val_mae: 0.4993\n",
      "Epoch 206/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2525 - mae: 0.4989 - val_loss: 0.2511 - val_mae: 0.4990\n",
      "Epoch 207/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2522 - mae: 0.4999 - val_loss: 0.2499 - val_mae: 0.4972\n",
      "Epoch 208/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2474 - mae: 0.4926 - val_loss: 0.2521 - val_mae: 0.4998\n",
      "Epoch 209/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2507 - mae: 0.4974 - val_loss: 0.2531 - val_mae: 0.5011\n",
      "Epoch 210/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2422 - mae: 0.4891 - val_loss: 0.2558 - val_mae: 0.5040\n",
      "Epoch 211/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2480 - mae: 0.4946 - val_loss: 0.2578 - val_mae: 0.5061\n",
      "Epoch 212/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2477 - mae: 0.4946 - val_loss: 0.2577 - val_mae: 0.5061\n",
      "Epoch 213/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2431 - mae: 0.4897 - val_loss: 0.2589 - val_mae: 0.5069\n",
      "Epoch 214/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2525 - mae: 0.4980 - val_loss: 0.2592 - val_mae: 0.5055\n",
      "Epoch 215/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2515 - mae: 0.4967 - val_loss: 0.2581 - val_mae: 0.5042\n",
      "Epoch 216/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2423 - mae: 0.4878 - val_loss: 0.2562 - val_mae: 0.5027\n",
      "Epoch 217/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2470 - mae: 0.4933 - val_loss: 0.2545 - val_mae: 0.5015\n",
      "Epoch 218/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2545 - mae: 0.4986 - val_loss: 0.2525 - val_mae: 0.4999\n",
      "Epoch 219/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2445 - mae: 0.4901 - val_loss: 0.2522 - val_mae: 0.4999\n",
      "Epoch 220/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2519 - mae: 0.4990 - val_loss: 0.2531 - val_mae: 0.5014\n",
      "Epoch 221/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2463 - mae: 0.4931 - val_loss: 0.2527 - val_mae: 0.5011\n",
      "Epoch 222/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2509 - mae: 0.4982 - val_loss: 0.2537 - val_mae: 0.5022\n",
      "Epoch 223/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2491 - mae: 0.4968 - val_loss: 0.2554 - val_mae: 0.5038\n",
      "Epoch 224/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2496 - mae: 0.4953 - val_loss: 0.2538 - val_mae: 0.5021\n",
      "Epoch 225/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2444 - mae: 0.4915 - val_loss: 0.2543 - val_mae: 0.5028\n",
      "Epoch 226/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2480 - mae: 0.4957 - val_loss: 0.2543 - val_mae: 0.5030\n",
      "Epoch 227/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2483 - mae: 0.4937 - val_loss: 0.2558 - val_mae: 0.5046\n",
      "Epoch 228/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2449 - mae: 0.4918 - val_loss: 0.2563 - val_mae: 0.5046\n",
      "Epoch 229/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2508 - mae: 0.4976 - val_loss: 0.2548 - val_mae: 0.5031\n",
      "Epoch 230/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2463 - mae: 0.4934 - val_loss: 0.2555 - val_mae: 0.5037\n",
      "Epoch 231/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2540 - mae: 0.5010 - val_loss: 0.2548 - val_mae: 0.5025\n",
      "Epoch 232/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2378 - mae: 0.4846 - val_loss: 0.2547 - val_mae: 0.5020\n",
      "Epoch 233/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2561 - mae: 0.5031 - val_loss: 0.2534 - val_mae: 0.5014\n",
      "Epoch 234/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2584 - mae: 0.5050 - val_loss: 0.2513 - val_mae: 0.5000\n",
      "Epoch 235/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2466 - mae: 0.4940 - val_loss: 0.2513 - val_mae: 0.5000\n",
      "Epoch 236/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2440 - mae: 0.4915 - val_loss: 0.2520 - val_mae: 0.5008\n",
      "Epoch 237/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2455 - mae: 0.4904 - val_loss: 0.2540 - val_mae: 0.5025\n",
      "Epoch 238/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2433 - mae: 0.4897 - val_loss: 0.2544 - val_mae: 0.5026\n",
      "Epoch 239/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2384 - mae: 0.4847 - val_loss: 0.2565 - val_mae: 0.5042\n",
      "Epoch 240/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2440 - mae: 0.4888 - val_loss: 0.2551 - val_mae: 0.5033\n",
      "Epoch 241/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2449 - mae: 0.4916 - val_loss: 0.2534 - val_mae: 0.5017\n",
      "Epoch 242/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2461 - mae: 0.4929 - val_loss: 0.2515 - val_mae: 0.4995\n",
      "Epoch 243/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2519 - mae: 0.4957 - val_loss: 0.2499 - val_mae: 0.4972\n",
      "Epoch 244/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2632 - mae: 0.5094 - val_loss: 0.2494 - val_mae: 0.4968\n",
      "Epoch 245/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2472 - mae: 0.4941 - val_loss: 0.2508 - val_mae: 0.4981\n",
      "Epoch 246/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2474 - mae: 0.4933 - val_loss: 0.2516 - val_mae: 0.4992\n",
      "Epoch 247/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2472 - mae: 0.4941 - val_loss: 0.2517 - val_mae: 0.4994\n",
      "Epoch 248/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2615 - mae: 0.5062 - val_loss: 0.2506 - val_mae: 0.4985\n",
      "Epoch 249/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2416 - mae: 0.4888 - val_loss: 0.2531 - val_mae: 0.5010\n",
      "Epoch 250/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2515 - mae: 0.4985 - val_loss: 0.2544 - val_mae: 0.5026\n",
      "Epoch 251/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2536 - mae: 0.5011 - val_loss: 0.2544 - val_mae: 0.5028\n",
      "Epoch 252/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2557 - mae: 0.5037 - val_loss: 0.2551 - val_mae: 0.5038\n",
      "Epoch 253/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2542 - mae: 0.5004 - val_loss: 0.2553 - val_mae: 0.5039\n",
      "Epoch 254/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2554 - mae: 0.5003 - val_loss: 0.2548 - val_mae: 0.5036\n",
      "Epoch 255/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2421 - mae: 0.4898 - val_loss: 0.2549 - val_mae: 0.5036\n",
      "Epoch 256/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2484 - mae: 0.4966 - val_loss: 0.2548 - val_mae: 0.5035\n",
      "Epoch 257/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2506 - mae: 0.4988 - val_loss: 0.2543 - val_mae: 0.5032\n",
      "Epoch 258/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2454 - mae: 0.4927 - val_loss: 0.2541 - val_mae: 0.5030\n",
      "Epoch 259/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2468 - mae: 0.4945 - val_loss: 0.2549 - val_mae: 0.5038\n",
      "Epoch 260/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2393 - mae: 0.4862 - val_loss: 0.2553 - val_mae: 0.5042\n",
      "Epoch 261/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2509 - mae: 0.4992 - val_loss: 0.2548 - val_mae: 0.5040\n",
      "Epoch 262/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2481 - mae: 0.4959 - val_loss: 0.2546 - val_mae: 0.5037\n",
      "Epoch 263/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2379 - mae: 0.4848 - val_loss: 0.2546 - val_mae: 0.5036\n",
      "Epoch 264/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2426 - mae: 0.4900 - val_loss: 0.2554 - val_mae: 0.5041\n",
      "Epoch 265/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2391 - mae: 0.4857 - val_loss: 0.2543 - val_mae: 0.5027\n",
      "Epoch 266/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2357 - mae: 0.4827 - val_loss: 0.2548 - val_mae: 0.5035\n",
      "Epoch 267/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2377 - mae: 0.4849 - val_loss: 0.2552 - val_mae: 0.5035\n",
      "Epoch 268/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2536 - mae: 0.4992 - val_loss: 0.2562 - val_mae: 0.5046\n",
      "Epoch 269/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2609 - mae: 0.5087 - val_loss: 0.2549 - val_mae: 0.5039\n",
      "Epoch 270/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2488 - mae: 0.4956 - val_loss: 0.2543 - val_mae: 0.5032\n",
      "Epoch 271/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2458 - mae: 0.4912 - val_loss: 0.2533 - val_mae: 0.5022\n",
      "Epoch 272/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2482 - mae: 0.4948 - val_loss: 0.2532 - val_mae: 0.5017\n",
      "Epoch 273/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2446 - mae: 0.4917 - val_loss: 0.2533 - val_mae: 0.5011\n",
      "Epoch 274/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2456 - mae: 0.4914 - val_loss: 0.2521 - val_mae: 0.4997\n",
      "Epoch 275/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2497 - mae: 0.4954 - val_loss: 0.2528 - val_mae: 0.4995\n",
      "Epoch 276/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2439 - mae: 0.4900 - val_loss: 0.2523 - val_mae: 0.4991\n",
      "Epoch 277/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2464 - mae: 0.4917 - val_loss: 0.2524 - val_mae: 0.4995\n",
      "Epoch 278/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2544 - mae: 0.5003 - val_loss: 0.2518 - val_mae: 0.4994\n",
      "Epoch 279/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2467 - mae: 0.4923 - val_loss: 0.2544 - val_mae: 0.5024\n",
      "Epoch 280/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2503 - mae: 0.4970 - val_loss: 0.2566 - val_mae: 0.5046\n",
      "Epoch 281/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2477 - mae: 0.4909 - val_loss: 0.2587 - val_mae: 0.5064\n",
      "Epoch 282/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2587 - mae: 0.5028 - val_loss: 0.2587 - val_mae: 0.5068\n",
      "Epoch 283/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2530 - mae: 0.4992 - val_loss: 0.2569 - val_mae: 0.5051\n",
      "Epoch 284/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2411 - mae: 0.4875 - val_loss: 0.2582 - val_mae: 0.5061\n",
      "Epoch 285/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2379 - mae: 0.4841 - val_loss: 0.2578 - val_mae: 0.5057\n",
      "Epoch 286/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2446 - mae: 0.4894 - val_loss: 0.2596 - val_mae: 0.5074\n",
      "Epoch 287/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2507 - mae: 0.4959 - val_loss: 0.2613 - val_mae: 0.5090\n",
      "Epoch 288/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2447 - mae: 0.4865 - val_loss: 0.2645 - val_mae: 0.5119\n",
      "Epoch 289/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2474 - mae: 0.4904 - val_loss: 0.2605 - val_mae: 0.5081\n",
      "Epoch 290/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2576 - mae: 0.4978 - val_loss: 0.2570 - val_mae: 0.5046\n",
      "Epoch 291/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2535 - mae: 0.4983 - val_loss: 0.2546 - val_mae: 0.5022\n",
      "Epoch 292/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2597 - mae: 0.5048 - val_loss: 0.2519 - val_mae: 0.5002\n",
      "Epoch 293/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2444 - mae: 0.4903 - val_loss: 0.2515 - val_mae: 0.4999\n",
      "Epoch 294/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2554 - mae: 0.5029 - val_loss: 0.2522 - val_mae: 0.5006\n",
      "Epoch 295/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2518 - mae: 0.4971 - val_loss: 0.2530 - val_mae: 0.5013\n",
      "Epoch 296/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2508 - mae: 0.4975 - val_loss: 0.2525 - val_mae: 0.5003\n",
      "Epoch 297/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2414 - mae: 0.4877 - val_loss: 0.2524 - val_mae: 0.5003\n",
      "Epoch 298/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2511 - mae: 0.4962 - val_loss: 0.2502 - val_mae: 0.4981\n",
      "Epoch 299/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2404 - mae: 0.4874 - val_loss: 0.2515 - val_mae: 0.4994\n",
      "Epoch 300/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2289 - mae: 0.4737 - val_loss: 0.2520 - val_mae: 0.4999\n",
      "Epoch 301/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2449 - mae: 0.4900 - val_loss: 0.2509 - val_mae: 0.4985\n",
      "Epoch 302/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2436 - mae: 0.4897 - val_loss: 0.2476 - val_mae: 0.4953\n",
      "Epoch 303/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2480 - mae: 0.4939 - val_loss: 0.2472 - val_mae: 0.4953\n",
      "Epoch 304/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2367 - mae: 0.4831 - val_loss: 0.2482 - val_mae: 0.4965\n",
      "Epoch 305/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2459 - mae: 0.4931 - val_loss: 0.2499 - val_mae: 0.4983\n",
      "Epoch 306/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2484 - mae: 0.4943 - val_loss: 0.2536 - val_mae: 0.5018\n",
      "Epoch 307/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2346 - mae: 0.4809 - val_loss: 0.2570 - val_mae: 0.5049\n",
      "Epoch 308/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2548 - mae: 0.5000 - val_loss: 0.2567 - val_mae: 0.5048\n",
      "Epoch 309/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2434 - mae: 0.4883 - val_loss: 0.2576 - val_mae: 0.5052\n",
      "Epoch 310/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2409 - mae: 0.4871 - val_loss: 0.2576 - val_mae: 0.5047\n",
      "Epoch 311/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2660 - mae: 0.5070 - val_loss: 0.2558 - val_mae: 0.5023\n",
      "Epoch 312/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2461 - mae: 0.4902 - val_loss: 0.2557 - val_mae: 0.5014\n",
      "Epoch 313/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2457 - mae: 0.4883 - val_loss: 0.2540 - val_mae: 0.4994\n",
      "Epoch 314/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2307 - mae: 0.4727 - val_loss: 0.2515 - val_mae: 0.4976\n",
      "Epoch 315/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2552 - mae: 0.4983 - val_loss: 0.2492 - val_mae: 0.4959\n",
      "Epoch 316/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2567 - mae: 0.5020 - val_loss: 0.2485 - val_mae: 0.4959\n",
      "Epoch 317/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2561 - mae: 0.5008 - val_loss: 0.2489 - val_mae: 0.4965\n",
      "Epoch 318/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.2487 - mae: 0.4953 - val_loss: 0.2472 - val_mae: 0.4949\n",
      "Epoch 319/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2581 - mae: 0.5044 - val_loss: 0.2454 - val_mae: 0.4937\n",
      "Epoch 320/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2645 - mae: 0.5102 - val_loss: 0.2450 - val_mae: 0.4936\n",
      "Epoch 321/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2456 - mae: 0.4918 - val_loss: 0.2465 - val_mae: 0.4953\n",
      "Epoch 322/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2502 - mae: 0.4966 - val_loss: 0.2481 - val_mae: 0.4968\n",
      "Epoch 323/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2451 - mae: 0.4930 - val_loss: 0.2488 - val_mae: 0.4975\n",
      "Epoch 324/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2495 - mae: 0.4958 - val_loss: 0.2486 - val_mae: 0.4972\n",
      "Epoch 325/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2552 - mae: 0.4980 - val_loss: 0.2478 - val_mae: 0.4963\n",
      "Epoch 326/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2547 - mae: 0.5018 - val_loss: 0.2482 - val_mae: 0.4968\n",
      "Epoch 327/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2476 - mae: 0.4955 - val_loss: 0.2475 - val_mae: 0.4964\n",
      "Epoch 328/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2420 - mae: 0.4891 - val_loss: 0.2487 - val_mae: 0.4973\n",
      "Epoch 329/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2479 - mae: 0.4948 - val_loss: 0.2497 - val_mae: 0.4983\n",
      "Epoch 330/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2478 - mae: 0.4933 - val_loss: 0.2501 - val_mae: 0.4988\n",
      "Epoch 331/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2458 - mae: 0.4927 - val_loss: 0.2506 - val_mae: 0.4995\n",
      "Epoch 332/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2454 - mae: 0.4916 - val_loss: 0.2507 - val_mae: 0.4995\n",
      "Epoch 333/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2570 - mae: 0.5035 - val_loss: 0.2505 - val_mae: 0.4987\n",
      "Epoch 334/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2436 - mae: 0.4899 - val_loss: 0.2522 - val_mae: 0.5000\n",
      "Epoch 335/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2538 - mae: 0.5005 - val_loss: 0.2520 - val_mae: 0.4999\n",
      "Epoch 336/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2432 - mae: 0.4896 - val_loss: 0.2527 - val_mae: 0.5008\n",
      "Epoch 337/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2464 - mae: 0.4926 - val_loss: 0.2536 - val_mae: 0.5021\n",
      "Epoch 338/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2503 - mae: 0.4973 - val_loss: 0.2531 - val_mae: 0.5021\n",
      "Epoch 339/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2504 - mae: 0.4984 - val_loss: 0.2531 - val_mae: 0.5017\n",
      "Epoch 340/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2459 - mae: 0.4930 - val_loss: 0.2534 - val_mae: 0.5017\n",
      "Epoch 341/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2514 - mae: 0.4971 - val_loss: 0.2527 - val_mae: 0.5014\n",
      "Epoch 342/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2498 - mae: 0.4956 - val_loss: 0.2540 - val_mae: 0.5030\n",
      "Epoch 343/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2457 - mae: 0.4929 - val_loss: 0.2563 - val_mae: 0.5050\n",
      "Epoch 344/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2426 - mae: 0.4886 - val_loss: 0.2566 - val_mae: 0.5052\n",
      "Epoch 345/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2543 - mae: 0.5012 - val_loss: 0.2560 - val_mae: 0.5047\n",
      "Epoch 346/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2523 - mae: 0.4994 - val_loss: 0.2566 - val_mae: 0.5052\n",
      "Epoch 347/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2391 - mae: 0.4855 - val_loss: 0.2561 - val_mae: 0.5046\n",
      "Epoch 348/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2440 - mae: 0.4907 - val_loss: 0.2564 - val_mae: 0.5046\n",
      "Epoch 349/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2416 - mae: 0.4890 - val_loss: 0.2549 - val_mae: 0.5032\n",
      "Epoch 350/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2493 - mae: 0.4959 - val_loss: 0.2527 - val_mae: 0.5013\n",
      "Epoch 351/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2572 - mae: 0.5044 - val_loss: 0.2524 - val_mae: 0.5011\n",
      "Epoch 352/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2462 - mae: 0.4929 - val_loss: 0.2524 - val_mae: 0.5009\n",
      "Epoch 353/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2485 - mae: 0.4948 - val_loss: 0.2504 - val_mae: 0.4991\n",
      "Epoch 354/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2486 - mae: 0.4957 - val_loss: 0.2502 - val_mae: 0.4988\n",
      "Epoch 355/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2497 - mae: 0.4966 - val_loss: 0.2490 - val_mae: 0.4977\n",
      "Epoch 356/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2530 - mae: 0.4980 - val_loss: 0.2479 - val_mae: 0.4964\n",
      "Epoch 357/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2385 - mae: 0.4857 - val_loss: 0.2486 - val_mae: 0.4966\n",
      "Epoch 358/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2391 - mae: 0.4847 - val_loss: 0.2488 - val_mae: 0.4965\n",
      "Epoch 359/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2549 - mae: 0.5001 - val_loss: 0.2473 - val_mae: 0.4950\n",
      "Epoch 360/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2548 - mae: 0.5013 - val_loss: 0.2453 - val_mae: 0.4935\n",
      "Epoch 361/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2374 - mae: 0.4838 - val_loss: 0.2451 - val_mae: 0.4934\n",
      "Epoch 362/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2503 - mae: 0.4974 - val_loss: 0.2454 - val_mae: 0.4937\n",
      "Epoch 363/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2516 - mae: 0.4981 - val_loss: 0.2459 - val_mae: 0.4945\n",
      "Epoch 364/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2437 - mae: 0.4912 - val_loss: 0.2483 - val_mae: 0.4967\n",
      "Epoch 365/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2494 - mae: 0.4964 - val_loss: 0.2499 - val_mae: 0.4980\n",
      "Epoch 366/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2487 - mae: 0.4951 - val_loss: 0.2513 - val_mae: 0.4995\n",
      "Epoch 367/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2478 - mae: 0.4939 - val_loss: 0.2515 - val_mae: 0.5000\n",
      "Epoch 368/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.2505 - mae: 0.4966 - val_loss: 0.2512 - val_mae: 0.4996\n",
      "Epoch 369/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2440 - mae: 0.4905 - val_loss: 0.2514 - val_mae: 0.5000\n",
      "Epoch 370/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2435 - mae: 0.4905 - val_loss: 0.2520 - val_mae: 0.5002\n",
      "Epoch 371/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2565 - mae: 0.5033 - val_loss: 0.2507 - val_mae: 0.4990\n",
      "Epoch 372/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2563 - mae: 0.5027 - val_loss: 0.2487 - val_mae: 0.4972\n",
      "Epoch 373/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2434 - mae: 0.4906 - val_loss: 0.2486 - val_mae: 0.4969\n",
      "Epoch 374/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2470 - mae: 0.4936 - val_loss: 0.2477 - val_mae: 0.4963\n",
      "Epoch 375/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2471 - mae: 0.4941 - val_loss: 0.2469 - val_mae: 0.4955\n",
      "Epoch 376/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2503 - mae: 0.4976 - val_loss: 0.2483 - val_mae: 0.4968\n",
      "Epoch 377/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2486 - mae: 0.4963 - val_loss: 0.2488 - val_mae: 0.4974\n",
      "Epoch 378/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2423 - mae: 0.4894 - val_loss: 0.2518 - val_mae: 0.5000\n",
      "Epoch 379/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2471 - mae: 0.4936 - val_loss: 0.2547 - val_mae: 0.5025\n",
      "Epoch 380/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2350 - mae: 0.4792 - val_loss: 0.2557 - val_mae: 0.5033\n",
      "Epoch 381/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2442 - mae: 0.4888 - val_loss: 0.2555 - val_mae: 0.5030\n",
      "Epoch 382/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2424 - mae: 0.4882 - val_loss: 0.2538 - val_mae: 0.5015\n",
      "Epoch 383/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2579 - mae: 0.5023 - val_loss: 0.2520 - val_mae: 0.4997\n",
      "Epoch 384/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2546 - mae: 0.4996 - val_loss: 0.2501 - val_mae: 0.4982\n",
      "Epoch 385/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2519 - mae: 0.4975 - val_loss: 0.2493 - val_mae: 0.4973\n",
      "Epoch 386/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2338 - mae: 0.4795 - val_loss: 0.2480 - val_mae: 0.4960\n",
      "Epoch 387/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2454 - mae: 0.4914 - val_loss: 0.2475 - val_mae: 0.4954\n",
      "Epoch 388/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2663 - mae: 0.5117 - val_loss: 0.2454 - val_mae: 0.4940\n",
      "Epoch 389/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2462 - mae: 0.4928 - val_loss: 0.2451 - val_mae: 0.4935\n",
      "Epoch 390/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2502 - mae: 0.4979 - val_loss: 0.2460 - val_mae: 0.4940\n",
      "Epoch 391/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2590 - mae: 0.5051 - val_loss: 0.2466 - val_mae: 0.4947\n",
      "Epoch 392/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2442 - mae: 0.4913 - val_loss: 0.2468 - val_mae: 0.4947\n",
      "Epoch 393/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2421 - mae: 0.4882 - val_loss: 0.2488 - val_mae: 0.4961\n",
      "Epoch 394/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2471 - mae: 0.4931 - val_loss: 0.2491 - val_mae: 0.4965\n",
      "Epoch 395/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2474 - mae: 0.4940 - val_loss: 0.2506 - val_mae: 0.4982\n",
      "Epoch 396/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2540 - mae: 0.4993 - val_loss: 0.2517 - val_mae: 0.4989\n",
      "Epoch 397/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2454 - mae: 0.4904 - val_loss: 0.2513 - val_mae: 0.4984\n",
      "Epoch 398/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2593 - mae: 0.5048 - val_loss: 0.2506 - val_mae: 0.4980\n",
      "Epoch 399/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2440 - mae: 0.4899 - val_loss: 0.2482 - val_mae: 0.4960\n",
      "Epoch 400/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2344 - mae: 0.4786 - val_loss: 0.2464 - val_mae: 0.4945\n",
      "Epoch 401/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2508 - mae: 0.4965 - val_loss: 0.2448 - val_mae: 0.4931\n",
      "Epoch 402/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2512 - mae: 0.4986 - val_loss: 0.2484 - val_mae: 0.4967\n",
      "Epoch 403/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2462 - mae: 0.4933 - val_loss: 0.2479 - val_mae: 0.4961\n",
      "Epoch 404/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2458 - mae: 0.4925 - val_loss: 0.2477 - val_mae: 0.4958\n",
      "Epoch 405/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2482 - mae: 0.4947 - val_loss: 0.2467 - val_mae: 0.4948\n",
      "Epoch 406/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2480 - mae: 0.4952 - val_loss: 0.2472 - val_mae: 0.4953\n",
      "Epoch 407/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2485 - mae: 0.4927 - val_loss: 0.2486 - val_mae: 0.4967\n",
      "Epoch 408/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2513 - mae: 0.4974 - val_loss: 0.2484 - val_mae: 0.4965\n",
      "Epoch 409/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2442 - mae: 0.4892 - val_loss: 0.2481 - val_mae: 0.4963\n",
      "Epoch 410/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2380 - mae: 0.4848 - val_loss: 0.2502 - val_mae: 0.4976\n",
      "Epoch 411/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2504 - mae: 0.4954 - val_loss: 0.2512 - val_mae: 0.4984\n",
      "Epoch 412/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2403 - mae: 0.4847 - val_loss: 0.2508 - val_mae: 0.4980\n",
      "Epoch 413/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2528 - mae: 0.4992 - val_loss: 0.2488 - val_mae: 0.4968\n",
      "Epoch 414/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2411 - mae: 0.4877 - val_loss: 0.2470 - val_mae: 0.4953\n",
      "Epoch 415/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2534 - mae: 0.5004 - val_loss: 0.2447 - val_mae: 0.4931\n",
      "Epoch 416/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2452 - mae: 0.4916 - val_loss: 0.2437 - val_mae: 0.4921\n",
      "Epoch 417/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2440 - mae: 0.4906 - val_loss: 0.2449 - val_mae: 0.4931\n",
      "Epoch 418/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2458 - mae: 0.4920 - val_loss: 0.2477 - val_mae: 0.4958\n",
      "Epoch 419/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2428 - mae: 0.4884 - val_loss: 0.2499 - val_mae: 0.4971\n",
      "Epoch 420/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2502 - mae: 0.4942 - val_loss: 0.2508 - val_mae: 0.4985\n",
      "Epoch 421/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2521 - mae: 0.4980 - val_loss: 0.2516 - val_mae: 0.4996\n",
      "Epoch 422/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2498 - mae: 0.4941 - val_loss: 0.2520 - val_mae: 0.4997\n",
      "Epoch 423/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2381 - mae: 0.4844 - val_loss: 0.2491 - val_mae: 0.4972\n",
      "Epoch 424/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2456 - mae: 0.4919 - val_loss: 0.2486 - val_mae: 0.4969\n",
      "Epoch 425/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2420 - mae: 0.4879 - val_loss: 0.2482 - val_mae: 0.4963\n",
      "Epoch 426/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2466 - mae: 0.4927 - val_loss: 0.2496 - val_mae: 0.4974\n",
      "Epoch 427/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2436 - mae: 0.4897 - val_loss: 0.2508 - val_mae: 0.4985\n",
      "Epoch 428/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2447 - mae: 0.4902 - val_loss: 0.2522 - val_mae: 0.4996\n",
      "Epoch 429/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2375 - mae: 0.4831 - val_loss: 0.2559 - val_mae: 0.5023\n",
      "Epoch 430/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2495 - mae: 0.4922 - val_loss: 0.2583 - val_mae: 0.5043\n",
      "Epoch 431/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2464 - mae: 0.4912 - val_loss: 0.2568 - val_mae: 0.5023\n",
      "Epoch 432/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2438 - mae: 0.4866 - val_loss: 0.2533 - val_mae: 0.4988\n",
      "Epoch 433/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2492 - mae: 0.4928 - val_loss: 0.2526 - val_mae: 0.4985\n",
      "Epoch 434/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2536 - mae: 0.4997 - val_loss: 0.2532 - val_mae: 0.4999\n",
      "Epoch 435/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2470 - mae: 0.4935 - val_loss: 0.2538 - val_mae: 0.5004\n",
      "Epoch 436/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2491 - mae: 0.4943 - val_loss: 0.2538 - val_mae: 0.5008\n",
      "Epoch 437/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2477 - mae: 0.4938 - val_loss: 0.2537 - val_mae: 0.5014\n",
      "Epoch 438/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2483 - mae: 0.4952 - val_loss: 0.2540 - val_mae: 0.5020\n",
      "Epoch 439/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2399 - mae: 0.4864 - val_loss: 0.2514 - val_mae: 0.4997\n",
      "Epoch 440/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2372 - mae: 0.4834 - val_loss: 0.2525 - val_mae: 0.5008\n",
      "Epoch 441/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2558 - mae: 0.5028 - val_loss: 0.2502 - val_mae: 0.4989\n",
      "Epoch 442/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2481 - mae: 0.4959 - val_loss: 0.2464 - val_mae: 0.4952\n",
      "Epoch 443/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2470 - mae: 0.4932 - val_loss: 0.2446 - val_mae: 0.4933\n",
      "Epoch 444/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2516 - mae: 0.4999 - val_loss: 0.2457 - val_mae: 0.4941\n",
      "Epoch 445/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2492 - mae: 0.4968 - val_loss: 0.2446 - val_mae: 0.4930\n",
      "Epoch 446/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2457 - mae: 0.4934 - val_loss: 0.2457 - val_mae: 0.4944\n",
      "Epoch 447/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2378 - mae: 0.4853 - val_loss: 0.2455 - val_mae: 0.4941\n",
      "Epoch 448/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2463 - mae: 0.4933 - val_loss: 0.2449 - val_mae: 0.4934\n",
      "Epoch 449/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2445 - mae: 0.4920 - val_loss: 0.2460 - val_mae: 0.4946\n",
      "Epoch 450/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2423 - mae: 0.4883 - val_loss: 0.2465 - val_mae: 0.4952\n",
      "Epoch 451/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2450 - mae: 0.4908 - val_loss: 0.2474 - val_mae: 0.4960\n",
      "Epoch 452/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2466 - mae: 0.4933 - val_loss: 0.2475 - val_mae: 0.4955\n",
      "Epoch 453/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2396 - mae: 0.4858 - val_loss: 0.2469 - val_mae: 0.4951\n",
      "Epoch 454/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2393 - mae: 0.4867 - val_loss: 0.2482 - val_mae: 0.4962\n",
      "Epoch 455/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2466 - mae: 0.4925 - val_loss: 0.2491 - val_mae: 0.4969\n",
      "Epoch 456/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2395 - mae: 0.4868 - val_loss: 0.2496 - val_mae: 0.4971\n",
      "Epoch 457/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2387 - mae: 0.4841 - val_loss: 0.2497 - val_mae: 0.4968\n",
      "Epoch 458/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2521 - mae: 0.4973 - val_loss: 0.2474 - val_mae: 0.4946\n",
      "Epoch 459/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2501 - mae: 0.4955 - val_loss: 0.2469 - val_mae: 0.4942\n",
      "Epoch 460/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2488 - mae: 0.4945 - val_loss: 0.2483 - val_mae: 0.4957\n",
      "Epoch 461/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2576 - mae: 0.5035 - val_loss: 0.2469 - val_mae: 0.4946\n",
      "Epoch 462/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2457 - mae: 0.4925 - val_loss: 0.2467 - val_mae: 0.4944\n",
      "Epoch 463/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2481 - mae: 0.4948 - val_loss: 0.2491 - val_mae: 0.4968\n",
      "Epoch 464/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2450 - mae: 0.4922 - val_loss: 0.2493 - val_mae: 0.4971\n",
      "Epoch 465/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2419 - mae: 0.4882 - val_loss: 0.2481 - val_mae: 0.4960\n",
      "Epoch 466/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2472 - mae: 0.4926 - val_loss: 0.2478 - val_mae: 0.4953\n",
      "Epoch 467/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2528 - mae: 0.4988 - val_loss: 0.2489 - val_mae: 0.4962\n",
      "Epoch 468/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2533 - mae: 0.4996 - val_loss: 0.2495 - val_mae: 0.4968\n",
      "Epoch 469/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2349 - mae: 0.4805 - val_loss: 0.2509 - val_mae: 0.4972\n",
      "Epoch 470/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2430 - mae: 0.4880 - val_loss: 0.2495 - val_mae: 0.4960\n",
      "Epoch 471/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2567 - mae: 0.5018 - val_loss: 0.2446 - val_mae: 0.4919\n",
      "Epoch 472/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2404 - mae: 0.4870 - val_loss: 0.2432 - val_mae: 0.4905\n",
      "Epoch 473/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2399 - mae: 0.4847 - val_loss: 0.2417 - val_mae: 0.4889\n",
      "Epoch 474/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2370 - mae: 0.4823 - val_loss: 0.2404 - val_mae: 0.4879\n",
      "Epoch 475/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2387 - mae: 0.4845 - val_loss: 0.2386 - val_mae: 0.4862\n",
      "Epoch 476/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2474 - mae: 0.4928 - val_loss: 0.2395 - val_mae: 0.4866\n",
      "Epoch 477/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2340 - mae: 0.4777 - val_loss: 0.2392 - val_mae: 0.4861\n",
      "Epoch 478/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2452 - mae: 0.4911 - val_loss: 0.2407 - val_mae: 0.4872\n",
      "Epoch 479/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2525 - mae: 0.4969 - val_loss: 0.2408 - val_mae: 0.4869\n",
      "Epoch 480/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2483 - mae: 0.4894 - val_loss: 0.2430 - val_mae: 0.4887\n",
      "Epoch 481/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2418 - mae: 0.4847 - val_loss: 0.2475 - val_mae: 0.4936\n",
      "Epoch 482/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2390 - mae: 0.4829 - val_loss: 0.2502 - val_mae: 0.4965\n",
      "Epoch 483/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2435 - mae: 0.4890 - val_loss: 0.2507 - val_mae: 0.4973\n",
      "Epoch 484/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2404 - mae: 0.4856 - val_loss: 0.2478 - val_mae: 0.4948\n",
      "Epoch 485/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2482 - mae: 0.4947 - val_loss: 0.2432 - val_mae: 0.4906\n",
      "Epoch 486/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2478 - mae: 0.4935 - val_loss: 0.2428 - val_mae: 0.4904\n",
      "Epoch 487/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2474 - mae: 0.4936 - val_loss: 0.2418 - val_mae: 0.4892\n",
      "Epoch 488/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2405 - mae: 0.4859 - val_loss: 0.2411 - val_mae: 0.4877\n",
      "Epoch 489/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2395 - mae: 0.4823 - val_loss: 0.2395 - val_mae: 0.4857\n",
      "Epoch 490/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2366 - mae: 0.4804 - val_loss: 0.2398 - val_mae: 0.4864\n",
      "Epoch 491/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2490 - mae: 0.4931 - val_loss: 0.2382 - val_mae: 0.4854\n",
      "Epoch 492/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2410 - mae: 0.4871 - val_loss: 0.2386 - val_mae: 0.4863\n",
      "Epoch 493/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2415 - mae: 0.4882 - val_loss: 0.2385 - val_mae: 0.4866\n",
      "Epoch 494/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2369 - mae: 0.4827 - val_loss: 0.2377 - val_mae: 0.4857\n",
      "Epoch 495/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2471 - mae: 0.4939 - val_loss: 0.2374 - val_mae: 0.4852\n",
      "Epoch 496/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2476 - mae: 0.4917 - val_loss: 0.2392 - val_mae: 0.4856\n",
      "Epoch 497/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2427 - mae: 0.4865 - val_loss: 0.2416 - val_mae: 0.4872\n",
      "Epoch 498/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2422 - mae: 0.4868 - val_loss: 0.2408 - val_mae: 0.4863\n",
      "Epoch 499/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2448 - mae: 0.4904 - val_loss: 0.2403 - val_mae: 0.4867\n",
      "Epoch 500/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2376 - mae: 0.4827 - val_loss: 0.2412 - val_mae: 0.4873\n",
      "Epoch 501/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2497 - mae: 0.4939 - val_loss: 0.2388 - val_mae: 0.4843\n",
      "Epoch 502/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2376 - mae: 0.4817 - val_loss: 0.2389 - val_mae: 0.4844\n",
      "Epoch 503/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2360 - mae: 0.4780 - val_loss: 0.2380 - val_mae: 0.4837\n",
      "Epoch 504/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2446 - mae: 0.4867 - val_loss: 0.2386 - val_mae: 0.4842\n",
      "Epoch 505/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2353 - mae: 0.4800 - val_loss: 0.2349 - val_mae: 0.4805\n",
      "Epoch 506/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2465 - mae: 0.4914 - val_loss: 0.2327 - val_mae: 0.4783\n",
      "Epoch 507/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2443 - mae: 0.4881 - val_loss: 0.2295 - val_mae: 0.4752\n",
      "Epoch 508/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2558 - mae: 0.5004 - val_loss: 0.2278 - val_mae: 0.4738\n",
      "Epoch 509/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2363 - mae: 0.4812 - val_loss: 0.2264 - val_mae: 0.4717\n",
      "Epoch 510/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2450 - mae: 0.4906 - val_loss: 0.2292 - val_mae: 0.4741\n",
      "Epoch 511/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2385 - mae: 0.4827 - val_loss: 0.2333 - val_mae: 0.4777\n",
      "Epoch 512/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2430 - mae: 0.4853 - val_loss: 0.2348 - val_mae: 0.4786\n",
      "Epoch 513/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2496 - mae: 0.4938 - val_loss: 0.2373 - val_mae: 0.4811\n",
      "Epoch 514/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2503 - mae: 0.4937 - val_loss: 0.2382 - val_mae: 0.4818\n",
      "Epoch 515/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2323 - mae: 0.4746 - val_loss: 0.2414 - val_mae: 0.4824\n",
      "Epoch 516/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2292 - mae: 0.4714 - val_loss: 0.2433 - val_mae: 0.4844\n",
      "Epoch 517/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2295 - mae: 0.4682 - val_loss: 0.2444 - val_mae: 0.4856\n",
      "Epoch 518/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2418 - mae: 0.4848 - val_loss: 0.2407 - val_mae: 0.4828\n",
      "Epoch 519/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2323 - mae: 0.4745 - val_loss: 0.2409 - val_mae: 0.4835\n",
      "Epoch 520/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2424 - mae: 0.4814 - val_loss: 0.2404 - val_mae: 0.4819\n",
      "Epoch 521/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2363 - mae: 0.4766 - val_loss: 0.2403 - val_mae: 0.4817\n",
      "Epoch 522/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2352 - mae: 0.4738 - val_loss: 0.2338 - val_mae: 0.4765\n",
      "Epoch 523/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2217 - mae: 0.4645 - val_loss: 0.2290 - val_mae: 0.4720\n",
      "Epoch 524/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2436 - mae: 0.4857 - val_loss: 0.2252 - val_mae: 0.4681\n",
      "Epoch 525/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2439 - mae: 0.4878 - val_loss: 0.2308 - val_mae: 0.4727\n",
      "Epoch 526/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2490 - mae: 0.4938 - val_loss: 0.2320 - val_mae: 0.4732\n",
      "Epoch 527/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2422 - mae: 0.4827 - val_loss: 0.2313 - val_mae: 0.4714\n",
      "Epoch 528/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2445 - mae: 0.4846 - val_loss: 0.2248 - val_mae: 0.4644\n",
      "Epoch 529/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2435 - mae: 0.4829 - val_loss: 0.2213 - val_mae: 0.4599\n",
      "Epoch 530/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2346 - mae: 0.4740 - val_loss: 0.2196 - val_mae: 0.4576\n",
      "Epoch 531/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2491 - mae: 0.4898 - val_loss: 0.2211 - val_mae: 0.4610\n",
      "Epoch 532/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2336 - mae: 0.4755 - val_loss: 0.2225 - val_mae: 0.4634\n",
      "Epoch 533/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2454 - mae: 0.4874 - val_loss: 0.2243 - val_mae: 0.4651\n",
      "Epoch 534/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2390 - mae: 0.4805 - val_loss: 0.2243 - val_mae: 0.4638\n",
      "Epoch 535/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2395 - mae: 0.4815 - val_loss: 0.2249 - val_mae: 0.4645\n",
      "Epoch 536/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2452 - mae: 0.4841 - val_loss: 0.2257 - val_mae: 0.4658\n",
      "Epoch 537/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2383 - mae: 0.4782 - val_loss: 0.2244 - val_mae: 0.4640\n",
      "Epoch 538/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2250 - mae: 0.4652 - val_loss: 0.2232 - val_mae: 0.4623\n",
      "Epoch 539/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2513 - mae: 0.4940 - val_loss: 0.2233 - val_mae: 0.4643\n",
      "Epoch 540/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2374 - mae: 0.4795 - val_loss: 0.2230 - val_mae: 0.4624\n",
      "Epoch 541/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2421 - mae: 0.4841 - val_loss: 0.2224 - val_mae: 0.4621\n",
      "Epoch 542/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2240 - mae: 0.4653 - val_loss: 0.2218 - val_mae: 0.4618\n",
      "Epoch 543/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2390 - mae: 0.4775 - val_loss: 0.2232 - val_mae: 0.4627\n",
      "Epoch 544/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2380 - mae: 0.4799 - val_loss: 0.2225 - val_mae: 0.4617\n",
      "Epoch 545/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2356 - mae: 0.4795 - val_loss: 0.2201 - val_mae: 0.4585\n",
      "Epoch 546/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2224 - mae: 0.4624 - val_loss: 0.2189 - val_mae: 0.4552\n",
      "Epoch 547/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2342 - mae: 0.4726 - val_loss: 0.2193 - val_mae: 0.4546\n",
      "Epoch 548/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2347 - mae: 0.4742 - val_loss: 0.2222 - val_mae: 0.4572\n",
      "Epoch 549/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2292 - mae: 0.4661 - val_loss: 0.2245 - val_mae: 0.4575\n",
      "Epoch 550/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2524 - mae: 0.4890 - val_loss: 0.2265 - val_mae: 0.4585\n",
      "Epoch 551/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2571 - mae: 0.4949 - val_loss: 0.2228 - val_mae: 0.4573\n",
      "Epoch 552/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2168 - mae: 0.4520 - val_loss: 0.2235 - val_mae: 0.4590\n",
      "Epoch 553/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2413 - mae: 0.4820 - val_loss: 0.2228 - val_mae: 0.4596\n",
      "Epoch 554/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2439 - mae: 0.4827 - val_loss: 0.2201 - val_mae: 0.4573\n",
      "Epoch 555/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2249 - mae: 0.4663 - val_loss: 0.2195 - val_mae: 0.4555\n",
      "Epoch 556/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2373 - mae: 0.4784 - val_loss: 0.2184 - val_mae: 0.4539\n",
      "Epoch 557/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2344 - mae: 0.4720 - val_loss: 0.2155 - val_mae: 0.4498\n",
      "Epoch 558/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2413 - mae: 0.4800 - val_loss: 0.2130 - val_mae: 0.4473\n",
      "Epoch 559/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2573 - mae: 0.4977 - val_loss: 0.2116 - val_mae: 0.4460\n",
      "Epoch 560/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2305 - mae: 0.4700 - val_loss: 0.2118 - val_mae: 0.4455\n",
      "Epoch 561/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2314 - mae: 0.4712 - val_loss: 0.2124 - val_mae: 0.4457\n",
      "Epoch 562/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2463 - mae: 0.4868 - val_loss: 0.2155 - val_mae: 0.4465\n",
      "Epoch 563/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2289 - mae: 0.4673 - val_loss: 0.2153 - val_mae: 0.4467\n",
      "Epoch 564/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2237 - mae: 0.4578 - val_loss: 0.2161 - val_mae: 0.4469\n",
      "Epoch 565/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2365 - mae: 0.4747 - val_loss: 0.2175 - val_mae: 0.4500\n",
      "Epoch 566/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2327 - mae: 0.4720 - val_loss: 0.2173 - val_mae: 0.4486\n",
      "Epoch 567/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2248 - mae: 0.4601 - val_loss: 0.2153 - val_mae: 0.4449\n",
      "Epoch 568/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2300 - mae: 0.4709 - val_loss: 0.2181 - val_mae: 0.4476\n",
      "Epoch 569/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2350 - mae: 0.4705 - val_loss: 0.2179 - val_mae: 0.4459\n",
      "Epoch 570/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2390 - mae: 0.4733 - val_loss: 0.2191 - val_mae: 0.4463\n",
      "Epoch 571/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2405 - mae: 0.4748 - val_loss: 0.2183 - val_mae: 0.4453\n",
      "Epoch 572/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2272 - mae: 0.4640 - val_loss: 0.2176 - val_mae: 0.4445\n",
      "Epoch 573/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2367 - mae: 0.4669 - val_loss: 0.2172 - val_mae: 0.4435\n",
      "Epoch 574/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2448 - mae: 0.4809 - val_loss: 0.2148 - val_mae: 0.4411\n",
      "Epoch 575/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2229 - mae: 0.4530 - val_loss: 0.2150 - val_mae: 0.4400\n",
      "Epoch 576/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2422 - mae: 0.4785 - val_loss: 0.2099 - val_mae: 0.4363\n",
      "Epoch 577/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2384 - mae: 0.4737 - val_loss: 0.2060 - val_mae: 0.4334\n",
      "Epoch 578/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2242 - mae: 0.4594 - val_loss: 0.2040 - val_mae: 0.4318\n",
      "Epoch 579/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2265 - mae: 0.4621 - val_loss: 0.2032 - val_mae: 0.4303\n",
      "Epoch 580/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2417 - mae: 0.4797 - val_loss: 0.2055 - val_mae: 0.4316\n",
      "Epoch 581/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2273 - mae: 0.4597 - val_loss: 0.2050 - val_mae: 0.4298\n",
      "Epoch 582/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2274 - mae: 0.4619 - val_loss: 0.2080 - val_mae: 0.4313\n",
      "Epoch 583/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2383 - mae: 0.4741 - val_loss: 0.2075 - val_mae: 0.4311\n",
      "Epoch 584/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2490 - mae: 0.4846 - val_loss: 0.2078 - val_mae: 0.4318\n",
      "Epoch 585/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2284 - mae: 0.4648 - val_loss: 0.2095 - val_mae: 0.4317\n",
      "Epoch 586/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2274 - mae: 0.4597 - val_loss: 0.2068 - val_mae: 0.4276\n",
      "Epoch 587/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2202 - mae: 0.4481 - val_loss: 0.2066 - val_mae: 0.4266\n",
      "Epoch 588/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2210 - mae: 0.4458 - val_loss: 0.2036 - val_mae: 0.4241\n",
      "Epoch 589/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2346 - mae: 0.4696 - val_loss: 0.2055 - val_mae: 0.4260\n",
      "Epoch 590/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2271 - mae: 0.4544 - val_loss: 0.2037 - val_mae: 0.4232\n",
      "Epoch 591/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2359 - mae: 0.4623 - val_loss: 0.2042 - val_mae: 0.4219\n",
      "Epoch 592/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2287 - mae: 0.4603 - val_loss: 0.2005 - val_mae: 0.4184\n",
      "Epoch 593/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2459 - mae: 0.4788 - val_loss: 0.2007 - val_mae: 0.4194\n",
      "Epoch 594/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2518 - mae: 0.4833 - val_loss: 0.2041 - val_mae: 0.4216\n",
      "Epoch 595/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2396 - mae: 0.4747 - val_loss: 0.1984 - val_mae: 0.4172\n",
      "Epoch 596/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2144 - mae: 0.4457 - val_loss: 0.1970 - val_mae: 0.4151\n",
      "Epoch 597/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2539 - mae: 0.4897 - val_loss: 0.1992 - val_mae: 0.4168\n",
      "Epoch 598/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2341 - mae: 0.4656 - val_loss: 0.1976 - val_mae: 0.4162\n",
      "Epoch 599/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2320 - mae: 0.4625 - val_loss: 0.1947 - val_mae: 0.4149\n",
      "Epoch 600/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2124 - mae: 0.4410 - val_loss: 0.1973 - val_mae: 0.4170\n",
      "Epoch 601/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2253 - mae: 0.4557 - val_loss: 0.1996 - val_mae: 0.4170\n",
      "Epoch 602/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2513 - mae: 0.4826 - val_loss: 0.2018 - val_mae: 0.4164\n",
      "Epoch 603/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2375 - mae: 0.4643 - val_loss: 0.2012 - val_mae: 0.4126\n",
      "Epoch 604/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2366 - mae: 0.4595 - val_loss: 0.2077 - val_mae: 0.4191\n",
      "Epoch 605/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2356 - mae: 0.4624 - val_loss: 0.2059 - val_mae: 0.4206\n",
      "Epoch 606/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2389 - mae: 0.4687 - val_loss: 0.2026 - val_mae: 0.4192\n",
      "Epoch 607/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2443 - mae: 0.4754 - val_loss: 0.2032 - val_mae: 0.4222\n",
      "Epoch 608/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2259 - mae: 0.4582 - val_loss: 0.2018 - val_mae: 0.4204\n",
      "Epoch 609/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2233 - mae: 0.4485 - val_loss: 0.2011 - val_mae: 0.4156\n",
      "Epoch 610/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2435 - mae: 0.4711 - val_loss: 0.2021 - val_mae: 0.4161\n",
      "Epoch 611/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2258 - mae: 0.4481 - val_loss: 0.2047 - val_mae: 0.4175\n",
      "Epoch 612/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2420 - mae: 0.4700 - val_loss: 0.2040 - val_mae: 0.4188\n",
      "Epoch 613/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2319 - mae: 0.4574 - val_loss: 0.2004 - val_mae: 0.4188\n",
      "Epoch 614/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2560 - mae: 0.4864 - val_loss: 0.1993 - val_mae: 0.4187\n",
      "Epoch 615/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2258 - mae: 0.4540 - val_loss: 0.1961 - val_mae: 0.4164\n",
      "Epoch 616/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2380 - mae: 0.4679 - val_loss: 0.1922 - val_mae: 0.4105\n",
      "Epoch 617/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2348 - mae: 0.4719 - val_loss: 0.1915 - val_mae: 0.4112\n",
      "Epoch 618/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2192 - mae: 0.4488 - val_loss: 0.1931 - val_mae: 0.4099\n",
      "Epoch 619/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2354 - mae: 0.4652 - val_loss: 0.1952 - val_mae: 0.4108\n",
      "Epoch 620/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2496 - mae: 0.4827 - val_loss: 0.1999 - val_mae: 0.4182\n",
      "Epoch 621/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2102 - mae: 0.4331 - val_loss: 0.2036 - val_mae: 0.4224\n",
      "Epoch 622/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2304 - mae: 0.4597 - val_loss: 0.2090 - val_mae: 0.4275\n",
      "Epoch 623/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.2435 - mae: 0.4747 - val_loss: 0.2066 - val_mae: 0.4252\n",
      "Epoch 624/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2113 - mae: 0.4367 - val_loss: 0.2080 - val_mae: 0.4247\n",
      "Epoch 625/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2220 - mae: 0.4473 - val_loss: 0.2051 - val_mae: 0.4217\n",
      "Epoch 626/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2337 - mae: 0.4633 - val_loss: 0.2030 - val_mae: 0.4207\n",
      "Epoch 627/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2313 - mae: 0.4612 - val_loss: 0.2003 - val_mae: 0.4181\n",
      "Epoch 628/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2301 - mae: 0.4621 - val_loss: 0.1987 - val_mae: 0.4153\n",
      "Epoch 629/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2240 - mae: 0.4490 - val_loss: 0.1980 - val_mae: 0.4135\n",
      "Epoch 630/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2066 - mae: 0.4307 - val_loss: 0.1952 - val_mae: 0.4103\n",
      "Epoch 631/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2236 - mae: 0.4527 - val_loss: 0.1921 - val_mae: 0.4054\n",
      "Epoch 632/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2711 - mae: 0.5005 - val_loss: 0.1967 - val_mae: 0.4111\n",
      "Epoch 633/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2281 - mae: 0.4592 - val_loss: 0.1945 - val_mae: 0.4099\n",
      "Epoch 634/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2118 - mae: 0.4396 - val_loss: 0.1924 - val_mae: 0.4085\n",
      "Epoch 635/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2433 - mae: 0.4736 - val_loss: 0.1922 - val_mae: 0.4089\n",
      "Epoch 636/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2320 - mae: 0.4590 - val_loss: 0.1950 - val_mae: 0.4143\n",
      "Epoch 637/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2330 - mae: 0.4641 - val_loss: 0.1964 - val_mae: 0.4167\n",
      "Epoch 638/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2389 - mae: 0.4726 - val_loss: 0.1985 - val_mae: 0.4175\n",
      "Epoch 639/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2327 - mae: 0.4677 - val_loss: 0.2005 - val_mae: 0.4177\n",
      "Epoch 640/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2233 - mae: 0.4530 - val_loss: 0.2016 - val_mae: 0.4169\n",
      "Epoch 641/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2270 - mae: 0.4499 - val_loss: 0.2009 - val_mae: 0.4149\n",
      "Epoch 642/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2279 - mae: 0.4593 - val_loss: 0.1979 - val_mae: 0.4146\n",
      "Epoch 643/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2339 - mae: 0.4663 - val_loss: 0.1983 - val_mae: 0.4159\n",
      "Epoch 644/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2279 - mae: 0.4642 - val_loss: 0.1976 - val_mae: 0.4152\n",
      "Epoch 645/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2277 - mae: 0.4608 - val_loss: 0.1998 - val_mae: 0.4174\n",
      "Epoch 646/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2213 - mae: 0.4530 - val_loss: 0.2017 - val_mae: 0.4180\n",
      "Epoch 647/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2289 - mae: 0.4583 - val_loss: 0.2025 - val_mae: 0.4152\n",
      "Epoch 648/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2253 - mae: 0.4564 - val_loss: 0.2014 - val_mae: 0.4136\n",
      "Epoch 649/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2322 - mae: 0.4615 - val_loss: 0.2003 - val_mae: 0.4117\n",
      "Epoch 650/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2589 - mae: 0.4866 - val_loss: 0.1959 - val_mae: 0.4100\n",
      "Epoch 651/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2374 - mae: 0.4592 - val_loss: 0.1996 - val_mae: 0.4149\n",
      "Epoch 652/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2243 - mae: 0.4531 - val_loss: 0.1991 - val_mae: 0.4147\n",
      "Epoch 653/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2299 - mae: 0.4627 - val_loss: 0.2012 - val_mae: 0.4144\n",
      "Epoch 654/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2394 - mae: 0.4750 - val_loss: 0.1987 - val_mae: 0.4114\n",
      "Epoch 655/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2298 - mae: 0.4661 - val_loss: 0.1958 - val_mae: 0.4075\n",
      "Epoch 656/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2153 - mae: 0.4411 - val_loss: 0.1952 - val_mae: 0.4050\n",
      "Epoch 657/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2327 - mae: 0.4660 - val_loss: 0.1952 - val_mae: 0.4053\n",
      "Epoch 658/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2306 - mae: 0.4599 - val_loss: 0.1956 - val_mae: 0.4050\n",
      "Epoch 659/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2162 - mae: 0.4389 - val_loss: 0.1958 - val_mae: 0.4051\n",
      "Epoch 660/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2151 - mae: 0.4412 - val_loss: 0.1954 - val_mae: 0.4052\n",
      "Epoch 661/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2241 - mae: 0.4533 - val_loss: 0.1961 - val_mae: 0.4059\n",
      "Epoch 662/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2066 - mae: 0.4303 - val_loss: 0.1972 - val_mae: 0.4064\n",
      "Epoch 663/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2227 - mae: 0.4471 - val_loss: 0.1960 - val_mae: 0.4040\n",
      "Epoch 664/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2312 - mae: 0.4667 - val_loss: 0.1941 - val_mae: 0.3994\n",
      "Epoch 665/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2241 - mae: 0.4500 - val_loss: 0.1951 - val_mae: 0.3968\n",
      "Epoch 666/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2189 - mae: 0.4391 - val_loss: 0.1947 - val_mae: 0.3960\n",
      "Epoch 667/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2320 - mae: 0.4569 - val_loss: 0.1930 - val_mae: 0.3929\n",
      "Epoch 668/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2173 - mae: 0.4453 - val_loss: 0.1852 - val_mae: 0.3848\n",
      "Epoch 669/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2661 - mae: 0.4949 - val_loss: 0.1861 - val_mae: 0.3854\n",
      "Epoch 670/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2229 - mae: 0.4500 - val_loss: 0.1854 - val_mae: 0.3857\n",
      "Epoch 671/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2229 - mae: 0.4505 - val_loss: 0.1826 - val_mae: 0.3852\n",
      "Epoch 672/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2169 - mae: 0.4349 - val_loss: 0.1818 - val_mae: 0.3863\n",
      "Epoch 673/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2223 - mae: 0.4379 - val_loss: 0.1835 - val_mae: 0.3886\n",
      "Epoch 674/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2105 - mae: 0.4273 - val_loss: 0.1852 - val_mae: 0.3905\n",
      "Epoch 675/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2194 - mae: 0.4403 - val_loss: 0.1839 - val_mae: 0.3910\n",
      "Epoch 676/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2274 - mae: 0.4580 - val_loss: 0.1869 - val_mae: 0.3923\n",
      "Epoch 677/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2331 - mae: 0.4607 - val_loss: 0.1888 - val_mae: 0.3943\n",
      "Epoch 678/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2213 - mae: 0.4470 - val_loss: 0.1901 - val_mae: 0.3950\n",
      "Epoch 679/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2313 - mae: 0.4586 - val_loss: 0.1944 - val_mae: 0.3974\n",
      "Epoch 680/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2103 - mae: 0.4374 - val_loss: 0.1977 - val_mae: 0.3995\n",
      "Epoch 681/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2264 - mae: 0.4527 - val_loss: 0.1969 - val_mae: 0.3989\n",
      "Epoch 682/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2240 - mae: 0.4536 - val_loss: 0.1958 - val_mae: 0.3986\n",
      "Epoch 683/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2356 - mae: 0.4654 - val_loss: 0.1965 - val_mae: 0.4007\n",
      "Epoch 684/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2462 - mae: 0.4751 - val_loss: 0.1903 - val_mae: 0.3988\n",
      "Epoch 685/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2276 - mae: 0.4544 - val_loss: 0.1913 - val_mae: 0.4025\n",
      "Epoch 686/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2278 - mae: 0.4615 - val_loss: 0.1926 - val_mae: 0.4059\n",
      "Epoch 687/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2210 - mae: 0.4372 - val_loss: 0.1932 - val_mae: 0.4086\n",
      "Epoch 688/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2241 - mae: 0.4561 - val_loss: 0.1918 - val_mae: 0.4073\n",
      "Epoch 689/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2200 - mae: 0.4446 - val_loss: 0.1913 - val_mae: 0.4019\n",
      "Epoch 690/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2420 - mae: 0.4695 - val_loss: 0.1935 - val_mae: 0.4003\n",
      "Epoch 691/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2245 - mae: 0.4521 - val_loss: 0.1947 - val_mae: 0.4022\n",
      "Epoch 692/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2391 - mae: 0.4591 - val_loss: 0.1969 - val_mae: 0.4068\n",
      "Epoch 693/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2280 - mae: 0.4592 - val_loss: 0.1971 - val_mae: 0.4106\n",
      "Epoch 694/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2174 - mae: 0.4372 - val_loss: 0.1965 - val_mae: 0.4131\n",
      "Epoch 695/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2226 - mae: 0.4516 - val_loss: 0.1985 - val_mae: 0.4160\n",
      "Epoch 696/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2285 - mae: 0.4568 - val_loss: 0.2067 - val_mae: 0.4234\n",
      "Epoch 697/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2405 - mae: 0.4726 - val_loss: 0.2097 - val_mae: 0.4244\n",
      "Epoch 698/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2290 - mae: 0.4551 - val_loss: 0.2103 - val_mae: 0.4246\n",
      "Epoch 699/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2404 - mae: 0.4663 - val_loss: 0.2133 - val_mae: 0.4266\n",
      "Epoch 700/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2295 - mae: 0.4627 - val_loss: 0.2102 - val_mae: 0.4218\n",
      "Epoch 701/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2227 - mae: 0.4520 - val_loss: 0.2090 - val_mae: 0.4189\n",
      "Epoch 702/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2049 - mae: 0.4287 - val_loss: 0.2071 - val_mae: 0.4163\n",
      "Epoch 703/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2267 - mae: 0.4549 - val_loss: 0.2064 - val_mae: 0.4166\n",
      "Epoch 704/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2343 - mae: 0.4598 - val_loss: 0.2059 - val_mae: 0.4176\n",
      "Epoch 705/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2263 - mae: 0.4483 - val_loss: 0.2031 - val_mae: 0.4166\n",
      "Epoch 706/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2263 - mae: 0.4481 - val_loss: 0.2009 - val_mae: 0.4155\n",
      "Epoch 707/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2234 - mae: 0.4458 - val_loss: 0.2001 - val_mae: 0.4133\n",
      "Epoch 708/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2322 - mae: 0.4622 - val_loss: 0.1985 - val_mae: 0.4090\n",
      "Epoch 709/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2285 - mae: 0.4598 - val_loss: 0.1990 - val_mae: 0.4082\n",
      "Epoch 710/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2410 - mae: 0.4685 - val_loss: 0.1994 - val_mae: 0.4085\n",
      "Epoch 711/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2391 - mae: 0.4713 - val_loss: 0.1988 - val_mae: 0.4072\n",
      "Epoch 712/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2231 - mae: 0.4563 - val_loss: 0.1968 - val_mae: 0.4049\n",
      "Epoch 713/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2488 - mae: 0.4817 - val_loss: 0.1968 - val_mae: 0.4062\n",
      "Epoch 714/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2337 - mae: 0.4660 - val_loss: 0.1945 - val_mae: 0.4051\n",
      "Epoch 715/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2258 - mae: 0.4573 - val_loss: 0.1915 - val_mae: 0.4035\n",
      "Epoch 716/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2172 - mae: 0.4360 - val_loss: 0.1919 - val_mae: 0.4023\n",
      "Epoch 717/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2269 - mae: 0.4506 - val_loss: 0.1919 - val_mae: 0.4003\n",
      "Epoch 718/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2257 - mae: 0.4536 - val_loss: 0.1939 - val_mae: 0.3981\n",
      "Epoch 719/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2229 - mae: 0.4504 - val_loss: 0.1968 - val_mae: 0.3969\n",
      "Epoch 720/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2256 - mae: 0.4530 - val_loss: 0.1967 - val_mae: 0.3965\n",
      "Epoch 721/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2259 - mae: 0.4559 - val_loss: 0.1952 - val_mae: 0.3955\n",
      "Epoch 722/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2350 - mae: 0.4631 - val_loss: 0.1950 - val_mae: 0.3951\n",
      "Epoch 723/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2364 - mae: 0.4674 - val_loss: 0.1946 - val_mae: 0.3961\n",
      "Epoch 724/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2269 - mae: 0.4526 - val_loss: 0.1951 - val_mae: 0.3978\n",
      "Epoch 725/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2312 - mae: 0.4576 - val_loss: 0.1938 - val_mae: 0.3975\n",
      "Epoch 726/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2341 - mae: 0.4569 - val_loss: 0.1919 - val_mae: 0.3977\n",
      "Epoch 727/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2453 - mae: 0.4699 - val_loss: 0.1908 - val_mae: 0.4008\n",
      "Epoch 728/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2336 - mae: 0.4570 - val_loss: 0.1926 - val_mae: 0.4041\n",
      "Epoch 729/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2321 - mae: 0.4530 - val_loss: 0.1936 - val_mae: 0.4083\n",
      "Epoch 730/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2354 - mae: 0.4593 - val_loss: 0.1949 - val_mae: 0.4102\n",
      "Epoch 731/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2439 - mae: 0.4789 - val_loss: 0.1957 - val_mae: 0.4116\n",
      "Epoch 732/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2264 - mae: 0.4544 - val_loss: 0.1991 - val_mae: 0.4160\n",
      "Epoch 733/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2446 - mae: 0.4676 - val_loss: 0.2017 - val_mae: 0.4179\n",
      "Epoch 734/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2229 - mae: 0.4472 - val_loss: 0.2058 - val_mae: 0.4217\n",
      "Epoch 735/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2270 - mae: 0.4510 - val_loss: 0.2044 - val_mae: 0.4191\n",
      "Epoch 736/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2394 - mae: 0.4766 - val_loss: 0.2023 - val_mae: 0.4160\n",
      "Epoch 737/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2057 - mae: 0.4296 - val_loss: 0.2022 - val_mae: 0.4142\n",
      "Epoch 738/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2251 - mae: 0.4584 - val_loss: 0.2028 - val_mae: 0.4143\n",
      "Epoch 739/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2242 - mae: 0.4559 - val_loss: 0.2040 - val_mae: 0.4155\n",
      "Epoch 740/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2264 - mae: 0.4497 - val_loss: 0.1987 - val_mae: 0.4106\n",
      "Epoch 741/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2501 - mae: 0.4793 - val_loss: 0.1951 - val_mae: 0.4087\n",
      "Epoch 742/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2393 - mae: 0.4699 - val_loss: 0.1938 - val_mae: 0.4084\n",
      "Epoch 743/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2373 - mae: 0.4714 - val_loss: 0.1928 - val_mae: 0.4079\n",
      "Epoch 744/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2176 - mae: 0.4400 - val_loss: 0.1927 - val_mae: 0.4079\n",
      "Epoch 745/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2448 - mae: 0.4737 - val_loss: 0.1961 - val_mae: 0.4107\n",
      "Epoch 746/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2307 - mae: 0.4626 - val_loss: 0.1974 - val_mae: 0.4100\n",
      "Epoch 747/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2283 - mae: 0.4544 - val_loss: 0.1989 - val_mae: 0.4112\n",
      "Epoch 748/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2142 - mae: 0.4405 - val_loss: 0.1973 - val_mae: 0.4102\n",
      "Epoch 749/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2375 - mae: 0.4720 - val_loss: 0.1978 - val_mae: 0.4104\n",
      "Epoch 750/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2365 - mae: 0.4629 - val_loss: 0.1980 - val_mae: 0.4110\n",
      "Epoch 751/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2100 - mae: 0.4355 - val_loss: 0.1984 - val_mae: 0.4104\n",
      "Epoch 752/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2289 - mae: 0.4608 - val_loss: 0.1987 - val_mae: 0.4101\n",
      "Epoch 753/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2285 - mae: 0.4551 - val_loss: 0.2001 - val_mae: 0.4097\n",
      "Epoch 754/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2434 - mae: 0.4737 - val_loss: 0.2031 - val_mae: 0.4110\n",
      "Epoch 755/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2379 - mae: 0.4695 - val_loss: 0.2047 - val_mae: 0.4112\n",
      "Epoch 756/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2284 - mae: 0.4543 - val_loss: 0.2008 - val_mae: 0.4064\n",
      "Epoch 757/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2288 - mae: 0.4500 - val_loss: 0.1994 - val_mae: 0.4067\n",
      "Epoch 758/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2368 - mae: 0.4553 - val_loss: 0.1981 - val_mae: 0.4084\n",
      "Epoch 759/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2064 - mae: 0.4232 - val_loss: 0.1972 - val_mae: 0.4072\n",
      "Epoch 760/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2133 - mae: 0.4340 - val_loss: 0.1972 - val_mae: 0.4046\n",
      "Epoch 761/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2141 - mae: 0.4301 - val_loss: 0.1966 - val_mae: 0.4035\n",
      "Epoch 762/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2342 - mae: 0.4586 - val_loss: 0.1981 - val_mae: 0.4052\n",
      "Epoch 763/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2220 - mae: 0.4432 - val_loss: 0.1993 - val_mae: 0.4082\n",
      "Epoch 764/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2266 - mae: 0.4537 - val_loss: 0.1986 - val_mae: 0.4073\n",
      "Epoch 765/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2292 - mae: 0.4518 - val_loss: 0.1993 - val_mae: 0.4087\n",
      "Epoch 766/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2228 - mae: 0.4484 - val_loss: 0.1973 - val_mae: 0.4060\n",
      "Epoch 767/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2322 - mae: 0.4588 - val_loss: 0.1964 - val_mae: 0.4061\n",
      "Epoch 768/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2278 - mae: 0.4557 - val_loss: 0.1959 - val_mae: 0.4063\n",
      "Epoch 769/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2289 - mae: 0.4555 - val_loss: 0.1958 - val_mae: 0.4070\n",
      "Epoch 770/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2276 - mae: 0.4562 - val_loss: 0.1977 - val_mae: 0.4086\n",
      "Epoch 771/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2398 - mae: 0.4618 - val_loss: 0.1996 - val_mae: 0.4053\n",
      "Epoch 772/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2308 - mae: 0.4564 - val_loss: 0.2026 - val_mae: 0.4044\n",
      "Epoch 773/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2248 - mae: 0.4501 - val_loss: 0.2014 - val_mae: 0.4025\n",
      "Epoch 774/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2379 - mae: 0.4674 - val_loss: 0.1988 - val_mae: 0.4023\n",
      "Epoch 775/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2292 - mae: 0.4621 - val_loss: 0.1947 - val_mae: 0.4012\n",
      "Epoch 776/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2247 - mae: 0.4517 - val_loss: 0.1912 - val_mae: 0.4000\n",
      "Epoch 777/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2296 - mae: 0.4646 - val_loss: 0.1885 - val_mae: 0.3975\n",
      "Epoch 778/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2335 - mae: 0.4695 - val_loss: 0.1868 - val_mae: 0.3955\n",
      "Epoch 779/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2203 - mae: 0.4416 - val_loss: 0.1888 - val_mae: 0.3970\n",
      "Epoch 780/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2264 - mae: 0.4601 - val_loss: 0.1886 - val_mae: 0.3979\n",
      "Epoch 781/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2134 - mae: 0.4394 - val_loss: 0.1899 - val_mae: 0.4005\n",
      "Epoch 782/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2437 - mae: 0.4776 - val_loss: 0.1919 - val_mae: 0.4042\n",
      "Epoch 783/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2294 - mae: 0.4638 - val_loss: 0.1952 - val_mae: 0.4081\n",
      "Epoch 784/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2296 - mae: 0.4560 - val_loss: 0.1959 - val_mae: 0.4104\n",
      "Epoch 785/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2290 - mae: 0.4637 - val_loss: 0.1953 - val_mae: 0.4100\n",
      "Epoch 786/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2368 - mae: 0.4675 - val_loss: 0.1944 - val_mae: 0.4092\n",
      "Epoch 787/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2186 - mae: 0.4472 - val_loss: 0.1942 - val_mae: 0.4086\n",
      "Epoch 788/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2323 - mae: 0.4631 - val_loss: 0.1968 - val_mae: 0.4099\n",
      "Epoch 789/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2171 - mae: 0.4419 - val_loss: 0.2008 - val_mae: 0.4125\n",
      "Epoch 790/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2436 - mae: 0.4698 - val_loss: 0.1990 - val_mae: 0.4091\n",
      "Epoch 791/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2326 - mae: 0.4610 - val_loss: 0.1970 - val_mae: 0.4071\n",
      "Epoch 792/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2271 - mae: 0.4649 - val_loss: 0.1931 - val_mae: 0.4058\n",
      "Epoch 793/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2355 - mae: 0.4677 - val_loss: 0.1919 - val_mae: 0.4044\n",
      "Epoch 794/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2111 - mae: 0.4273 - val_loss: 0.1906 - val_mae: 0.4024\n",
      "Epoch 795/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2167 - mae: 0.4441 - val_loss: 0.1909 - val_mae: 0.4018\n",
      "Epoch 796/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2228 - mae: 0.4515 - val_loss: 0.1916 - val_mae: 0.4013\n",
      "Epoch 797/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2168 - mae: 0.4420 - val_loss: 0.1924 - val_mae: 0.4011\n",
      "Epoch 798/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2224 - mae: 0.4518 - val_loss: 0.1913 - val_mae: 0.3996\n",
      "Epoch 799/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2192 - mae: 0.4449 - val_loss: 0.1929 - val_mae: 0.3988\n",
      "Epoch 800/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2293 - mae: 0.4581 - val_loss: 0.1933 - val_mae: 0.3992\n",
      "Epoch 801/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2307 - mae: 0.4589 - val_loss: 0.1932 - val_mae: 0.3995\n",
      "Epoch 802/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2148 - mae: 0.4365 - val_loss: 0.1941 - val_mae: 0.4016\n",
      "Epoch 803/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2358 - mae: 0.4647 - val_loss: 0.1934 - val_mae: 0.4013\n",
      "Epoch 804/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2345 - mae: 0.4572 - val_loss: 0.1928 - val_mae: 0.4025\n",
      "Epoch 805/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2099 - mae: 0.4292 - val_loss: 0.1916 - val_mae: 0.4009\n",
      "Epoch 806/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2221 - mae: 0.4420 - val_loss: 0.1938 - val_mae: 0.4030\n",
      "Epoch 807/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2120 - mae: 0.4306 - val_loss: 0.1936 - val_mae: 0.4023\n",
      "Epoch 808/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2318 - mae: 0.4528 - val_loss: 0.1950 - val_mae: 0.4045\n",
      "Epoch 809/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2190 - mae: 0.4453 - val_loss: 0.1962 - val_mae: 0.4060\n",
      "Epoch 810/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2399 - mae: 0.4614 - val_loss: 0.1983 - val_mae: 0.4089\n",
      "Epoch 811/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2348 - mae: 0.4665 - val_loss: 0.1997 - val_mae: 0.4103\n",
      "Epoch 812/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2399 - mae: 0.4735 - val_loss: 0.1998 - val_mae: 0.4098\n",
      "Epoch 813/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2183 - mae: 0.4343 - val_loss: 0.1987 - val_mae: 0.4086\n",
      "Epoch 814/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2240 - mae: 0.4484 - val_loss: 0.1984 - val_mae: 0.4073\n",
      "Epoch 815/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2225 - mae: 0.4535 - val_loss: 0.1997 - val_mae: 0.4079\n",
      "Epoch 816/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2148 - mae: 0.4411 - val_loss: 0.1956 - val_mae: 0.4037\n",
      "Epoch 817/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2176 - mae: 0.4391 - val_loss: 0.1974 - val_mae: 0.4027\n",
      "Epoch 818/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2331 - mae: 0.4561 - val_loss: 0.1970 - val_mae: 0.4017\n",
      "Epoch 819/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2313 - mae: 0.4502 - val_loss: 0.1956 - val_mae: 0.3992\n",
      "Epoch 820/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2413 - mae: 0.4647 - val_loss: 0.1937 - val_mae: 0.3985\n",
      "Epoch 821/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2110 - mae: 0.4331 - val_loss: 0.1925 - val_mae: 0.3985\n",
      "Epoch 822/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2301 - mae: 0.4580 - val_loss: 0.1903 - val_mae: 0.3988\n",
      "Epoch 823/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2414 - mae: 0.4602 - val_loss: 0.1893 - val_mae: 0.4010\n",
      "Epoch 824/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2229 - mae: 0.4531 - val_loss: 0.1902 - val_mae: 0.4015\n",
      "Epoch 825/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2271 - mae: 0.4627 - val_loss: 0.1918 - val_mae: 0.4026\n",
      "Epoch 826/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2101 - mae: 0.4262 - val_loss: 0.1937 - val_mae: 0.4032\n",
      "Epoch 827/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2135 - mae: 0.4361 - val_loss: 0.1945 - val_mae: 0.4044\n",
      "Epoch 828/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2295 - mae: 0.4539 - val_loss: 0.1970 - val_mae: 0.4058\n",
      "Epoch 829/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2159 - mae: 0.4358 - val_loss: 0.1957 - val_mae: 0.4033\n",
      "Epoch 830/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2222 - mae: 0.4446 - val_loss: 0.1943 - val_mae: 0.4032\n",
      "Epoch 831/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2151 - mae: 0.4416 - val_loss: 0.1946 - val_mae: 0.4021\n",
      "Epoch 832/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2231 - mae: 0.4435 - val_loss: 0.1929 - val_mae: 0.4008\n",
      "Epoch 833/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2308 - mae: 0.4581 - val_loss: 0.1927 - val_mae: 0.3998\n",
      "Epoch 834/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2378 - mae: 0.4704 - val_loss: 0.1915 - val_mae: 0.3994\n",
      "Epoch 835/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2281 - mae: 0.4631 - val_loss: 0.1940 - val_mae: 0.4021\n",
      "Epoch 836/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2215 - mae: 0.4446 - val_loss: 0.1918 - val_mae: 0.4024\n",
      "Epoch 837/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2218 - mae: 0.4460 - val_loss: 0.1910 - val_mae: 0.4021\n",
      "Epoch 838/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2353 - mae: 0.4676 - val_loss: 0.1920 - val_mae: 0.4043\n",
      "Epoch 839/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2302 - mae: 0.4597 - val_loss: 0.1946 - val_mae: 0.4078\n",
      "Epoch 840/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2214 - mae: 0.4351 - val_loss: 0.1953 - val_mae: 0.4085\n",
      "Epoch 841/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2166 - mae: 0.4468 - val_loss: 0.1943 - val_mae: 0.4069\n",
      "Epoch 842/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2254 - mae: 0.4567 - val_loss: 0.1948 - val_mae: 0.4069\n",
      "Epoch 843/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2292 - mae: 0.4550 - val_loss: 0.1893 - val_mae: 0.3991\n",
      "Epoch 844/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2307 - mae: 0.4571 - val_loss: 0.1898 - val_mae: 0.3987\n",
      "Epoch 845/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2267 - mae: 0.4532 - val_loss: 0.1937 - val_mae: 0.4049\n",
      "Epoch 846/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2341 - mae: 0.4585 - val_loss: 0.1996 - val_mae: 0.4126\n",
      "Epoch 847/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2445 - mae: 0.4751 - val_loss: 0.1994 - val_mae: 0.4119\n",
      "Epoch 848/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2320 - mae: 0.4501 - val_loss: 0.2064 - val_mae: 0.4196\n",
      "Epoch 849/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2277 - mae: 0.4547 - val_loss: 0.2057 - val_mae: 0.4177\n",
      "Epoch 850/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2374 - mae: 0.4631 - val_loss: 0.2036 - val_mae: 0.4134\n",
      "Epoch 851/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2271 - mae: 0.4646 - val_loss: 0.2016 - val_mae: 0.4094\n",
      "Epoch 852/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2294 - mae: 0.4574 - val_loss: 0.2014 - val_mae: 0.4093\n",
      "Epoch 853/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2178 - mae: 0.4421 - val_loss: 0.2012 - val_mae: 0.4101\n",
      "Epoch 854/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2281 - mae: 0.4566 - val_loss: 0.1991 - val_mae: 0.4092\n",
      "Epoch 855/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2339 - mae: 0.4661 - val_loss: 0.2007 - val_mae: 0.4116\n",
      "Epoch 856/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2265 - mae: 0.4485 - val_loss: 0.2028 - val_mae: 0.4139\n",
      "Epoch 857/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2347 - mae: 0.4628 - val_loss: 0.2012 - val_mae: 0.4103\n",
      "Epoch 858/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2354 - mae: 0.4622 - val_loss: 0.2020 - val_mae: 0.4114\n",
      "Epoch 859/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2226 - mae: 0.4455 - val_loss: 0.2012 - val_mae: 0.4114\n",
      "Epoch 860/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2284 - mae: 0.4587 - val_loss: 0.2017 - val_mae: 0.4124\n",
      "Epoch 861/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2158 - mae: 0.4480 - val_loss: 0.2001 - val_mae: 0.4122\n",
      "Epoch 862/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2229 - mae: 0.4475 - val_loss: 0.1978 - val_mae: 0.4079\n",
      "Epoch 863/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2439 - mae: 0.4718 - val_loss: 0.1978 - val_mae: 0.4060\n",
      "Epoch 864/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2385 - mae: 0.4627 - val_loss: 0.2015 - val_mae: 0.4113\n",
      "Epoch 865/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2264 - mae: 0.4470 - val_loss: 0.2006 - val_mae: 0.4089\n",
      "Epoch 866/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2367 - mae: 0.4622 - val_loss: 0.2003 - val_mae: 0.4079\n",
      "Epoch 867/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2332 - mae: 0.4500 - val_loss: 0.1979 - val_mae: 0.4070\n",
      "Epoch 868/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2237 - mae: 0.4456 - val_loss: 0.1992 - val_mae: 0.4113\n",
      "Epoch 869/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2480 - mae: 0.4739 - val_loss: 0.1994 - val_mae: 0.4125\n",
      "Epoch 870/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2293 - mae: 0.4523 - val_loss: 0.2032 - val_mae: 0.4174\n",
      "Epoch 871/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2309 - mae: 0.4621 - val_loss: 0.2059 - val_mae: 0.4215\n",
      "Epoch 872/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2232 - mae: 0.4540 - val_loss: 0.2108 - val_mae: 0.4265\n",
      "Epoch 873/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2270 - mae: 0.4562 - val_loss: 0.2123 - val_mae: 0.4264\n",
      "Epoch 874/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2207 - mae: 0.4511 - val_loss: 0.2107 - val_mae: 0.4243\n",
      "Epoch 875/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2210 - mae: 0.4479 - val_loss: 0.2074 - val_mae: 0.4219\n",
      "Epoch 876/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2431 - mae: 0.4830 - val_loss: 0.2050 - val_mae: 0.4200\n",
      "Epoch 877/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.2309 - mae: 0.4613 - val_loss: 0.2042 - val_mae: 0.4184\n",
      "Epoch 878/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2306 - mae: 0.4592 - val_loss: 0.2016 - val_mae: 0.4154\n",
      "Epoch 879/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2331 - mae: 0.4624 - val_loss: 0.2012 - val_mae: 0.4148\n",
      "Epoch 880/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2230 - mae: 0.4459 - val_loss: 0.1997 - val_mae: 0.4139\n",
      "Epoch 881/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2345 - mae: 0.4661 - val_loss: 0.1993 - val_mae: 0.4143\n",
      "Epoch 882/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2203 - mae: 0.4472 - val_loss: 0.1994 - val_mae: 0.4143\n",
      "Epoch 883/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2392 - mae: 0.4733 - val_loss: 0.1984 - val_mae: 0.4131\n",
      "Epoch 884/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2389 - mae: 0.4707 - val_loss: 0.1987 - val_mae: 0.4120\n",
      "Epoch 885/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2261 - mae: 0.4505 - val_loss: 0.1969 - val_mae: 0.4110\n",
      "Epoch 886/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2171 - mae: 0.4450 - val_loss: 0.1975 - val_mae: 0.4112\n",
      "Epoch 887/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2167 - mae: 0.4407 - val_loss: 0.1978 - val_mae: 0.4101\n",
      "Epoch 888/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2384 - mae: 0.4727 - val_loss: 0.2001 - val_mae: 0.4117\n",
      "Epoch 889/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2143 - mae: 0.4421 - val_loss: 0.1988 - val_mae: 0.4103\n",
      "Epoch 890/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2210 - mae: 0.4391 - val_loss: 0.1986 - val_mae: 0.4095\n",
      "Epoch 891/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2227 - mae: 0.4486 - val_loss: 0.1996 - val_mae: 0.4112\n",
      "Epoch 892/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2308 - mae: 0.4597 - val_loss: 0.1998 - val_mae: 0.4120\n",
      "Epoch 893/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2183 - mae: 0.4452 - val_loss: 0.1990 - val_mae: 0.4111\n",
      "Epoch 894/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2332 - mae: 0.4672 - val_loss: 0.1979 - val_mae: 0.4100\n",
      "Epoch 895/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2194 - mae: 0.4372 - val_loss: 0.1962 - val_mae: 0.4071\n",
      "Epoch 896/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2348 - mae: 0.4535 - val_loss: 0.1980 - val_mae: 0.4070\n",
      "Epoch 897/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2237 - mae: 0.4540 - val_loss: 0.1976 - val_mae: 0.4048\n",
      "Epoch 898/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2328 - mae: 0.4617 - val_loss: 0.1954 - val_mae: 0.4032\n",
      "Epoch 899/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2421 - mae: 0.4725 - val_loss: 0.1945 - val_mae: 0.4026\n",
      "Epoch 900/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2289 - mae: 0.4580 - val_loss: 0.1957 - val_mae: 0.4052\n",
      "Epoch 901/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2185 - mae: 0.4436 - val_loss: 0.1955 - val_mae: 0.4035\n",
      "Epoch 902/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2087 - mae: 0.4278 - val_loss: 0.1951 - val_mae: 0.4020\n",
      "Epoch 903/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2203 - mae: 0.4398 - val_loss: 0.1958 - val_mae: 0.4025\n",
      "Epoch 904/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2265 - mae: 0.4538 - val_loss: 0.1962 - val_mae: 0.4039\n",
      "Epoch 905/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2298 - mae: 0.4575 - val_loss: 0.1967 - val_mae: 0.4050\n",
      "Epoch 906/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2079 - mae: 0.4251 - val_loss: 0.1987 - val_mae: 0.4081\n",
      "Epoch 907/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2028 - mae: 0.4207 - val_loss: 0.1999 - val_mae: 0.4089\n",
      "Epoch 908/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2172 - mae: 0.4394 - val_loss: 0.2017 - val_mae: 0.4108\n",
      "Epoch 909/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2249 - mae: 0.4489 - val_loss: 0.2016 - val_mae: 0.4100\n",
      "Epoch 910/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2278 - mae: 0.4508 - val_loss: 0.2006 - val_mae: 0.4099\n",
      "Epoch 911/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2113 - mae: 0.4307 - val_loss: 0.2006 - val_mae: 0.4100\n",
      "Epoch 912/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2098 - mae: 0.4322 - val_loss: 0.2007 - val_mae: 0.4120\n",
      "Epoch 913/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2226 - mae: 0.4457 - val_loss: 0.1971 - val_mae: 0.4074\n",
      "Epoch 914/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2180 - mae: 0.4339 - val_loss: 0.1953 - val_mae: 0.4039\n",
      "Epoch 915/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2458 - mae: 0.4709 - val_loss: 0.1949 - val_mae: 0.4061\n",
      "Epoch 916/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2103 - mae: 0.4308 - val_loss: 0.1971 - val_mae: 0.4082\n",
      "Epoch 917/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2259 - mae: 0.4501 - val_loss: 0.1975 - val_mae: 0.4077\n",
      "Epoch 918/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2337 - mae: 0.4646 - val_loss: 0.1987 - val_mae: 0.4089\n",
      "Epoch 919/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2254 - mae: 0.4476 - val_loss: 0.2007 - val_mae: 0.4114\n",
      "Epoch 920/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2067 - mae: 0.4253 - val_loss: 0.2018 - val_mae: 0.4128\n",
      "Epoch 921/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2191 - mae: 0.4370 - val_loss: 0.2031 - val_mae: 0.4143\n",
      "Epoch 922/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2416 - mae: 0.4679 - val_loss: 0.2028 - val_mae: 0.4128\n",
      "Epoch 923/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2179 - mae: 0.4438 - val_loss: 0.2008 - val_mae: 0.4088\n",
      "Epoch 924/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2115 - mae: 0.4379 - val_loss: 0.2010 - val_mae: 0.4094\n",
      "Epoch 925/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2283 - mae: 0.4520 - val_loss: 0.2013 - val_mae: 0.4112\n",
      "Epoch 926/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2449 - mae: 0.4792 - val_loss: 0.2017 - val_mae: 0.4124\n",
      "Epoch 927/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2346 - mae: 0.4680 - val_loss: 0.2019 - val_mae: 0.4122\n",
      "Epoch 928/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2187 - mae: 0.4355 - val_loss: 0.2036 - val_mae: 0.4140\n",
      "Epoch 929/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2405 - mae: 0.4643 - val_loss: 0.2039 - val_mae: 0.4127\n",
      "Epoch 930/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2183 - mae: 0.4419 - val_loss: 0.2025 - val_mae: 0.4100\n",
      "Epoch 931/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2286 - mae: 0.4551 - val_loss: 0.2021 - val_mae: 0.4123\n",
      "Epoch 932/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2164 - mae: 0.4377 - val_loss: 0.2018 - val_mae: 0.4121\n",
      "Epoch 933/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2150 - mae: 0.4398 - val_loss: 0.2016 - val_mae: 0.4126\n",
      "Epoch 934/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2295 - mae: 0.4558 - val_loss: 0.2014 - val_mae: 0.4134\n",
      "Epoch 935/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2243 - mae: 0.4474 - val_loss: 0.2028 - val_mae: 0.4139\n",
      "Epoch 936/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2144 - mae: 0.4372 - val_loss: 0.2014 - val_mae: 0.4122\n",
      "Epoch 937/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2299 - mae: 0.4539 - val_loss: 0.2015 - val_mae: 0.4131\n",
      "Epoch 938/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2167 - mae: 0.4380 - val_loss: 0.2029 - val_mae: 0.4149\n",
      "Epoch 939/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2234 - mae: 0.4586 - val_loss: 0.2047 - val_mae: 0.4154\n",
      "Epoch 940/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2346 - mae: 0.4633 - val_loss: 0.2060 - val_mae: 0.4171\n",
      "Epoch 941/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2366 - mae: 0.4621 - val_loss: 0.2040 - val_mae: 0.4150\n",
      "Epoch 942/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2225 - mae: 0.4497 - val_loss: 0.2013 - val_mae: 0.4116\n",
      "Epoch 943/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2455 - mae: 0.4754 - val_loss: 0.2015 - val_mae: 0.4138\n",
      "Epoch 944/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2154 - mae: 0.4378 - val_loss: 0.2008 - val_mae: 0.4127\n",
      "Epoch 945/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2153 - mae: 0.4425 - val_loss: 0.2001 - val_mae: 0.4124\n",
      "Epoch 946/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2195 - mae: 0.4394 - val_loss: 0.1998 - val_mae: 0.4118\n",
      "Epoch 947/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2174 - mae: 0.4403 - val_loss: 0.2013 - val_mae: 0.4126\n",
      "Epoch 948/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2176 - mae: 0.4377 - val_loss: 0.2038 - val_mae: 0.4163\n",
      "Epoch 949/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2206 - mae: 0.4377 - val_loss: 0.2047 - val_mae: 0.4179\n",
      "Epoch 950/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2489 - mae: 0.4792 - val_loss: 0.2046 - val_mae: 0.4179\n",
      "Epoch 951/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2358 - mae: 0.4561 - val_loss: 0.2023 - val_mae: 0.4145\n",
      "Epoch 952/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2237 - mae: 0.4510 - val_loss: 0.2012 - val_mae: 0.4155\n",
      "Epoch 953/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2230 - mae: 0.4461 - val_loss: 0.2028 - val_mae: 0.4176\n",
      "Epoch 954/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2133 - mae: 0.4325 - val_loss: 0.2014 - val_mae: 0.4157\n",
      "Epoch 955/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2196 - mae: 0.4480 - val_loss: 0.2017 - val_mae: 0.4156\n",
      "Epoch 956/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2215 - mae: 0.4472 - val_loss: 0.2015 - val_mae: 0.4145\n",
      "Epoch 957/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2062 - mae: 0.4221 - val_loss: 0.2033 - val_mae: 0.4152\n",
      "Epoch 958/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2202 - mae: 0.4411 - val_loss: 0.2034 - val_mae: 0.4156\n",
      "Epoch 959/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2330 - mae: 0.4588 - val_loss: 0.2044 - val_mae: 0.4170\n",
      "Epoch 960/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2384 - mae: 0.4718 - val_loss: 0.2034 - val_mae: 0.4164\n",
      "Epoch 961/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2319 - mae: 0.4610 - val_loss: 0.2023 - val_mae: 0.4149\n",
      "Epoch 962/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2244 - mae: 0.4527 - val_loss: 0.2006 - val_mae: 0.4131\n",
      "Epoch 963/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2317 - mae: 0.4590 - val_loss: 0.2003 - val_mae: 0.4118\n",
      "Epoch 964/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2296 - mae: 0.4559 - val_loss: 0.2010 - val_mae: 0.4125\n",
      "Epoch 965/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2199 - mae: 0.4470 - val_loss: 0.2032 - val_mae: 0.4146\n",
      "Epoch 966/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2187 - mae: 0.4483 - val_loss: 0.2035 - val_mae: 0.4140\n",
      "Epoch 967/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2403 - mae: 0.4688 - val_loss: 0.2029 - val_mae: 0.4130\n",
      "Epoch 968/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2216 - mae: 0.4461 - val_loss: 0.2024 - val_mae: 0.4122\n",
      "Epoch 969/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2248 - mae: 0.4418 - val_loss: 0.2012 - val_mae: 0.4119\n",
      "Epoch 970/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2330 - mae: 0.4663 - val_loss: 0.2004 - val_mae: 0.4124\n",
      "Epoch 971/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2291 - mae: 0.4599 - val_loss: 0.2010 - val_mae: 0.4127\n",
      "Epoch 972/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2246 - mae: 0.4509 - val_loss: 0.2002 - val_mae: 0.4101\n",
      "Epoch 973/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2355 - mae: 0.4684 - val_loss: 0.1995 - val_mae: 0.4085\n",
      "Epoch 974/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2276 - mae: 0.4612 - val_loss: 0.2008 - val_mae: 0.4087\n",
      "Epoch 975/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2125 - mae: 0.4376 - val_loss: 0.2005 - val_mae: 0.4080\n",
      "Epoch 976/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2174 - mae: 0.4418 - val_loss: 0.2015 - val_mae: 0.4092\n",
      "Epoch 977/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2284 - mae: 0.4582 - val_loss: 0.2017 - val_mae: 0.4099\n",
      "Epoch 978/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2410 - mae: 0.4752 - val_loss: 0.2032 - val_mae: 0.4133\n",
      "Epoch 979/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2244 - mae: 0.4552 - val_loss: 0.2045 - val_mae: 0.4156\n",
      "Epoch 980/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2267 - mae: 0.4581 - val_loss: 0.2017 - val_mae: 0.4119\n",
      "Epoch 981/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2143 - mae: 0.4348 - val_loss: 0.2010 - val_mae: 0.4117\n",
      "Epoch 982/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2204 - mae: 0.4464 - val_loss: 0.2017 - val_mae: 0.4131\n",
      "Epoch 983/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2162 - mae: 0.4367 - val_loss: 0.2017 - val_mae: 0.4132\n",
      "Epoch 984/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2336 - mae: 0.4645 - val_loss: 0.2000 - val_mae: 0.4106\n",
      "Epoch 985/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2289 - mae: 0.4637 - val_loss: 0.1990 - val_mae: 0.4091\n",
      "Epoch 986/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2263 - mae: 0.4499 - val_loss: 0.2003 - val_mae: 0.4102\n",
      "Epoch 987/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2219 - mae: 0.4379 - val_loss: 0.1999 - val_mae: 0.4105\n",
      "Epoch 988/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2255 - mae: 0.4521 - val_loss: 0.1983 - val_mae: 0.4096\n",
      "Epoch 989/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2373 - mae: 0.4582 - val_loss: 0.1968 - val_mae: 0.4079\n",
      "Epoch 990/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2250 - mae: 0.4470 - val_loss: 0.1963 - val_mae: 0.4072\n",
      "Epoch 991/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.2220 - mae: 0.4422 - val_loss: 0.1962 - val_mae: 0.4071\n",
      "Epoch 992/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2128 - mae: 0.4366 - val_loss: 0.1948 - val_mae: 0.4057\n",
      "Epoch 993/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2216 - mae: 0.4450 - val_loss: 0.1947 - val_mae: 0.4059\n",
      "Epoch 994/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2194 - mae: 0.4387 - val_loss: 0.1943 - val_mae: 0.4055\n",
      "Epoch 995/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2186 - mae: 0.4461 - val_loss: 0.1940 - val_mae: 0.4047\n",
      "Epoch 996/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2239 - mae: 0.4466 - val_loss: 0.1940 - val_mae: 0.4042\n",
      "Epoch 997/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2306 - mae: 0.4589 - val_loss: 0.1937 - val_mae: 0.4037\n",
      "Epoch 998/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2207 - mae: 0.4523 - val_loss: 0.1942 - val_mae: 0.4036\n",
      "Epoch 999/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2011 - mae: 0.4206 - val_loss: 0.1937 - val_mae: 0.4023\n",
      "Epoch 1000/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2412 - mae: 0.4729 - val_loss: 0.1936 - val_mae: 0.4016\n"
     ]
    }
   ],
   "source": [
    "# Train the LSTM model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=1000,  # You can adjust based on convergence\n",
    "    batch_size=16,  # Smaller batch size for augmented data\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1936, Validation MAE: 0.4016\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_mae = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation MAE: {val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
      "Predicted: 0.46, Actual: 0.00\n",
      "Predicted: 0.46, Actual: 0.00\n",
      "Predicted: 0.41, Actual: 1.00\n",
      "Predicted: 0.46, Actual: 0.00\n",
      "Predicted: 0.46, Actual: 0.00\n",
      "Predicted: 0.46, Actual: 0.00\n",
      "Predicted: 0.99, Actual: 1.00\n",
      "Predicted: 0.99, Actual: 1.00\n",
      "Predicted: 0.46, Actual: 0.00\n",
      "Predicted: 0.49, Actual: 1.00\n",
      "Predicted: 0.46, Actual: 0.00\n",
      "Predicted: 0.46, Actual: 0.00\n",
      "Predicted: 0.72, Actual: 1.00\n",
      "Predicted: 0.46, Actual: 1.00\n",
      "Predicted: 0.45, Actual: 1.00\n",
      "Predicted: 0.46, Actual: 0.00\n",
      "Predicted: 0.98, Actual: 1.00\n",
      "Predicted: 0.46, Actual: 0.00\n",
      "Predicted: 0.46, Actual: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Predict scores on validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Print predictions vs. actual\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Predicted: {pred[0]:.2f}, Actual: {y_val[i]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatter plot of predictions vs. actual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_val, predictions, c='blue', label='Predicted vs Actual')\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Perfect Match')  # Reference line\n",
    "plt.xlabel('Actual Scores')\n",
    "plt.ylabel('Predicted Scores')\n",
    "plt.title('Model Predictions vs. Actual Scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737657199.374971 10178720 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n",
      "W0000 00:00:1737657199.434754 10313581 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737657199.445036 10313579 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Hurdle Cleared: 0\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x399e1d580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
      "Predicted Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to check if the first hurdle is cleared\n",
    "def is_hurdle_cleared(lead_leg, trail_leg, hurdle_height):\n",
    "    \"\"\"\n",
    "    Determines if the first hurdle is cleared by checking if both legs move above a given height.\n",
    "    \"\"\"\n",
    "    lead_leg_y = lead_leg[1]\n",
    "    trail_leg_y = trail_leg[1]\n",
    "\n",
    "    # Both legs must rise above the hurdle height threshold\n",
    "    return lead_leg_y < hurdle_height and trail_leg_y < hurdle_height\n",
    "\n",
    "# Path for the new test video\n",
    "new_video_path = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/hurdling/stages/stage2/test_videos/1_user9.mp4\"\n",
    "\n",
    "# Extract keypoints for the new video\n",
    "hurdle_height_threshold = 0.5  # Adjust based on the expected height in normalized coordinates\n",
    "hurdle_cleared = False\n",
    "\n",
    "cap = cv2.VideoCapture(new_video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB for MediaPipe processing\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = pose.process(frame_rgb)\n",
    "\n",
    "    if result.pose_landmarks:\n",
    "        landmarks = result.pose_landmarks.landmark\n",
    "\n",
    "        # Extract relevant keypoints for hurdle analysis\n",
    "        right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y]\n",
    "        left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y]\n",
    "\n",
    "        # Check if the hurdle is cleared\n",
    "        if is_hurdle_cleared(right_knee, left_knee, hurdle_height_threshold):\n",
    "            hurdle_cleared = True\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Convert hurdle cleared status to binary value for model input\n",
    "hurdle_cleared_value = 1 if hurdle_cleared else 0\n",
    "\n",
    "print(f\"First Hurdle Cleared: {hurdle_cleared_value}\")\n",
    "\n",
    "# Prepare data for model prediction\n",
    "new_keypoints_padded = pad_sequences([[hurdle_cleared_value]], \n",
    "                                     maxlen=X_train.shape[1], \n",
    "                                     padding='post', dtype='float32')\n",
    "\n",
    "# Reshape to match model input (samples, timesteps, features)\n",
    "new_keypoints_padded = new_keypoints_padded.reshape((new_keypoints_padded.shape[0], new_keypoints_padded.shape[1], 1))\n",
    "\n",
    "# Predict score for the new video\n",
    "predicted_score = model.predict(new_keypoints_padded)\n",
    "print(f\"Predicted Score: {predicted_score[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_score(prediction):\n",
    "    \"\"\"Classify the prediction into 0, 0.5, or 1 based on thresholds.\"\"\"\n",
    "    if prediction >= 0.7:\n",
    "        return 1.0\n",
    "    elif prediction >= 0.5:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 0.0\n",
      "Classified: 0.0, Actual: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Predict scores on validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Apply classification logic\n",
    "classified_predictions = [classify_score(pred[0]) for pred in predictions]\n",
    "\n",
    "# Print classified predictions vs actual scores\n",
    "for i, (pred, actual) in enumerate(zip(classified_predictions, y_val)):\n",
    "    print(f\"Classified: {pred}, Actual: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def weighted_mse(y_true, y_pred):\n",
    "    \"\"\"Weighted Mean Squared Error to prioritize true negatives.\"\"\"\n",
    "    weights = K.switch(y_true < 0.70, 2.0, 1.0)  # Weight true negatives higher\n",
    "    return K.mean(weights * K.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=weighted_mse, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
      "Classification Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Predict and classify scores\n",
    "classified_predictions = [classify_score(pred[0]) for pred in model.predict(X_val)]\n",
    "\n",
    "# Evaluate accuracy of classification\n",
    "correct = sum(1 for pred, actual in zip(classified_predictions, y_val) if pred == actual)\n",
    "accuracy = correct / len(y_val)\n",
    "\n",
    "print(f\"Classification Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/hurdling/stages/stage2/models/hurdles_stage2.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
