{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737648392.074977 9103311 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1737648392.129360 9104352 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737648392.137435 9104355 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737648392.149980 9104364 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center of mass extraction complete! JSON files saved in 'keypoints' folder.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to determine if center of mass leans forward\n",
    "def is_center_of_mass_forward(shoulder, hip, ankle):\n",
    "    \"\"\"\n",
    "    Determines if the center of mass is leaning forward by checking the relative positions\n",
    "    of the hip and shoulder to the ankle.\n",
    "    \"\"\"\n",
    "    # Ensure vertical alignment (y-axis higher value means lower in the frame)\n",
    "    shoulder_x, shoulder_y = shoulder\n",
    "    hip_x, hip_y = hip\n",
    "    ankle_x, ankle_y = ankle\n",
    "\n",
    "    # Center of mass leans forward if the shoulder is ahead (x-axis) of the ankle and\n",
    "    # the hip is not too far behind the shoulder.\n",
    "    return shoulder_x > ankle_x and hip_x > ankle_x\n",
    "\n",
    "# Paths for the stage 5 videos and keypoints storage\n",
    "stage_path = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/sprint_technique/stages/stage5/videos\"\n",
    "keypoints_folder = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/sprint_technique/stages/stage5/keypoints\"\n",
    "\n",
    "# Ensure keypoints folder exists\n",
    "os.makedirs(keypoints_folder, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(stage_path):\n",
    "    if file.endswith(\".mp4\"):\n",
    "        video_file_path = os.path.join(stage_path, file)\n",
    "        cap = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "        keypoints_data = []  # Store keypoints for this video\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Convert frame to RGB for MediaPipe processing\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result = pose.process(frame_rgb)\n",
    "\n",
    "            if result.pose_landmarks:\n",
    "                landmarks = result.pose_landmarks.landmark\n",
    "\n",
    "                # Extract relevant keypoints for center of mass analysis\n",
    "                left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x,\n",
    "                                 landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y]\n",
    "                left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP].x,\n",
    "                            landmarks[mp_pose.PoseLandmark.LEFT_HIP].y]\n",
    "                left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x,\n",
    "                              landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y]\n",
    "\n",
    "                right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x,\n",
    "                                  landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y]\n",
    "                right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x,\n",
    "                             landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y]\n",
    "                right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].x,\n",
    "                               landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].y]\n",
    "\n",
    "                # Check if center of mass leans forward for both sides\n",
    "                left_mass_forward = is_center_of_mass_forward(left_shoulder, left_hip, left_ankle)\n",
    "                right_mass_forward = is_center_of_mass_forward(right_shoulder, right_hip, right_ankle)\n",
    "\n",
    "                # Store data for this frame\n",
    "                keypoints_data.append({\n",
    "                    \"frame\": int(cap.get(cv2.CAP_PROP_POS_FRAMES)),\n",
    "                    \"left_mass_forward\": left_mass_forward,\n",
    "                    \"right_mass_forward\": right_mass_forward,\n",
    "                    \"left_shoulder\": left_shoulder,\n",
    "                    \"left_hip\": left_hip,\n",
    "                    \"left_ankle\": left_ankle,\n",
    "                    \"right_shoulder\": right_shoulder,\n",
    "                    \"right_hip\": right_hip,\n",
    "                    \"right_ankle\": right_ankle\n",
    "                })\n",
    "\n",
    "        # Release the video\n",
    "        cap.release()\n",
    "\n",
    "        # Save keypoints to the keypoints folder\n",
    "        json_filename = os.path.splitext(file)[0] + \"_keypoints.json\"\n",
    "        json_path = os.path.join(keypoints_folder, json_filename)\n",
    "        with open(json_path, \"w\") as json_file:\n",
    "            json.dump(keypoints_data, json_file, indent=4)\n",
    "\n",
    "print(\"Center of mass extraction complete! JSON files saved in 'keypoints' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 sequences with labels.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Path to the keypoints folder for stage 5 (center of mass leans forward)\n",
    "keypoints_folder = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/sprint_technique/stages/stage5/keypoints\"\n",
    "\n",
    "# Lists to store sequences and labels\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "# Process keypoint JSON files\n",
    "for file in os.listdir(keypoints_folder):\n",
    "    if file.endswith(\"_keypoints.json\"):\n",
    "        file_path = os.path.join(keypoints_folder, file)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Extract center of mass indicators across all frames\n",
    "        mass_positions = [\n",
    "            [int(frame[\"left_mass_forward\"]), int(frame[\"right_mass_forward\"])]\n",
    "            for frame in data\n",
    "        ]\n",
    "        sequences.append(mass_positions)\n",
    "\n",
    "        # Extract label from filename (assumes label is the first part of filename)\n",
    "        try:\n",
    "            label = float(file.split(\"_\")[0])  # Modify if filename structure differs\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Unable to extract label from {file}\")\n",
    "            continue\n",
    "        \n",
    "        labels.append(label)\n",
    "\n",
    "# Pad sequences to the same length\n",
    "if sequences:\n",
    "    max_len = max(len(seq) for seq in sequences)\n",
    "    sequences = pad_sequences(sequences, maxlen=max_len, padding='post', dtype='float32')\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    print(f\"Loaded {len(sequences)} sequences with labels.\")\n",
    "else:\n",
    "    print(\"No sequences found in the keypoints folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented dataset size: 80\n"
     ]
    }
   ],
   "source": [
    "def augment_data(sequence):\n",
    "    augmented_sequences = []\n",
    "\n",
    "    # Original\n",
    "    augmented_sequences.append(sequence)\n",
    "\n",
    "    # Mirrored (flip angles horizontally)\n",
    "    mirrored = -sequence\n",
    "    augmented_sequences.append(mirrored)\n",
    "\n",
    "    # Rotation (add a small angle offset)\n",
    "    rotated = sequence + np.random.uniform(-10, 10, size=sequence.shape)\n",
    "    augmented_sequences.append(rotated)\n",
    "\n",
    "    # Noise (add random Gaussian noise)\n",
    "    noisy = sequence + np.random.normal(0, 0.05, size=sequence.shape)\n",
    "    augmented_sequences.append(noisy)\n",
    "\n",
    "    # Scaled (adjust by a small percentage)\n",
    "    scaled = sequence * np.random.uniform(0.9, 1.1)\n",
    "    augmented_sequences.append(scaled)\n",
    "\n",
    "    return augmented_sequences\n",
    "\n",
    "augmented_sequences = []\n",
    "augmented_labels = []\n",
    "\n",
    "for seq, label in zip(sequences, labels):\n",
    "    augmented = augment_data(seq)\n",
    "    augmented_sequences.extend(augmented)\n",
    "    augmented_labels.extend([label] * len(augmented))\n",
    "\n",
    "augmented_sequences = np.array(augmented_sequences)\n",
    "augmented_labels = np.array(augmented_labels)\n",
    "\n",
    "print(f\"Augmented dataset size: {len(augmented_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 61, Validation samples: 19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    augmented_sequences, augmented_labels, test_size=4/17, random_state=42\n",
    ")\n",
    "\n",
    "# Ensure correct shape for LSTM input (samples, timesteps, features)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 2))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 2))\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define enhanced LSTM model\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(128, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1], 2))),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Bidirectional(LSTM(64, activation='tanh', return_sequences=True)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Bidirectional(LSTM(32, activation='tanh', return_sequences=False)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output: Regression score\n",
    "])\n",
    "\n",
    "# Compile the model with a reduced learning rate for better convergence\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse', metrics=['mae'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 275ms/step - loss: 0.6667 - mae: 0.7291 - val_loss: 0.5738 - val_mae: 0.7341\n",
      "Epoch 2/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243ms/step - loss: 0.4037 - mae: 0.5723 - val_loss: 0.2708 - val_mae: 0.4654\n",
      "Epoch 3/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244ms/step - loss: 0.3282 - mae: 0.4871 - val_loss: 0.1759 - val_mae: 0.3232\n",
      "Epoch 4/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 242ms/step - loss: 0.3063 - mae: 0.4332 - val_loss: 0.1497 - val_mae: 0.3013\n",
      "Epoch 5/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - loss: 0.2694 - mae: 0.4274 - val_loss: 0.1674 - val_mae: 0.3688\n",
      "Epoch 6/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237ms/step - loss: 0.1949 - mae: 0.3997 - val_loss: 0.1679 - val_mae: 0.3815\n",
      "Epoch 7/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - loss: 0.1890 - mae: 0.3870 - val_loss: 0.1437 - val_mae: 0.3534\n",
      "Epoch 8/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275ms/step - loss: 0.1619 - mae: 0.3433 - val_loss: 0.1146 - val_mae: 0.3018\n",
      "Epoch 9/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278ms/step - loss: 0.1765 - mae: 0.3538 - val_loss: 0.0945 - val_mae: 0.2697\n",
      "Epoch 10/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - loss: 0.2383 - mae: 0.3872 - val_loss: 0.1039 - val_mae: 0.2906\n",
      "Epoch 11/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - loss: 0.1765 - mae: 0.3495 - val_loss: 0.1051 - val_mae: 0.2974\n",
      "Epoch 12/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 212ms/step - loss: 0.1680 - mae: 0.3409 - val_loss: 0.1069 - val_mae: 0.3030\n",
      "Epoch 13/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 251ms/step - loss: 0.1647 - mae: 0.3457 - val_loss: 0.1056 - val_mae: 0.3028\n",
      "Epoch 14/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - loss: 0.1478 - mae: 0.3167 - val_loss: 0.1004 - val_mae: 0.2946\n",
      "Epoch 15/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - loss: 0.1530 - mae: 0.3253 - val_loss: 0.0968 - val_mae: 0.2885\n",
      "Epoch 16/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 213ms/step - loss: 0.1646 - mae: 0.3330 - val_loss: 0.0995 - val_mae: 0.2955\n",
      "Epoch 17/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 207ms/step - loss: 0.1773 - mae: 0.3549 - val_loss: 0.1056 - val_mae: 0.3082\n",
      "Epoch 18/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - loss: 0.1555 - mae: 0.3306 - val_loss: 0.1209 - val_mae: 0.3321\n",
      "Epoch 19/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 234ms/step - loss: 0.1503 - mae: 0.3190 - val_loss: 0.1417 - val_mae: 0.3577\n",
      "Epoch 20/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 232ms/step - loss: 0.1456 - mae: 0.3190 - val_loss: 0.1377 - val_mae: 0.3538\n",
      "Epoch 21/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250ms/step - loss: 0.1417 - mae: 0.3022 - val_loss: 0.1086 - val_mae: 0.3102\n",
      "Epoch 22/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 214ms/step - loss: 0.1659 - mae: 0.3158 - val_loss: 0.1154 - val_mae: 0.3208\n",
      "Epoch 23/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step - loss: 0.1575 - mae: 0.3269 - val_loss: 0.1142 - val_mae: 0.3173\n",
      "Epoch 24/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273ms/step - loss: 0.1343 - mae: 0.2945 - val_loss: 0.1064 - val_mae: 0.3026\n",
      "Epoch 25/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step - loss: 0.1456 - mae: 0.3032 - val_loss: 0.1040 - val_mae: 0.2968\n",
      "Epoch 26/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338ms/step - loss: 0.1168 - mae: 0.2637 - val_loss: 0.1089 - val_mae: 0.3039\n",
      "Epoch 27/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - loss: 0.1166 - mae: 0.2687 - val_loss: 0.1088 - val_mae: 0.2976\n",
      "Epoch 28/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348ms/step - loss: 0.1375 - mae: 0.2866 - val_loss: 0.1465 - val_mae: 0.3583\n",
      "Epoch 29/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303ms/step - loss: 0.1503 - mae: 0.3227 - val_loss: 0.1315 - val_mae: 0.3287\n",
      "Epoch 30/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312ms/step - loss: 0.1453 - mae: 0.3274 - val_loss: 0.1047 - val_mae: 0.2526\n",
      "Epoch 31/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308ms/step - loss: 0.1258 - mae: 0.2518 - val_loss: 0.1021 - val_mae: 0.2445\n",
      "Epoch 32/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step - loss: 0.1413 - mae: 0.2786 - val_loss: 0.1377 - val_mae: 0.3472\n",
      "Epoch 33/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353ms/step - loss: 0.1176 - mae: 0.2825 - val_loss: 0.1212 - val_mae: 0.3202\n",
      "Epoch 34/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339ms/step - loss: 0.1557 - mae: 0.3350 - val_loss: 0.1067 - val_mae: 0.2820\n",
      "Epoch 35/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step - loss: 0.1241 - mae: 0.2646 - val_loss: 0.0996 - val_mae: 0.2647\n",
      "Epoch 36/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - loss: 0.0909 - mae: 0.2365 - val_loss: 0.1063 - val_mae: 0.2904\n",
      "Epoch 37/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 0.1290 - mae: 0.2949 - val_loss: 0.0926 - val_mae: 0.2588\n",
      "Epoch 38/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - loss: 0.1136 - mae: 0.2482 - val_loss: 0.0968 - val_mae: 0.2630\n",
      "Epoch 39/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - loss: 0.1090 - mae: 0.2545 - val_loss: 0.1303 - val_mae: 0.3265\n",
      "Epoch 40/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341ms/step - loss: 0.1121 - mae: 0.2747 - val_loss: 0.1361 - val_mae: 0.2989\n",
      "Epoch 41/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - loss: 0.1166 - mae: 0.2442 - val_loss: 0.1306 - val_mae: 0.3043\n",
      "Epoch 42/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step - loss: 0.1401 - mae: 0.2972 - val_loss: 0.1302 - val_mae: 0.3229\n",
      "Epoch 43/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 0.0836 - mae: 0.2226 - val_loss: 0.1069 - val_mae: 0.2553\n",
      "Epoch 44/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 288ms/step - loss: 0.0964 - mae: 0.2230 - val_loss: 0.0981 - val_mae: 0.2602\n",
      "Epoch 45/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 262ms/step - loss: 0.1036 - mae: 0.2396 - val_loss: 0.1203 - val_mae: 0.3119\n",
      "Epoch 46/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 255ms/step - loss: 0.1024 - mae: 0.2362 - val_loss: 0.0946 - val_mae: 0.2522\n",
      "Epoch 47/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355ms/step - loss: 0.0921 - mae: 0.2172 - val_loss: 0.0961 - val_mae: 0.2352\n",
      "Epoch 48/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350ms/step - loss: 0.0815 - mae: 0.2151 - val_loss: 0.0945 - val_mae: 0.2435\n",
      "Epoch 49/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step - loss: 0.0841 - mae: 0.2139 - val_loss: 0.0978 - val_mae: 0.2619\n",
      "Epoch 50/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315ms/step - loss: 0.0718 - mae: 0.2098 - val_loss: 0.0927 - val_mae: 0.2381\n",
      "Epoch 51/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - loss: 0.0702 - mae: 0.1936 - val_loss: 0.0915 - val_mae: 0.2326\n",
      "Epoch 52/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318ms/step - loss: 0.0797 - mae: 0.2060 - val_loss: 0.1433 - val_mae: 0.3428\n",
      "Epoch 53/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - loss: 0.0712 - mae: 0.2082 - val_loss: 0.1008 - val_mae: 0.2672\n",
      "Epoch 54/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 360ms/step - loss: 0.0856 - mae: 0.1923 - val_loss: 0.0926 - val_mae: 0.2663\n",
      "Epoch 55/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350ms/step - loss: 0.0754 - mae: 0.2067 - val_loss: 0.0756 - val_mae: 0.2293\n",
      "Epoch 56/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - loss: 0.0595 - mae: 0.1859 - val_loss: 0.0741 - val_mae: 0.2109\n",
      "Epoch 57/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - loss: 0.0747 - mae: 0.1921 - val_loss: 0.0831 - val_mae: 0.2167\n",
      "Epoch 58/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 0.0514 - mae: 0.1639 - val_loss: 0.0884 - val_mae: 0.1969\n",
      "Epoch 59/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - loss: 0.0996 - mae: 0.2040 - val_loss: 0.1028 - val_mae: 0.2030\n",
      "Epoch 60/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - loss: 0.1089 - mae: 0.2292 - val_loss: 0.2850 - val_mae: 0.4344\n",
      "Epoch 61/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - loss: 0.1075 - mae: 0.2418 - val_loss: 0.1915 - val_mae: 0.3977\n",
      "Epoch 62/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370ms/step - loss: 0.1181 - mae: 0.2698 - val_loss: 0.2101 - val_mae: 0.3705\n",
      "Epoch 63/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349ms/step - loss: 0.0737 - mae: 0.2049 - val_loss: 0.1911 - val_mae: 0.3668\n",
      "Epoch 64/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301ms/step - loss: 0.0936 - mae: 0.2331 - val_loss: 0.2172 - val_mae: 0.4343\n",
      "Epoch 65/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 0.1015 - mae: 0.2411 - val_loss: 0.1274 - val_mae: 0.3259\n",
      "Epoch 66/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309ms/step - loss: 0.0760 - mae: 0.2130 - val_loss: 0.0949 - val_mae: 0.2461\n",
      "Epoch 67/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - loss: 0.0574 - mae: 0.1759 - val_loss: 0.1033 - val_mae: 0.2572\n",
      "Epoch 68/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359ms/step - loss: 0.0961 - mae: 0.2354 - val_loss: 0.1222 - val_mae: 0.2837\n",
      "Epoch 69/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - loss: 0.0580 - mae: 0.1750 - val_loss: 0.1252 - val_mae: 0.2818\n",
      "Epoch 70/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 363ms/step - loss: 0.0792 - mae: 0.1917 - val_loss: 0.1211 - val_mae: 0.2783\n",
      "Epoch 71/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 0.0798 - mae: 0.2133 - val_loss: 0.1067 - val_mae: 0.2392\n",
      "Epoch 72/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0529 - mae: 0.1513 - val_loss: 0.1030 - val_mae: 0.2234\n",
      "Epoch 73/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step - loss: 0.0676 - mae: 0.1826 - val_loss: 0.1113 - val_mae: 0.2511\n",
      "Epoch 74/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 399ms/step - loss: 0.0488 - mae: 0.1472 - val_loss: 0.1053 - val_mae: 0.2358\n",
      "Epoch 75/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - loss: 0.0533 - mae: 0.1683 - val_loss: 0.1028 - val_mae: 0.2259\n",
      "Epoch 76/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 0.0515 - mae: 0.1432 - val_loss: 0.1154 - val_mae: 0.2473\n",
      "Epoch 77/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - loss: 0.0472 - mae: 0.1570 - val_loss: 0.1005 - val_mae: 0.2158\n",
      "Epoch 78/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - loss: 0.0485 - mae: 0.1665 - val_loss: 0.1070 - val_mae: 0.2288\n",
      "Epoch 79/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314ms/step - loss: 0.0509 - mae: 0.1606 - val_loss: 0.0945 - val_mae: 0.2127\n",
      "Epoch 80/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308ms/step - loss: 0.0487 - mae: 0.1698 - val_loss: 0.0883 - val_mae: 0.2050\n",
      "Epoch 81/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353ms/step - loss: 0.0469 - mae: 0.1474 - val_loss: 0.1046 - val_mae: 0.2402\n",
      "Epoch 82/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356ms/step - loss: 0.0502 - mae: 0.1666 - val_loss: 0.0830 - val_mae: 0.2086\n",
      "Epoch 83/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - loss: 0.0503 - mae: 0.1560 - val_loss: 0.0724 - val_mae: 0.1856\n",
      "Epoch 84/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308ms/step - loss: 0.0485 - mae: 0.1578 - val_loss: 0.0859 - val_mae: 0.2141\n",
      "Epoch 85/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321ms/step - loss: 0.0590 - mae: 0.1867 - val_loss: 0.1063 - val_mae: 0.2476\n",
      "Epoch 86/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305ms/step - loss: 0.0434 - mae: 0.1577 - val_loss: 0.0825 - val_mae: 0.1987\n",
      "Epoch 87/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323ms/step - loss: 0.0362 - mae: 0.1414 - val_loss: 0.0849 - val_mae: 0.1959\n",
      "Epoch 88/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348ms/step - loss: 0.0383 - mae: 0.1440 - val_loss: 0.1069 - val_mae: 0.2334\n",
      "Epoch 89/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 389ms/step - loss: 0.0343 - mae: 0.1400 - val_loss: 0.1054 - val_mae: 0.2215\n",
      "Epoch 90/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step - loss: 0.0262 - mae: 0.1232 - val_loss: 0.1093 - val_mae: 0.2267\n",
      "Epoch 91/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 307ms/step - loss: 0.0215 - mae: 0.1122 - val_loss: 0.1041 - val_mae: 0.2207\n",
      "Epoch 92/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318ms/step - loss: 0.0272 - mae: 0.1151 - val_loss: 0.1054 - val_mae: 0.2139\n",
      "Epoch 93/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - loss: 0.0188 - mae: 0.1047 - val_loss: 0.1135 - val_mae: 0.2138\n",
      "Epoch 94/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 0.0251 - mae: 0.1184 - val_loss: 0.1082 - val_mae: 0.2009\n",
      "Epoch 95/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - loss: 0.0280 - mae: 0.1282 - val_loss: 0.1127 - val_mae: 0.1940\n",
      "Epoch 96/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 360ms/step - loss: 0.0218 - mae: 0.1045 - val_loss: 0.1180 - val_mae: 0.1863\n",
      "Epoch 97/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step - loss: 0.0355 - mae: 0.1422 - val_loss: 0.1074 - val_mae: 0.1784\n",
      "Epoch 98/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step - loss: 0.0313 - mae: 0.1289 - val_loss: 0.1005 - val_mae: 0.1881\n",
      "Epoch 99/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 296ms/step - loss: 0.0230 - mae: 0.1180 - val_loss: 0.1124 - val_mae: 0.2137\n",
      "Epoch 100/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303ms/step - loss: 0.0263 - mae: 0.1205 - val_loss: 0.0959 - val_mae: 0.1939\n",
      "Epoch 101/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 358ms/step - loss: 0.0142 - mae: 0.0863 - val_loss: 0.0939 - val_mae: 0.1886\n",
      "Epoch 102/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350ms/step - loss: 0.0189 - mae: 0.1089 - val_loss: 0.0960 - val_mae: 0.1863\n",
      "Epoch 103/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - loss: 0.0189 - mae: 0.1044 - val_loss: 0.1096 - val_mae: 0.1947\n",
      "Epoch 104/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step - loss: 0.0154 - mae: 0.0970 - val_loss: 0.1125 - val_mae: 0.1995\n",
      "Epoch 105/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312ms/step - loss: 0.0113 - mae: 0.0800 - val_loss: 0.1172 - val_mae: 0.2040\n",
      "Epoch 106/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 0.0147 - mae: 0.0908 - val_loss: 0.1141 - val_mae: 0.2051\n",
      "Epoch 107/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 498ms/step - loss: 0.0121 - mae: 0.0846 - val_loss: 0.1126 - val_mae: 0.2068\n",
      "Epoch 108/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 421ms/step - loss: 0.0189 - mae: 0.0995 - val_loss: 0.1265 - val_mae: 0.2143\n",
      "Epoch 109/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step - loss: 0.0221 - mae: 0.1192 - val_loss: 0.0948 - val_mae: 0.1664\n",
      "Epoch 110/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322ms/step - loss: 0.0195 - mae: 0.0931 - val_loss: 0.1008 - val_mae: 0.1857\n",
      "Epoch 111/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - loss: 0.0410 - mae: 0.1383 - val_loss: 0.1589 - val_mae: 0.2771\n",
      "Epoch 112/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372ms/step - loss: 0.0434 - mae: 0.1422 - val_loss: 0.0987 - val_mae: 0.2094\n",
      "Epoch 113/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312ms/step - loss: 0.0277 - mae: 0.1111 - val_loss: 0.0863 - val_mae: 0.1599\n",
      "Epoch 114/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367ms/step - loss: 0.0208 - mae: 0.1113 - val_loss: 0.1061 - val_mae: 0.2022\n",
      "Epoch 115/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322ms/step - loss: 0.0321 - mae: 0.1468 - val_loss: 0.0926 - val_mae: 0.1745\n",
      "Epoch 116/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step - loss: 0.0299 - mae: 0.1397 - val_loss: 0.1018 - val_mae: 0.2002\n",
      "Epoch 117/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302ms/step - loss: 0.0230 - mae: 0.1152 - val_loss: 0.1101 - val_mae: 0.2381\n",
      "Epoch 118/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 308ms/step - loss: 0.0201 - mae: 0.1118 - val_loss: 0.0840 - val_mae: 0.1619\n",
      "Epoch 119/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step - loss: 0.0194 - mae: 0.1062 - val_loss: 0.0874 - val_mae: 0.1750\n",
      "Epoch 120/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386ms/step - loss: 0.0146 - mae: 0.0982 - val_loss: 0.0961 - val_mae: 0.2008\n",
      "Epoch 121/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353ms/step - loss: 0.0169 - mae: 0.1092 - val_loss: 0.0956 - val_mae: 0.1964\n",
      "Epoch 122/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - loss: 0.0133 - mae: 0.0819 - val_loss: 0.0969 - val_mae: 0.1913\n",
      "Epoch 123/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339ms/step - loss: 0.0090 - mae: 0.0753 - val_loss: 0.0991 - val_mae: 0.1907\n",
      "Epoch 124/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300ms/step - loss: 0.0164 - mae: 0.0972 - val_loss: 0.2958 - val_mae: 0.3656\n",
      "Epoch 125/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - loss: 0.0485 - mae: 0.1339 - val_loss: 0.1770 - val_mae: 0.2785\n",
      "Epoch 126/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366ms/step - loss: 0.0526 - mae: 0.1371 - val_loss: 0.2010 - val_mae: 0.3425\n",
      "Epoch 127/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 385ms/step - loss: 0.0664 - mae: 0.1730 - val_loss: 0.1230 - val_mae: 0.2580\n",
      "Epoch 128/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - loss: 0.0525 - mae: 0.1454 - val_loss: 0.1517 - val_mae: 0.2822\n",
      "Epoch 129/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304ms/step - loss: 0.0573 - mae: 0.1626 - val_loss: 0.1843 - val_mae: 0.3539\n",
      "Epoch 130/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322ms/step - loss: 0.0441 - mae: 0.1602 - val_loss: 0.1076 - val_mae: 0.2455\n",
      "Epoch 131/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323ms/step - loss: 0.0475 - mae: 0.1426 - val_loss: 0.0936 - val_mae: 0.1897\n",
      "Epoch 132/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 365ms/step - loss: 0.0368 - mae: 0.1158 - val_loss: 0.1181 - val_mae: 0.2581\n",
      "Epoch 133/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 440ms/step - loss: 0.0338 - mae: 0.1367 - val_loss: 0.1491 - val_mae: 0.3067\n",
      "Epoch 134/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - loss: 0.0300 - mae: 0.1341 - val_loss: 0.1349 - val_mae: 0.2703\n",
      "Epoch 135/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - loss: 0.0266 - mae: 0.1133 - val_loss: 0.1068 - val_mae: 0.1895\n",
      "Epoch 136/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371ms/step - loss: 0.0192 - mae: 0.1110 - val_loss: 0.1003 - val_mae: 0.1835\n",
      "Epoch 137/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 422ms/step - loss: 0.0281 - mae: 0.1380 - val_loss: 0.1321 - val_mae: 0.2453\n",
      "Epoch 138/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367ms/step - loss: 0.0280 - mae: 0.1187 - val_loss: 0.1241 - val_mae: 0.2268\n",
      "Epoch 139/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 385ms/step - loss: 0.0160 - mae: 0.0986 - val_loss: 0.1177 - val_mae: 0.2116\n",
      "Epoch 140/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 387ms/step - loss: 0.0137 - mae: 0.0858 - val_loss: 0.1198 - val_mae: 0.2235\n",
      "Epoch 141/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step - loss: 0.0178 - mae: 0.1094 - val_loss: 0.1170 - val_mae: 0.2195\n",
      "Epoch 142/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - loss: 0.0123 - mae: 0.0839 - val_loss: 0.1179 - val_mae: 0.2227\n",
      "Epoch 143/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - loss: 0.0203 - mae: 0.1078 - val_loss: 0.1052 - val_mae: 0.1798\n",
      "Epoch 144/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - loss: 0.0148 - mae: 0.0956 - val_loss: 0.1106 - val_mae: 0.1912\n",
      "Epoch 145/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - loss: 0.0158 - mae: 0.0896 - val_loss: 0.1227 - val_mae: 0.2093\n",
      "Epoch 146/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - loss: 0.0137 - mae: 0.0905 - val_loss: 0.1308 - val_mae: 0.2273\n",
      "Epoch 147/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373ms/step - loss: 0.0118 - mae: 0.0840 - val_loss: 0.1161 - val_mae: 0.1924\n",
      "Epoch 148/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 376ms/step - loss: 0.0115 - mae: 0.0773 - val_loss: 0.0948 - val_mae: 0.1534\n",
      "Epoch 149/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 0.0138 - mae: 0.0888 - val_loss: 0.0927 - val_mae: 0.1711\n",
      "Epoch 150/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322ms/step - loss: 0.0156 - mae: 0.0912 - val_loss: 0.1624 - val_mae: 0.2501\n",
      "Epoch 151/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323ms/step - loss: 0.0140 - mae: 0.0962 - val_loss: 0.1303 - val_mae: 0.2068\n",
      "Epoch 152/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - loss: 0.0145 - mae: 0.0972 - val_loss: 0.1046 - val_mae: 0.1549\n",
      "Epoch 153/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - loss: 0.0064 - mae: 0.0693 - val_loss: 0.0968 - val_mae: 0.1606\n",
      "Epoch 154/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - loss: 0.0091 - mae: 0.0781 - val_loss: 0.0927 - val_mae: 0.1636\n",
      "Epoch 155/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366ms/step - loss: 0.0118 - mae: 0.0826 - val_loss: 0.0943 - val_mae: 0.1779\n",
      "Epoch 156/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356ms/step - loss: 0.0106 - mae: 0.0810 - val_loss: 0.1086 - val_mae: 0.2157\n",
      "Epoch 157/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step - loss: 0.0115 - mae: 0.0881 - val_loss: 0.1105 - val_mae: 0.2088\n",
      "Epoch 158/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322ms/step - loss: 0.0095 - mae: 0.0745 - val_loss: 0.1057 - val_mae: 0.1826\n",
      "Epoch 159/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378ms/step - loss: 0.0090 - mae: 0.0788 - val_loss: 0.1001 - val_mae: 0.1650\n",
      "Epoch 160/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 421ms/step - loss: 0.0112 - mae: 0.0835 - val_loss: 0.1222 - val_mae: 0.1903\n",
      "Epoch 161/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - loss: 0.0057 - mae: 0.0604 - val_loss: 0.1312 - val_mae: 0.2109\n",
      "Epoch 162/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 416ms/step - loss: 0.0096 - mae: 0.0769 - val_loss: 0.1254 - val_mae: 0.2041\n",
      "Epoch 163/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 388ms/step - loss: 0.0079 - mae: 0.0730 - val_loss: 0.1111 - val_mae: 0.1782\n",
      "Epoch 164/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 347ms/step - loss: 0.0108 - mae: 0.0788 - val_loss: 0.1006 - val_mae: 0.1487\n",
      "Epoch 165/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - loss: 0.0159 - mae: 0.0883 - val_loss: 0.1099 - val_mae: 0.1708\n",
      "Epoch 166/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 337ms/step - loss: 0.0132 - mae: 0.0959 - val_loss: 0.1237 - val_mae: 0.2014\n",
      "Epoch 167/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386ms/step - loss: 0.0089 - mae: 0.0721 - val_loss: 0.1274 - val_mae: 0.2035\n",
      "Epoch 168/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338ms/step - loss: 0.0078 - mae: 0.0657 - val_loss: 0.1174 - val_mae: 0.1782\n",
      "Epoch 169/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 422ms/step - loss: 0.0061 - mae: 0.0647 - val_loss: 0.1082 - val_mae: 0.1710\n",
      "Epoch 170/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 431ms/step - loss: 0.0087 - mae: 0.0776 - val_loss: 0.0996 - val_mae: 0.1651\n",
      "Epoch 171/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - loss: 0.0097 - mae: 0.0727 - val_loss: 0.0977 - val_mae: 0.1663\n",
      "Epoch 172/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 341ms/step - loss: 0.0081 - mae: 0.0734 - val_loss: 0.1056 - val_mae: 0.1789\n",
      "Epoch 173/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - loss: 0.0084 - mae: 0.0731 - val_loss: 0.1128 - val_mae: 0.2020\n",
      "Epoch 174/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 424ms/step - loss: 0.0114 - mae: 0.0808 - val_loss: 0.1123 - val_mae: 0.2078\n",
      "Epoch 175/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 405ms/step - loss: 0.0064 - mae: 0.0666 - val_loss: 0.1016 - val_mae: 0.1789\n",
      "Epoch 176/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - loss: 0.0097 - mae: 0.0715 - val_loss: 0.0943 - val_mae: 0.1588\n",
      "Epoch 177/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - loss: 0.0079 - mae: 0.0695 - val_loss: 0.0944 - val_mae: 0.1704\n",
      "Epoch 178/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - loss: 0.0073 - mae: 0.0630 - val_loss: 0.0975 - val_mae: 0.1852\n",
      "Epoch 179/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 0.0105 - mae: 0.0782 - val_loss: 0.1181 - val_mae: 0.2064\n",
      "Epoch 180/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - loss: 0.0061 - mae: 0.0619 - val_loss: 0.1211 - val_mae: 0.1927\n",
      "Epoch 181/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - loss: 0.0069 - mae: 0.0651 - val_loss: 0.1179 - val_mae: 0.1728\n",
      "Epoch 182/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - loss: 0.0061 - mae: 0.0618 - val_loss: 0.1127 - val_mae: 0.1665\n",
      "Epoch 183/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305ms/step - loss: 0.0079 - mae: 0.0666 - val_loss: 0.1130 - val_mae: 0.1856\n",
      "Epoch 184/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301ms/step - loss: 0.0053 - mae: 0.0578 - val_loss: 0.1156 - val_mae: 0.2023\n",
      "Epoch 185/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - loss: 0.0067 - mae: 0.0667 - val_loss: 0.1172 - val_mae: 0.2031\n",
      "Epoch 186/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350ms/step - loss: 0.0077 - mae: 0.0651 - val_loss: 0.1139 - val_mae: 0.1836\n",
      "Epoch 187/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 363ms/step - loss: 0.0094 - mae: 0.0784 - val_loss: 0.1125 - val_mae: 0.1654\n",
      "Epoch 188/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355ms/step - loss: 0.0084 - mae: 0.0699 - val_loss: 0.1191 - val_mae: 0.1854\n",
      "Epoch 189/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349ms/step - loss: 0.0068 - mae: 0.0646 - val_loss: 0.1223 - val_mae: 0.2046\n",
      "Epoch 190/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311ms/step - loss: 0.0081 - mae: 0.0688 - val_loss: 0.1194 - val_mae: 0.2018\n",
      "Epoch 191/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - loss: 0.0076 - mae: 0.0691 - val_loss: 0.1088 - val_mae: 0.1769\n",
      "Epoch 192/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - loss: 0.0063 - mae: 0.0631 - val_loss: 0.1042 - val_mae: 0.1673\n",
      "Epoch 193/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 0.0051 - mae: 0.0505 - val_loss: 0.1047 - val_mae: 0.1751\n",
      "Epoch 194/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - loss: 0.0074 - mae: 0.0685 - val_loss: 0.1034 - val_mae: 0.1797\n",
      "Epoch 195/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 363ms/step - loss: 0.0071 - mae: 0.0632 - val_loss: 0.1021 - val_mae: 0.1799\n",
      "Epoch 196/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - loss: 0.0099 - mae: 0.0748 - val_loss: 0.1005 - val_mae: 0.1687\n",
      "Epoch 197/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 0.0064 - mae: 0.0615 - val_loss: 0.1018 - val_mae: 0.1730\n",
      "Epoch 198/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - loss: 0.0117 - mae: 0.0801 - val_loss: 0.1131 - val_mae: 0.1979\n",
      "Epoch 199/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366ms/step - loss: 0.0061 - mae: 0.0573 - val_loss: 0.1165 - val_mae: 0.2070\n",
      "Epoch 200/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 0.0109 - mae: 0.0749 - val_loss: 0.1065 - val_mae: 0.1784\n",
      "Epoch 201/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - loss: 0.0091 - mae: 0.0693 - val_loss: 0.0960 - val_mae: 0.1542\n",
      "Epoch 202/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - loss: 0.0180 - mae: 0.0953 - val_loss: 0.0959 - val_mae: 0.1656\n",
      "Epoch 203/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step - loss: 0.0073 - mae: 0.0695 - val_loss: 0.1003 - val_mae: 0.1878\n",
      "Epoch 204/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 0.0054 - mae: 0.0575 - val_loss: 0.1008 - val_mae: 0.1873\n",
      "Epoch 205/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321ms/step - loss: 0.0050 - mae: 0.0530 - val_loss: 0.0998 - val_mae: 0.1814\n",
      "Epoch 206/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 0.0068 - mae: 0.0628 - val_loss: 0.1028 - val_mae: 0.1762\n",
      "Epoch 207/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364ms/step - loss: 0.0044 - mae: 0.0537 - val_loss: 0.1056 - val_mae: 0.1777\n",
      "Epoch 208/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321ms/step - loss: 0.0071 - mae: 0.0627 - val_loss: 0.1078 - val_mae: 0.1861\n",
      "Epoch 209/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - loss: 0.0054 - mae: 0.0556 - val_loss: 0.1071 - val_mae: 0.1910\n",
      "Epoch 210/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339ms/step - loss: 0.0058 - mae: 0.0614 - val_loss: 0.1020 - val_mae: 0.1838\n",
      "Epoch 211/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - loss: 0.0037 - mae: 0.0474 - val_loss: 0.0994 - val_mae: 0.1810\n",
      "Epoch 212/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321ms/step - loss: 0.0042 - mae: 0.0531 - val_loss: 0.1050 - val_mae: 0.1837\n",
      "Epoch 213/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - loss: 0.0043 - mae: 0.0509 - val_loss: 0.1114 - val_mae: 0.1916\n",
      "Epoch 214/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367ms/step - loss: 0.0057 - mae: 0.0597 - val_loss: 0.1115 - val_mae: 0.1833\n",
      "Epoch 215/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 375ms/step - loss: 0.0079 - mae: 0.0666 - val_loss: 0.1130 - val_mae: 0.1827\n",
      "Epoch 216/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - loss: 0.0077 - mae: 0.0689 - val_loss: 0.1092 - val_mae: 0.1898\n",
      "Epoch 217/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - loss: 0.0052 - mae: 0.0595 - val_loss: 0.0954 - val_mae: 0.1804\n",
      "Epoch 218/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322ms/step - loss: 0.0048 - mae: 0.0525 - val_loss: 0.0820 - val_mae: 0.1681\n",
      "Epoch 219/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - loss: 0.0068 - mae: 0.0595 - val_loss: 0.0811 - val_mae: 0.1723\n",
      "Epoch 220/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - loss: 0.0048 - mae: 0.0545 - val_loss: 0.0850 - val_mae: 0.1848\n",
      "Epoch 221/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 363ms/step - loss: 0.0061 - mae: 0.0633 - val_loss: 0.0904 - val_mae: 0.1917\n",
      "Epoch 222/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - loss: 0.0080 - mae: 0.0675 - val_loss: 0.0833 - val_mae: 0.1699\n",
      "Epoch 223/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 347ms/step - loss: 0.0061 - mae: 0.0630 - val_loss: 0.0798 - val_mae: 0.1535\n",
      "Epoch 224/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - loss: 0.0059 - mae: 0.0596 - val_loss: 0.0930 - val_mae: 0.1687\n",
      "Epoch 225/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318ms/step - loss: 0.0052 - mae: 0.0586 - val_loss: 0.1007 - val_mae: 0.1814\n",
      "Epoch 226/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - loss: 0.0058 - mae: 0.0626 - val_loss: 0.1059 - val_mae: 0.2046\n",
      "Epoch 227/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314ms/step - loss: 0.0041 - mae: 0.0492 - val_loss: 0.1101 - val_mae: 0.2119\n",
      "Epoch 228/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375ms/step - loss: 0.0059 - mae: 0.0596 - val_loss: 0.1045 - val_mae: 0.1815\n",
      "Epoch 229/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0047 - mae: 0.0515 - val_loss: 0.1036 - val_mae: 0.1691\n",
      "Epoch 230/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - loss: 0.0058 - mae: 0.0597 - val_loss: 0.1070 - val_mae: 0.1821\n",
      "Epoch 231/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - loss: 0.0068 - mae: 0.0649 - val_loss: 0.1113 - val_mae: 0.2059\n",
      "Epoch 232/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 0.0048 - mae: 0.0557 - val_loss: 0.1140 - val_mae: 0.2173\n",
      "Epoch 233/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373ms/step - loss: 0.0051 - mae: 0.0547 - val_loss: 0.1135 - val_mae: 0.2160\n",
      "Epoch 234/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - loss: 0.0045 - mae: 0.0498 - val_loss: 0.1118 - val_mae: 0.2120\n",
      "Epoch 235/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 361ms/step - loss: 0.0064 - mae: 0.0624 - val_loss: 0.1108 - val_mae: 0.2056\n",
      "Epoch 236/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - loss: 0.0045 - mae: 0.0518 - val_loss: 0.1112 - val_mae: 0.2040\n",
      "Epoch 237/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - loss: 0.0070 - mae: 0.0662 - val_loss: 0.1153 - val_mae: 0.2056\n",
      "Epoch 238/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - loss: 0.0066 - mae: 0.0638 - val_loss: 0.1120 - val_mae: 0.1967\n",
      "Epoch 239/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - loss: 0.0054 - mae: 0.0579 - val_loss: 0.1159 - val_mae: 0.1982\n",
      "Epoch 240/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 402ms/step - loss: 0.0071 - mae: 0.0524 - val_loss: 0.1358 - val_mae: 0.2268\n",
      "Epoch 241/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - loss: 0.0070 - mae: 0.0611 - val_loss: 0.1450 - val_mae: 0.2343\n",
      "Epoch 242/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0053 - mae: 0.0568 - val_loss: 0.1428 - val_mae: 0.2262\n",
      "Epoch 243/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - loss: 0.0040 - mae: 0.0519 - val_loss: 0.1408 - val_mae: 0.2286\n",
      "Epoch 244/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 0.0044 - mae: 0.0493 - val_loss: 0.1376 - val_mae: 0.2333\n",
      "Epoch 245/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 363ms/step - loss: 0.0054 - mae: 0.0565 - val_loss: 0.1272 - val_mae: 0.2214\n",
      "Epoch 246/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359ms/step - loss: 0.0056 - mae: 0.0618 - val_loss: 0.1191 - val_mae: 0.2108\n",
      "Epoch 247/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366ms/step - loss: 0.0067 - mae: 0.0651 - val_loss: 0.1129 - val_mae: 0.1968\n",
      "Epoch 248/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 0.0050 - mae: 0.0553 - val_loss: 0.1118 - val_mae: 0.1975\n",
      "Epoch 249/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0035 - mae: 0.0431 - val_loss: 0.1112 - val_mae: 0.1950\n",
      "Epoch 250/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - loss: 0.0048 - mae: 0.0527 - val_loss: 0.1151 - val_mae: 0.2061\n",
      "Epoch 251/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - loss: 0.0057 - mae: 0.0546 - val_loss: 0.1180 - val_mae: 0.2147\n",
      "Epoch 252/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348ms/step - loss: 0.0040 - mae: 0.0478 - val_loss: 0.1112 - val_mae: 0.1984\n",
      "Epoch 253/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step - loss: 0.0048 - mae: 0.0576 - val_loss: 0.1068 - val_mae: 0.1880\n",
      "Epoch 254/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 365ms/step - loss: 0.0034 - mae: 0.0453 - val_loss: 0.1119 - val_mae: 0.2010\n",
      "Epoch 255/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323ms/step - loss: 0.0049 - mae: 0.0556 - val_loss: 0.1114 - val_mae: 0.2046\n",
      "Epoch 256/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0045 - mae: 0.0516 - val_loss: 0.1113 - val_mae: 0.2066\n",
      "Epoch 257/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - loss: 0.0057 - mae: 0.0558 - val_loss: 0.1038 - val_mae: 0.1886\n",
      "Epoch 258/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339ms/step - loss: 0.0069 - mae: 0.0676 - val_loss: 0.0970 - val_mae: 0.1747\n",
      "Epoch 259/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - loss: 0.0059 - mae: 0.0577 - val_loss: 0.1013 - val_mae: 0.1905\n",
      "Epoch 260/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - loss: 0.0044 - mae: 0.0552 - val_loss: 0.1079 - val_mae: 0.2074\n",
      "Epoch 261/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 387ms/step - loss: 0.0052 - mae: 0.0576 - val_loss: 0.1089 - val_mae: 0.2094\n",
      "Epoch 262/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step - loss: 0.0051 - mae: 0.0493 - val_loss: 0.1071 - val_mae: 0.2029\n",
      "Epoch 263/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step - loss: 0.0041 - mae: 0.0492 - val_loss: 0.1014 - val_mae: 0.1881\n",
      "Epoch 264/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338ms/step - loss: 0.0033 - mae: 0.0450 - val_loss: 0.1001 - val_mae: 0.1901\n",
      "Epoch 265/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 365ms/step - loss: 0.0034 - mae: 0.0475 - val_loss: 0.1017 - val_mae: 0.2011\n",
      "Epoch 266/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - loss: 0.0048 - mae: 0.0562 - val_loss: 0.1003 - val_mae: 0.2002\n",
      "Epoch 267/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 375ms/step - loss: 0.0042 - mae: 0.0502 - val_loss: 0.1012 - val_mae: 0.1926\n",
      "Epoch 268/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - loss: 0.0036 - mae: 0.0451 - val_loss: 0.1081 - val_mae: 0.2014\n",
      "Epoch 269/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323ms/step - loss: 0.0038 - mae: 0.0509 - val_loss: 0.1118 - val_mae: 0.2071\n",
      "Epoch 270/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0030 - mae: 0.0397 - val_loss: 0.1106 - val_mae: 0.2004\n",
      "Epoch 271/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341ms/step - loss: 0.0052 - mae: 0.0585 - val_loss: 0.1101 - val_mae: 0.2008\n",
      "Epoch 272/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 352ms/step - loss: 0.0050 - mae: 0.0534 - val_loss: 0.1083 - val_mae: 0.2002\n",
      "Epoch 273/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 389ms/step - loss: 0.0040 - mae: 0.0507 - val_loss: 0.1086 - val_mae: 0.2016\n",
      "Epoch 274/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 387ms/step - loss: 0.0075 - mae: 0.0696 - val_loss: 0.1128 - val_mae: 0.2151\n",
      "Epoch 275/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312ms/step - loss: 0.0062 - mae: 0.0609 - val_loss: 0.1035 - val_mae: 0.1878\n",
      "Epoch 276/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0058 - mae: 0.0578 - val_loss: 0.1058 - val_mae: 0.1867\n",
      "Epoch 277/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - loss: 0.0039 - mae: 0.0502 - val_loss: 0.1178 - val_mae: 0.2145\n",
      "Epoch 278/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350ms/step - loss: 0.0038 - mae: 0.0454 - val_loss: 0.1291 - val_mae: 0.2413\n",
      "Epoch 279/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366ms/step - loss: 0.0045 - mae: 0.0544 - val_loss: 0.1262 - val_mae: 0.2304\n",
      "Epoch 280/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - loss: 0.0094 - mae: 0.0610 - val_loss: 0.1025 - val_mae: 0.1871\n",
      "Epoch 281/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 0.0036 - mae: 0.0505 - val_loss: 0.0799 - val_mae: 0.1615\n",
      "Epoch 282/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 0.0032 - mae: 0.0416 - val_loss: 0.0755 - val_mae: 0.1714\n",
      "Epoch 283/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314ms/step - loss: 0.0045 - mae: 0.0553 - val_loss: 0.0825 - val_mae: 0.1988\n",
      "Epoch 284/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350ms/step - loss: 0.0042 - mae: 0.0484 - val_loss: 0.0798 - val_mae: 0.1929\n",
      "Epoch 285/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367ms/step - loss: 0.0030 - mae: 0.0416 - val_loss: 0.0984 - val_mae: 0.1906\n",
      "Epoch 286/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - loss: 0.0055 - mae: 0.0566 - val_loss: 0.1724 - val_mae: 0.2422\n",
      "Epoch 287/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0107 - mae: 0.0611 - val_loss: 0.1458 - val_mae: 0.2184\n",
      "Epoch 288/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 0.0032 - mae: 0.0458 - val_loss: 0.1030 - val_mae: 0.1778\n",
      "Epoch 289/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - loss: 0.0037 - mae: 0.0471 - val_loss: 0.0838 - val_mae: 0.1733\n",
      "Epoch 290/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - loss: 0.0054 - mae: 0.0588 - val_loss: 0.0742 - val_mae: 0.1686\n",
      "Epoch 291/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - loss: 0.0065 - mae: 0.0582 - val_loss: 0.0686 - val_mae: 0.1563\n",
      "Epoch 292/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380ms/step - loss: 0.0048 - mae: 0.0552 - val_loss: 0.0684 - val_mae: 0.1535\n",
      "Epoch 293/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - loss: 0.0044 - mae: 0.0552 - val_loss: 0.0673 - val_mae: 0.1515\n",
      "Epoch 294/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - loss: 0.0042 - mae: 0.0487 - val_loss: 0.0683 - val_mae: 0.1633\n",
      "Epoch 295/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311ms/step - loss: 0.0047 - mae: 0.0547 - val_loss: 0.0736 - val_mae: 0.1828\n",
      "Epoch 296/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - loss: 0.0045 - mae: 0.0503 - val_loss: 0.0695 - val_mae: 0.1678\n",
      "Epoch 297/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - loss: 0.0048 - mae: 0.0557 - val_loss: 0.0658 - val_mae: 0.1433\n",
      "Epoch 298/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378ms/step - loss: 0.0039 - mae: 0.0514 - val_loss: 0.0723 - val_mae: 0.1595\n",
      "Epoch 299/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - loss: 0.0034 - mae: 0.0454 - val_loss: 0.0793 - val_mae: 0.1766\n",
      "Epoch 300/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348ms/step - loss: 0.0033 - mae: 0.0460 - val_loss: 0.0826 - val_mae: 0.1846\n",
      "Epoch 301/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step - loss: 0.0040 - mae: 0.0520 - val_loss: 0.0813 - val_mae: 0.1822\n",
      "Epoch 302/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338ms/step - loss: 0.0038 - mae: 0.0469 - val_loss: 0.0819 - val_mae: 0.1845\n",
      "Epoch 303/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0031 - mae: 0.0436 - val_loss: 0.0804 - val_mae: 0.1762\n",
      "Epoch 304/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349ms/step - loss: 0.0047 - mae: 0.0507 - val_loss: 0.0797 - val_mae: 0.1742\n",
      "Epoch 305/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315ms/step - loss: 0.0041 - mae: 0.0499 - val_loss: 0.0804 - val_mae: 0.1801\n",
      "Epoch 306/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step - loss: 0.0038 - mae: 0.0505 - val_loss: 0.0799 - val_mae: 0.1799\n",
      "Epoch 307/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338ms/step - loss: 0.0023 - mae: 0.0393 - val_loss: 0.0766 - val_mae: 0.1693\n",
      "Epoch 308/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314ms/step - loss: 0.0031 - mae: 0.0442 - val_loss: 0.0734 - val_mae: 0.1614\n",
      "Epoch 309/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - loss: 0.0047 - mae: 0.0557 - val_loss: 0.0766 - val_mae: 0.1656\n",
      "Epoch 310/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382ms/step - loss: 0.0030 - mae: 0.0429 - val_loss: 0.0780 - val_mae: 0.1658\n",
      "Epoch 311/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - loss: 0.0043 - mae: 0.0522 - val_loss: 0.0785 - val_mae: 0.1661\n",
      "Epoch 312/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - loss: 0.0021 - mae: 0.0381 - val_loss: 0.0792 - val_mae: 0.1758\n",
      "Epoch 313/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363ms/step - loss: 0.0034 - mae: 0.0446 - val_loss: 0.0743 - val_mae: 0.1653\n",
      "Epoch 314/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 0.0047 - mae: 0.0557 - val_loss: 0.0715 - val_mae: 0.1551\n",
      "Epoch 315/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - loss: 0.0030 - mae: 0.0450 - val_loss: 0.0715 - val_mae: 0.1564\n",
      "Epoch 316/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0039 - mae: 0.0515 - val_loss: 0.0716 - val_mae: 0.1602\n",
      "Epoch 317/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step - loss: 0.0043 - mae: 0.0524 - val_loss: 0.0698 - val_mae: 0.1587\n",
      "Epoch 318/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - loss: 0.0038 - mae: 0.0472 - val_loss: 0.0660 - val_mae: 0.1535\n",
      "Epoch 319/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - loss: 0.0032 - mae: 0.0447 - val_loss: 0.0693 - val_mae: 0.1692\n",
      "Epoch 320/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 0.0060 - mae: 0.0585 - val_loss: 0.0685 - val_mae: 0.1603\n",
      "Epoch 321/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - loss: 0.0040 - mae: 0.0494 - val_loss: 0.0690 - val_mae: 0.1574\n",
      "Epoch 322/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - loss: 0.0044 - mae: 0.0537 - val_loss: 0.0845 - val_mae: 0.1823\n",
      "Epoch 323/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 387ms/step - loss: 0.0057 - mae: 0.0540 - val_loss: 0.0910 - val_mae: 0.1800\n",
      "Epoch 324/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341ms/step - loss: 0.0031 - mae: 0.0448 - val_loss: 0.0937 - val_mae: 0.1798\n",
      "Epoch 325/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - loss: 0.0044 - mae: 0.0506 - val_loss: 0.0913 - val_mae: 0.1727\n",
      "Epoch 326/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356ms/step - loss: 0.0042 - mae: 0.0528 - val_loss: 0.0879 - val_mae: 0.1763\n",
      "Epoch 327/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314ms/step - loss: 0.0028 - mae: 0.0410 - val_loss: 0.0858 - val_mae: 0.1740\n",
      "Epoch 328/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334ms/step - loss: 0.0033 - mae: 0.0459 - val_loss: 0.0902 - val_mae: 0.1832\n",
      "Epoch 329/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - loss: 0.0045 - mae: 0.0510 - val_loss: 0.0945 - val_mae: 0.1984\n",
      "Epoch 330/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356ms/step - loss: 0.0023 - mae: 0.0402 - val_loss: 0.0933 - val_mae: 0.1960\n",
      "Epoch 331/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0879 - val_mae: 0.1824\n",
      "Epoch 332/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - loss: 0.0040 - mae: 0.0482 - val_loss: 0.0793 - val_mae: 0.1664\n",
      "Epoch 333/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - loss: 0.0041 - mae: 0.0513 - val_loss: 0.0720 - val_mae: 0.1614\n",
      "Epoch 334/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0347 - mae: 0.0871 - val_loss: 0.1172 - val_mae: 0.2028\n",
      "Epoch 335/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 0.0273 - mae: 0.0867 - val_loss: 0.1443 - val_mae: 0.2644\n",
      "Epoch 336/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334ms/step - loss: 0.0661 - mae: 0.1566 - val_loss: 0.1782 - val_mae: 0.3405\n",
      "Epoch 337/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 0.0503 - mae: 0.1650 - val_loss: 0.1091 - val_mae: 0.2597\n",
      "Epoch 338/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371ms/step - loss: 0.0395 - mae: 0.1291 - val_loss: 0.1126 - val_mae: 0.2527\n",
      "Epoch 339/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0318 - mae: 0.1209 - val_loss: 0.0769 - val_mae: 0.1938\n",
      "Epoch 340/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0361 - mae: 0.1212 - val_loss: 0.0495 - val_mae: 0.1373\n",
      "Epoch 341/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364ms/step - loss: 0.0278 - mae: 0.1067 - val_loss: 0.1972 - val_mae: 0.3233\n",
      "Epoch 342/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - loss: 0.0245 - mae: 0.1032 - val_loss: 0.1213 - val_mae: 0.2370\n",
      "Epoch 343/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 407ms/step - loss: 0.0345 - mae: 0.1125 - val_loss: 0.1089 - val_mae: 0.2039\n",
      "Epoch 344/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - loss: 0.0340 - mae: 0.1166 - val_loss: 0.1845 - val_mae: 0.2946\n",
      "Epoch 345/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 360ms/step - loss: 0.0474 - mae: 0.1309 - val_loss: 0.0581 - val_mae: 0.1457\n",
      "Epoch 346/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - loss: 0.0556 - mae: 0.1200 - val_loss: 0.1009 - val_mae: 0.2235\n",
      "Epoch 347/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - loss: 0.0738 - mae: 0.1626 - val_loss: 0.1375 - val_mae: 0.3182\n",
      "Epoch 348/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0965 - mae: 0.2298 - val_loss: 0.1463 - val_mae: 0.3318\n",
      "Epoch 349/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341ms/step - loss: 0.0800 - mae: 0.1974 - val_loss: 0.1205 - val_mae: 0.2760\n",
      "Epoch 350/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 0.0597 - mae: 0.1438 - val_loss: 0.0806 - val_mae: 0.2004\n",
      "Epoch 351/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - loss: 0.0340 - mae: 0.1295 - val_loss: 0.2689 - val_mae: 0.3720\n",
      "Epoch 352/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 365ms/step - loss: 0.0475 - mae: 0.1361 - val_loss: 0.1017 - val_mae: 0.2078\n",
      "Epoch 353/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373ms/step - loss: 0.0327 - mae: 0.1229 - val_loss: 0.1394 - val_mae: 0.2364\n",
      "Epoch 354/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step - loss: 0.0229 - mae: 0.0997 - val_loss: 0.1572 - val_mae: 0.2906\n",
      "Epoch 355/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - loss: 0.0232 - mae: 0.1090 - val_loss: 0.1033 - val_mae: 0.2410\n",
      "Epoch 356/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step - loss: 0.0174 - mae: 0.0987 - val_loss: 0.0820 - val_mae: 0.1780\n",
      "Epoch 357/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366ms/step - loss: 0.0152 - mae: 0.0949 - val_loss: 0.1110 - val_mae: 0.2102\n",
      "Epoch 358/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 361ms/step - loss: 0.0132 - mae: 0.0850 - val_loss: 0.1194 - val_mae: 0.2160\n",
      "Epoch 359/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - loss: 0.0202 - mae: 0.1044 - val_loss: 0.0898 - val_mae: 0.1721\n",
      "Epoch 360/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - loss: 0.0162 - mae: 0.1000 - val_loss: 0.0742 - val_mae: 0.1738\n",
      "Epoch 361/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339ms/step - loss: 0.0282 - mae: 0.1043 - val_loss: 0.1152 - val_mae: 0.2604\n",
      "Epoch 362/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - loss: 0.0155 - mae: 0.0916 - val_loss: 0.1093 - val_mae: 0.2309\n",
      "Epoch 363/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353ms/step - loss: 0.0064 - mae: 0.0635 - val_loss: 0.0832 - val_mae: 0.1491\n",
      "Epoch 364/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367ms/step - loss: 0.0083 - mae: 0.0736 - val_loss: 0.0786 - val_mae: 0.1377\n",
      "Epoch 365/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - loss: 0.0104 - mae: 0.0735 - val_loss: 0.0901 - val_mae: 0.1766\n",
      "Epoch 366/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0105 - mae: 0.0832 - val_loss: 0.1046 - val_mae: 0.2197\n",
      "Epoch 367/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339ms/step - loss: 0.0065 - mae: 0.0646 - val_loss: 0.0983 - val_mae: 0.2120\n",
      "Epoch 368/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - loss: 0.0075 - mae: 0.0704 - val_loss: 0.0872 - val_mae: 0.1787\n",
      "Epoch 369/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366ms/step - loss: 0.0044 - mae: 0.0499 - val_loss: 0.0845 - val_mae: 0.1593\n",
      "Epoch 370/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 397ms/step - loss: 0.0072 - mae: 0.0657 - val_loss: 0.0916 - val_mae: 0.1676\n",
      "Epoch 371/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - loss: 0.0041 - mae: 0.0498 - val_loss: 0.0988 - val_mae: 0.1839\n",
      "Epoch 372/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step - loss: 0.0051 - mae: 0.0559 - val_loss: 0.1006 - val_mae: 0.1875\n",
      "Epoch 373/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338ms/step - loss: 0.0059 - mae: 0.0615 - val_loss: 0.1003 - val_mae: 0.1871\n",
      "Epoch 374/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - loss: 0.0032 - mae: 0.0442 - val_loss: 0.0988 - val_mae: 0.1797\n",
      "Epoch 375/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 391ms/step - loss: 0.0052 - mae: 0.0556 - val_loss: 0.0967 - val_mae: 0.1691\n",
      "Epoch 376/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366ms/step - loss: 0.0049 - mae: 0.0558 - val_loss: 0.0954 - val_mae: 0.1626\n",
      "Epoch 377/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341ms/step - loss: 0.0061 - mae: 0.0598 - val_loss: 0.0983 - val_mae: 0.1748\n",
      "Epoch 378/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - loss: 0.0044 - mae: 0.0477 - val_loss: 0.0990 - val_mae: 0.1813\n",
      "Epoch 379/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - loss: 0.0051 - mae: 0.0570 - val_loss: 0.0990 - val_mae: 0.1757\n",
      "Epoch 380/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 364ms/step - loss: 0.0032 - mae: 0.0484 - val_loss: 0.0961 - val_mae: 0.1634\n",
      "Epoch 381/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - loss: 0.0041 - mae: 0.0515 - val_loss: 0.0995 - val_mae: 0.1764\n",
      "Epoch 382/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378ms/step - loss: 0.0064 - mae: 0.0634 - val_loss: 0.1089 - val_mae: 0.2021\n",
      "Epoch 383/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - loss: 0.0034 - mae: 0.0438 - val_loss: 0.1168 - val_mae: 0.2208\n",
      "Epoch 384/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366ms/step - loss: 0.0054 - mae: 0.0583 - val_loss: 0.1097 - val_mae: 0.2053\n",
      "Epoch 385/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - loss: 0.0037 - mae: 0.0437 - val_loss: 0.1010 - val_mae: 0.1831\n",
      "Epoch 386/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0037 - mae: 0.0442 - val_loss: 0.0985 - val_mae: 0.1819\n",
      "Epoch 387/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step - loss: 0.0027 - mae: 0.0425 - val_loss: 0.0952 - val_mae: 0.1801\n",
      "Epoch 388/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 385ms/step - loss: 0.0028 - mae: 0.0393 - val_loss: 0.0922 - val_mae: 0.1793\n",
      "Epoch 389/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - loss: 0.0048 - mae: 0.0557 - val_loss: 0.0912 - val_mae: 0.1825\n",
      "Epoch 390/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - loss: 0.0042 - mae: 0.0513 - val_loss: 0.0984 - val_mae: 0.1996\n",
      "Epoch 391/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - loss: 0.0034 - mae: 0.0463 - val_loss: 0.1040 - val_mae: 0.2015\n",
      "Epoch 392/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0036 - mae: 0.0481 - val_loss: 0.1015 - val_mae: 0.1860\n",
      "Epoch 393/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323ms/step - loss: 0.0049 - mae: 0.0514 - val_loss: 0.0986 - val_mae: 0.1775\n",
      "Epoch 394/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - loss: 0.0046 - mae: 0.0509 - val_loss: 0.1033 - val_mae: 0.1911\n",
      "Epoch 395/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 362ms/step - loss: 0.0027 - mae: 0.0425 - val_loss: 0.1073 - val_mae: 0.2044\n",
      "Epoch 396/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - loss: 0.0046 - mae: 0.0549 - val_loss: 0.0945 - val_mae: 0.1800\n",
      "Epoch 397/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 0.0019 - mae: 0.0329 - val_loss: 0.0874 - val_mae: 0.1611\n",
      "Epoch 398/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step - loss: 0.0029 - mae: 0.0386 - val_loss: 0.0844 - val_mae: 0.1550\n",
      "Epoch 399/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0824 - val_mae: 0.1585\n",
      "Epoch 400/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322ms/step - loss: 0.0042 - mae: 0.0552 - val_loss: 0.0814 - val_mae: 0.1684\n",
      "Epoch 401/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 374ms/step - loss: 0.0047 - mae: 0.0511 - val_loss: 0.0771 - val_mae: 0.1636\n",
      "Epoch 402/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - loss: 0.0032 - mae: 0.0456 - val_loss: 0.0748 - val_mae: 0.1600\n",
      "Epoch 403/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370ms/step - loss: 0.0041 - mae: 0.0527 - val_loss: 0.0774 - val_mae: 0.1730\n",
      "Epoch 404/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - loss: 0.0043 - mae: 0.0492 - val_loss: 0.0787 - val_mae: 0.1747\n",
      "Epoch 405/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - loss: 0.0029 - mae: 0.0442 - val_loss: 0.0768 - val_mae: 0.1679\n",
      "Epoch 406/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - loss: 0.0029 - mae: 0.0447 - val_loss: 0.0751 - val_mae: 0.1670\n",
      "Epoch 407/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384ms/step - loss: 0.0050 - mae: 0.0578 - val_loss: 0.0764 - val_mae: 0.1764\n",
      "Epoch 408/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367ms/step - loss: 0.0059 - mae: 0.0491 - val_loss: 0.0759 - val_mae: 0.1749\n",
      "Epoch 409/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348ms/step - loss: 0.0040 - mae: 0.0504 - val_loss: 0.0723 - val_mae: 0.1595\n",
      "Epoch 410/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - loss: 0.0051 - mae: 0.0550 - val_loss: 0.0697 - val_mae: 0.1539\n",
      "Epoch 411/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - loss: 0.0034 - mae: 0.0469 - val_loss: 0.0705 - val_mae: 0.1613\n",
      "Epoch 412/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - loss: 0.0031 - mae: 0.0459 - val_loss: 0.0701 - val_mae: 0.1604\n",
      "Epoch 413/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step - loss: 0.0026 - mae: 0.0391 - val_loss: 0.0701 - val_mae: 0.1625\n",
      "Epoch 414/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370ms/step - loss: 0.0026 - mae: 0.0395 - val_loss: 0.0698 - val_mae: 0.1654\n",
      "Epoch 415/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - loss: 0.0025 - mae: 0.0395 - val_loss: 0.0724 - val_mae: 0.1778\n",
      "Epoch 416/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - loss: 0.0035 - mae: 0.0476 - val_loss: 0.0772 - val_mae: 0.1908\n",
      "Epoch 417/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - loss: 0.0041 - mae: 0.0528 - val_loss: 0.0733 - val_mae: 0.1790\n",
      "Epoch 418/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - loss: 0.0031 - mae: 0.0404 - val_loss: 0.0646 - val_mae: 0.1458\n",
      "Epoch 419/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315ms/step - loss: 0.0037 - mae: 0.0502 - val_loss: 0.0646 - val_mae: 0.1397\n",
      "Epoch 420/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - loss: 0.0033 - mae: 0.0453 - val_loss: 0.0717 - val_mae: 0.1609\n",
      "Epoch 421/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - loss: 0.0025 - mae: 0.0424 - val_loss: 0.0788 - val_mae: 0.1823\n",
      "Epoch 422/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 389ms/step - loss: 0.0038 - mae: 0.0461 - val_loss: 0.0858 - val_mae: 0.1947\n",
      "Epoch 423/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 358ms/step - loss: 0.0036 - mae: 0.0476 - val_loss: 0.0813 - val_mae: 0.1709\n",
      "Epoch 424/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - loss: 0.0031 - mae: 0.0409 - val_loss: 0.0784 - val_mae: 0.1495\n",
      "Epoch 425/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - loss: 0.0044 - mae: 0.0531 - val_loss: 0.0868 - val_mae: 0.1749\n",
      "Epoch 426/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - loss: 0.0032 - mae: 0.0454 - val_loss: 0.0945 - val_mae: 0.1993\n",
      "Epoch 427/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - loss: 0.0025 - mae: 0.0361 - val_loss: 0.0962 - val_mae: 0.2024\n",
      "Epoch 428/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323ms/step - loss: 0.0023 - mae: 0.0403 - val_loss: 0.0908 - val_mae: 0.1866\n",
      "Epoch 429/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 385ms/step - loss: 0.0028 - mae: 0.0398 - val_loss: 0.0843 - val_mae: 0.1652\n",
      "Epoch 430/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372ms/step - loss: 0.0027 - mae: 0.0385 - val_loss: 0.0817 - val_mae: 0.1683\n",
      "Epoch 431/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - loss: 0.0032 - mae: 0.0445 - val_loss: 0.0819 - val_mae: 0.1787\n",
      "Epoch 432/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - loss: 0.0042 - mae: 0.0498 - val_loss: 0.0817 - val_mae: 0.1776\n",
      "Epoch 433/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0799 - val_mae: 0.1731\n",
      "Epoch 434/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 380ms/step - loss: 0.0043 - mae: 0.0495 - val_loss: 0.0822 - val_mae: 0.1790\n",
      "Epoch 435/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 394ms/step - loss: 0.0029 - mae: 0.0435 - val_loss: 0.0794 - val_mae: 0.1696\n",
      "Epoch 436/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341ms/step - loss: 0.0031 - mae: 0.0422 - val_loss: 0.0808 - val_mae: 0.1754\n",
      "Epoch 437/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step - loss: 0.0027 - mae: 0.0436 - val_loss: 0.0816 - val_mae: 0.1816\n",
      "Epoch 438/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - loss: 0.0035 - mae: 0.0457 - val_loss: 0.0755 - val_mae: 0.1677\n",
      "Epoch 439/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - loss: 0.0024 - mae: 0.0391 - val_loss: 0.0715 - val_mae: 0.1581\n",
      "Epoch 440/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 394ms/step - loss: 0.0031 - mae: 0.0433 - val_loss: 0.0750 - val_mae: 0.1741\n",
      "Epoch 441/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - loss: 0.0033 - mae: 0.0429 - val_loss: 0.0788 - val_mae: 0.1852\n",
      "Epoch 442/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - loss: 0.0033 - mae: 0.0451 - val_loss: 0.0804 - val_mae: 0.1876\n",
      "Epoch 443/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - loss: 0.0029 - mae: 0.0428 - val_loss: 0.0796 - val_mae: 0.1806\n",
      "Epoch 444/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305ms/step - loss: 0.0030 - mae: 0.0383 - val_loss: 0.0764 - val_mae: 0.1676\n",
      "Epoch 445/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350ms/step - loss: 0.0026 - mae: 0.0420 - val_loss: 0.0740 - val_mae: 0.1578\n",
      "Epoch 446/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 374ms/step - loss: 0.0034 - mae: 0.0476 - val_loss: 0.0761 - val_mae: 0.1674\n",
      "Epoch 447/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 387ms/step - loss: 0.0018 - mae: 0.0325 - val_loss: 0.0792 - val_mae: 0.1791\n",
      "Epoch 448/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341ms/step - loss: 0.0026 - mae: 0.0412 - val_loss: 0.0762 - val_mae: 0.1706\n",
      "Epoch 449/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0730 - val_mae: 0.1626\n",
      "Epoch 450/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step - loss: 0.0041 - mae: 0.0457 - val_loss: 0.0746 - val_mae: 0.1716\n",
      "Epoch 451/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321ms/step - loss: 0.0031 - mae: 0.0448 - val_loss: 0.0739 - val_mae: 0.1712\n",
      "Epoch 452/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 359ms/step - loss: 0.0021 - mae: 0.0338 - val_loss: 0.0701 - val_mae: 0.1584\n",
      "Epoch 453/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372ms/step - loss: 0.0052 - mae: 0.0547 - val_loss: 0.0726 - val_mae: 0.1678\n",
      "Epoch 454/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - loss: 0.0029 - mae: 0.0447 - val_loss: 0.0744 - val_mae: 0.1725\n",
      "Epoch 455/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0760 - val_mae: 0.1746\n",
      "Epoch 456/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309ms/step - loss: 0.0024 - mae: 0.0382 - val_loss: 0.0765 - val_mae: 0.1775\n",
      "Epoch 457/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - loss: 0.0035 - mae: 0.0415 - val_loss: 0.0758 - val_mae: 0.1839\n",
      "Epoch 458/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353ms/step - loss: 0.0029 - mae: 0.0422 - val_loss: 0.0712 - val_mae: 0.1755\n",
      "Epoch 459/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 395ms/step - loss: 0.0033 - mae: 0.0456 - val_loss: 0.0631 - val_mae: 0.1547\n",
      "Epoch 460/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 368ms/step - loss: 0.0026 - mae: 0.0393 - val_loss: 0.0589 - val_mae: 0.1420\n",
      "Epoch 461/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373ms/step - loss: 0.0037 - mae: 0.0502 - val_loss: 0.0638 - val_mae: 0.1627\n",
      "Epoch 462/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341ms/step - loss: 0.0022 - mae: 0.0389 - val_loss: 0.0665 - val_mae: 0.1712\n",
      "Epoch 463/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - loss: 0.0028 - mae: 0.0421 - val_loss: 0.0653 - val_mae: 0.1669\n",
      "Epoch 464/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348ms/step - loss: 0.0019 - mae: 0.0332 - val_loss: 0.0650 - val_mae: 0.1677\n",
      "Epoch 465/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - loss: 0.0022 - mae: 0.0388 - val_loss: 0.0641 - val_mae: 0.1658\n",
      "Epoch 466/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 404ms/step - loss: 0.0025 - mae: 0.0389 - val_loss: 0.0607 - val_mae: 0.1555\n",
      "Epoch 467/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - loss: 0.0024 - mae: 0.0368 - val_loss: 0.0616 - val_mae: 0.1603\n",
      "Epoch 468/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - loss: 0.0029 - mae: 0.0404 - val_loss: 0.0639 - val_mae: 0.1658\n",
      "Epoch 469/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step - loss: 0.0022 - mae: 0.0381 - val_loss: 0.0637 - val_mae: 0.1613\n",
      "Epoch 470/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321ms/step - loss: 0.0018 - mae: 0.0335 - val_loss: 0.0644 - val_mae: 0.1618\n",
      "Epoch 471/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - loss: 0.0020 - mae: 0.0357 - val_loss: 0.0628 - val_mae: 0.1581\n",
      "Epoch 472/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step - loss: 0.0026 - mae: 0.0396 - val_loss: 0.0641 - val_mae: 0.1635\n",
      "Epoch 473/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368ms/step - loss: 0.0028 - mae: 0.0386 - val_loss: 0.0693 - val_mae: 0.1763\n",
      "Epoch 474/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - loss: 0.0028 - mae: 0.0418 - val_loss: 0.0705 - val_mae: 0.1783\n",
      "Epoch 475/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - loss: 0.0021 - mae: 0.0358 - val_loss: 0.0675 - val_mae: 0.1644\n",
      "Epoch 476/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - loss: 0.0019 - mae: 0.0331 - val_loss: 0.0688 - val_mae: 0.1641\n",
      "Epoch 477/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - loss: 0.0017 - mae: 0.0341 - val_loss: 0.0752 - val_mae: 0.1831\n",
      "Epoch 478/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 377ms/step - loss: 0.0028 - mae: 0.0430 - val_loss: 0.0765 - val_mae: 0.1913\n",
      "Epoch 479/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - loss: 0.0037 - mae: 0.0462 - val_loss: 0.0725 - val_mae: 0.1815\n",
      "Epoch 480/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 371ms/step - loss: 0.0036 - mae: 0.0453 - val_loss: 0.0645 - val_mae: 0.1563\n",
      "Epoch 481/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320ms/step - loss: 0.0027 - mae: 0.0413 - val_loss: 0.0633 - val_mae: 0.1549\n",
      "Epoch 482/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - loss: 0.0036 - mae: 0.0475 - val_loss: 0.0679 - val_mae: 0.1719\n",
      "Epoch 483/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - loss: 0.0030 - mae: 0.0399 - val_loss: 0.0676 - val_mae: 0.1738\n",
      "Epoch 484/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367ms/step - loss: 0.0030 - mae: 0.0428 - val_loss: 0.0657 - val_mae: 0.1657\n",
      "Epoch 485/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 375ms/step - loss: 0.0031 - mae: 0.0428 - val_loss: 0.0610 - val_mae: 0.1448\n",
      "Epoch 486/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378ms/step - loss: 0.0033 - mae: 0.0444 - val_loss: 0.0597 - val_mae: 0.1396\n",
      "Epoch 487/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 361ms/step - loss: 0.0022 - mae: 0.0367 - val_loss: 0.0625 - val_mae: 0.1585\n",
      "Epoch 488/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314ms/step - loss: 0.0030 - mae: 0.0424 - val_loss: 0.0637 - val_mae: 0.1679\n",
      "Epoch 489/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319ms/step - loss: 0.0019 - mae: 0.0312 - val_loss: 0.0632 - val_mae: 0.1680\n",
      "Epoch 490/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - loss: 0.0028 - mae: 0.0426 - val_loss: 0.0596 - val_mae: 0.1526\n",
      "Epoch 491/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - loss: 0.0018 - mae: 0.0361 - val_loss: 0.0621 - val_mae: 0.1560\n",
      "Epoch 492/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 365ms/step - loss: 0.0023 - mae: 0.0356 - val_loss: 0.0640 - val_mae: 0.1599\n",
      "Epoch 493/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step - loss: 0.0018 - mae: 0.0339 - val_loss: 0.0638 - val_mae: 0.1564\n",
      "Epoch 494/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304ms/step - loss: 0.0022 - mae: 0.0363 - val_loss: 0.0643 - val_mae: 0.1579\n",
      "Epoch 495/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - loss: 0.0021 - mae: 0.0363 - val_loss: 0.0654 - val_mae: 0.1612\n",
      "Epoch 496/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 351ms/step - loss: 0.0018 - mae: 0.0325 - val_loss: 0.0678 - val_mae: 0.1667\n",
      "Epoch 497/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 372ms/step - loss: 0.0022 - mae: 0.0359 - val_loss: 0.0722 - val_mae: 0.1714\n",
      "Epoch 498/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - loss: 0.0019 - mae: 0.0344 - val_loss: 0.0777 - val_mae: 0.1767\n",
      "Epoch 499/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 360ms/step - loss: 0.0021 - mae: 0.0353 - val_loss: 0.0824 - val_mae: 0.1848\n",
      "Epoch 500/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step - loss: 0.0016 - mae: 0.0322 - val_loss: 0.0803 - val_mae: 0.1746\n"
     ]
    }
   ],
   "source": [
    "# Train the LSTM model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=500,  # You can adjust based on convergence\n",
    "    batch_size=16,  # Smaller batch size for augmented data\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0803, Validation MAE: 0.1746\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_mae = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation MAE: {val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step\n",
      "Predicted: 0.90, Actual: 1.00\n",
      "Predicted: 0.90, Actual: 1.00\n",
      "Predicted: 0.94, Actual: 1.00\n",
      "Predicted: 0.35, Actual: 1.00\n",
      "Predicted: 0.93, Actual: 1.00\n",
      "Predicted: 0.90, Actual: 1.00\n",
      "Predicted: 0.92, Actual: 1.00\n",
      "Predicted: 0.88, Actual: 1.00\n",
      "Predicted: 0.90, Actual: 1.00\n",
      "Predicted: 0.72, Actual: 1.00\n",
      "Predicted: 0.91, Actual: 1.00\n",
      "Predicted: 0.90, Actual: 1.00\n",
      "Predicted: 0.06, Actual: 1.00\n",
      "Predicted: 0.90, Actual: 1.00\n",
      "Predicted: 0.90, Actual: 1.00\n",
      "Predicted: 0.91, Actual: 1.00\n",
      "Predicted: 0.88, Actual: 1.00\n",
      "Predicted: 0.89, Actual: 1.00\n",
      "Predicted: 0.01, Actual: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Predict scores on validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Print predictions vs. actual\n",
    "for i, pred in enumerate(predictions):\n",
    "    print(f\"Predicted: {pred[0]:.2f}, Actual: {y_val[i]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatter plot of predictions vs. actual\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_val, predictions, c='blue', label='Predicted vs Actual')\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Perfect Match')  # Reference line\n",
    "plt.xlabel('Actual Scores')\n",
    "plt.ylabel('Predicted Scores')\n",
    "plt.title('Model Predictions vs. Actual Scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737649183.171986 9103311 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Pro\n",
      "W0000 00:00:1737649183.227677 9155645 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1737649183.236617 9155645 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step\n",
      "Predicted Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to determine if center of mass leans forward\n",
    "def is_center_of_mass_forward(shoulder, hip, ankle):\n",
    "    \"\"\"\n",
    "    Determines if the center of mass is leaning forward by analyzing the relative positions\n",
    "    of the shoulder and hip to the ankle.\n",
    "    \"\"\"\n",
    "    shoulder_x, shoulder_y = shoulder\n",
    "    hip_x, hip_y = hip\n",
    "    ankle_x, ankle_y = ankle\n",
    "\n",
    "    # Center of mass leans forward if the shoulder is ahead (x-axis) of the ankle\n",
    "    # and the hip is slightly ahead or aligned with the ankle.\n",
    "    return shoulder_x > ankle_x and hip_x > ankle_x\n",
    "\n",
    "# Path for the new test video\n",
    "new_video_path = \"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/sprint_technique/stages/stage5/test_videos/VID20250113142648.mp4\"\n",
    "\n",
    "# Extract keypoints for the new video\n",
    "new_keypoints = []\n",
    "cap = cv2.VideoCapture(new_video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB for MediaPipe processing\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = pose.process(frame_rgb)\n",
    "\n",
    "    if result.pose_landmarks:\n",
    "        landmarks = result.pose_landmarks.landmark\n",
    "\n",
    "        # Extract relevant keypoints for left and right side\n",
    "        left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x,\n",
    "                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y]\n",
    "        left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.LEFT_HIP].y]\n",
    "        left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y]\n",
    "\n",
    "        right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x,\n",
    "                          landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y]\n",
    "        right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y]\n",
    "        right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].x,\n",
    "                       landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].y]\n",
    "\n",
    "        # Check if center of mass leans forward\n",
    "        left_mass_forward = is_center_of_mass_forward(left_shoulder, left_hip, left_ankle)\n",
    "        right_mass_forward = is_center_of_mass_forward(right_shoulder, right_hip, right_ankle)\n",
    "\n",
    "        # Store the binary values (0 or 1) for analysis\n",
    "        new_keypoints.append([int(left_mass_forward), int(right_mass_forward)])\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Pad the sequence to match training input length\n",
    "max_seq_length = X_train.shape[1]  # Ensure it's the same length used during training\n",
    "new_keypoints_padded = pad_sequences([new_keypoints], maxlen=max_seq_length, padding='post', dtype='float32')\n",
    "\n",
    "# Reshape to match model input (samples, timesteps, features)\n",
    "new_keypoints_padded = new_keypoints_padded.reshape((new_keypoints_padded.shape[0], new_keypoints_padded.shape[1], 2))\n",
    "\n",
    "# Predict score for the new video\n",
    "predicted_score = model.predict(new_keypoints_padded)\n",
    "print(f\"Predicted Score: {predicted_score[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_score(prediction):\n",
    "    \"\"\"Classify the prediction into 0, 0.5, or 1 based on thresholds.\"\"\"\n",
    "    if prediction >= 0.8:\n",
    "        return 1.0\n",
    "    elif prediction >= 0.7:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 0.5, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 1.0, Actual: 1.0\n",
      "Classified: 0.0, Actual: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Predict scores on validation data\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Apply classification logic\n",
    "classified_predictions = [classify_score(pred[0]) for pred in predictions]\n",
    "\n",
    "# Print classified predictions vs actual scores\n",
    "for i, (pred, actual) in enumerate(zip(classified_predictions, y_val)):\n",
    "    print(f\"Classified: {pred}, Actual: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def weighted_mse(y_true, y_pred):\n",
    "    \"\"\"Weighted Mean Squared Error to prioritize true negatives.\"\"\"\n",
    "    weights = K.switch(y_true < 0.70, 2.0, 1.0)  # Weight true negatives higher\n",
    "    return K.mean(weights * K.square(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=weighted_mse, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
      "Classification Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Predict and classify scores\n",
    "classified_predictions = [classify_score(pred[0]) for pred in model.predict(X_val)]\n",
    "\n",
    "# Evaluate accuracy of classification\n",
    "correct = sum(1 for pred, actual in zip(classified_predictions, y_val) if pred == actual)\n",
    "accuracy = correct / len(y_val)\n",
    "\n",
    "print(f\"Classification Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/Users/danyukezz/Desktop/2 year 1 semester/team project/danya_preprocessing_sports/sprint_technique/stages/stage5/models/sprint_stage5.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
